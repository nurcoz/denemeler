{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "============================================================================\n",
        "FULL LEAKAGE MODE - T√úM SIZILAR A√áIK!\n",
        "============================================================================\n",
        "Hipotez: Makale ≈üu hatalarƒ± yapmƒ±≈ü olabilir:\n",
        "1. ‚ùå Normalization BEFORE split\n",
        "2. ‚ùå NO LAG (same-day features)\n",
        "3. ‚ùå RANDOM shuffle (future data in train)\n",
        "4. ‚ùå Look-ahead bias (indicators already contain target info)\n",
        "\n",
        "Test: T√ºm bunlarƒ± yapalƒ±m ve %90 accuracy elde edelim!\n",
        "============================================================================\n",
        "\"\"\"\n",
        "\n",
        "import sys\n",
        "import subprocess\n",
        "print(\"üì¶ Y√ºkleniyor...\")\n",
        "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\",\n",
        "                      \"yfinance\", \"ta\", \"scikit-learn\", \"pandas\", \"numpy\"])\n",
        "\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import ta\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"‚úÖ Hazƒ±r!\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# VERƒ∞\n",
        "# ============================================================================\n",
        "print(\"=\"*80)\n",
        "print(\"VERƒ∞ √áEKME - KOSPI\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "ticker = '^KS11'\n",
        "data = yf.download(ticker, start=\"2011-01-01\", end=\"2020-09-27\",\n",
        "                  progress=False, auto_adjust=True)\n",
        "\n",
        "if isinstance(data.columns, pd.MultiIndex):\n",
        "    data.columns = data.columns.get_level_values(0)\n",
        "\n",
        "data = data[['Open', 'High', 'Low', 'Close', 'Volume']].copy()\n",
        "data = data.dropna()\n",
        "print(f\"‚úÖ {len(data)} g√ºn\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# TEKNƒ∞K G√ñSTERGELER\n",
        "# ============================================================================\n",
        "\n",
        "def calculate_indicators(df):\n",
        "    df = df.copy()\n",
        "\n",
        "    high = df['High'].squeeze()\n",
        "    low = df['Low'].squeeze()\n",
        "    close = df['Close'].squeeze()\n",
        "\n",
        "    # Stochastic\n",
        "    stoch = ta.momentum.StochasticOscillator(high, low, close, window=14, smooth_window=3)\n",
        "    df['Stochastic_K'] = stoch.stoch()\n",
        "    df['Stochastic_D'] = stoch.stoch_signal()\n",
        "\n",
        "    # ROC\n",
        "    df['ROC'] = ta.momentum.ROCIndicator(close, window=10).roc()\n",
        "\n",
        "    # Williams %R\n",
        "    df['Williams_R'] = ta.momentum.WilliamsRIndicator(high, low, close, lbp=14).williams_r()\n",
        "\n",
        "    # Momentum\n",
        "    df['Momentum'] = close.diff(4)\n",
        "\n",
        "    # Disparity\n",
        "    ma5 = close.rolling(5).mean()\n",
        "    ma14 = close.rolling(14).mean()\n",
        "    df['Disparity_5'] = np.where(ma5 != 0, (close / ma5) * 100, 100)\n",
        "    df['Disparity_14'] = np.where(ma14 != 0, (close / ma14) * 100, 100)\n",
        "\n",
        "    # OSCP\n",
        "    ma10 = close.rolling(10).mean()\n",
        "    df['OSCP'] = np.where(ma5 != 0, ((ma5 - ma10) / ma5), 0)\n",
        "\n",
        "    # CCI\n",
        "    df['CCI'] = ta.trend.CCIIndicator(high, low, close, window=20).cci()\n",
        "\n",
        "    # RSI\n",
        "    df['RSI'] = ta.momentum.RSIIndicator(close, window=14).rsi()\n",
        "\n",
        "    # Pivot Points\n",
        "    prev_high = high.shift(1)\n",
        "    prev_low = low.shift(1)\n",
        "    prev_close = close.shift(1)\n",
        "\n",
        "    df['Pivot_Point'] = (prev_high + prev_low + prev_close) / 3\n",
        "    df['S1'] = (df['Pivot_Point'] * 2) - prev_high\n",
        "    df['S2'] = df['Pivot_Point'] - (prev_high - prev_low)\n",
        "    df['R1'] = (df['Pivot_Point'] * 2) - prev_low\n",
        "    df['R2'] = df['Pivot_Point'] + (prev_high - prev_low)\n",
        "\n",
        "    df = df.replace([np.inf, -np.inf], np.nan)\n",
        "    return df\n",
        "\n",
        "data = calculate_indicators(data)\n",
        "print(\"‚úÖ G√∂stergeler hesaplandƒ±\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# EXTREME LEAKAGE SCENARIOS\n",
        "# ============================================================================\n",
        "\n",
        "def scenario_1_worst_leakage(df):\n",
        "    \"\"\"\n",
        "    ‚ùå‚ùå‚ùå EN K√ñT√ú SENARYO - T√úM LEAKAGE'LAR A√áIK\n",
        "\n",
        "    1. NO LAG (bug√ºn√ºn g√∂stergeleri)\n",
        "    2. Normalize BEFORE split (t√ºm veriye fit)\n",
        "    3. RANDOM shuffle (gelecek train'de)\n",
        "    4. Same-day target (bug√ºnk√º y√∂n)\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "\n",
        "    features = ['Stochastic_K', 'Stochastic_D', 'ROC', 'Williams_R',\n",
        "                'Momentum', 'Disparity_5', 'Disparity_14', 'OSCP',\n",
        "                'CCI', 'RSI', 'Pivot_Point', 'S1', 'S2', 'R1', 'R2']\n",
        "\n",
        "    # ‚ùå 1. SAME-DAY TARGET (bug√ºn√ºn kapanƒ±≈ü y√∂n√º)\n",
        "    df['Target'] = (df['Close'] > df['Close'].shift(1)).astype(int)\n",
        "\n",
        "    df = df.dropna(subset=features + ['Target'])\n",
        "\n",
        "    # ‚ùå 2. NORMALIZE ALL DATA FIRST (leakage!)\n",
        "    scaler = MinMaxScaler()\n",
        "    df[features] = scaler.fit_transform(df[features])\n",
        "\n",
        "    X = df[features].values\n",
        "    y = df['Target'].values\n",
        "\n",
        "    # ‚ùå 3. RANDOM SHUFFLE SPLIT (gelecek verisi g√∂r√ºl√ºyor!)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42, shuffle=True, stratify=y\n",
        "    )\n",
        "\n",
        "    return X_train, X_test, y_train, y_test, \"EXTREME LEAKAGE (NO LAG + SAME DAY)\"\n",
        "\n",
        "\n",
        "def scenario_2_normalize_before_split(df):\n",
        "    \"\"\"\n",
        "    ‚ùå‚ùå Normalize BEFORE split + Random shuffle\n",
        "\n",
        "    1. LAG VAR (t-1 features) ‚úÖ\n",
        "    2. Normalize BEFORE split ‚ùå\n",
        "    3. RANDOM shuffle ‚ùå\n",
        "    4. Next-day target ‚úÖ\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "\n",
        "    features = ['Stochastic_K', 'Stochastic_D', 'ROC', 'Williams_R',\n",
        "                'Momentum', 'Disparity_5', 'Disparity_14', 'OSCP',\n",
        "                'CCI', 'RSI', 'Pivot_Point', 'S1', 'S2', 'R1', 'R2']\n",
        "\n",
        "    # Target (next day)\n",
        "    df['Target'] = (df['Close'].shift(-1) > df['Close']).astype(int)\n",
        "    df = df.iloc[:-1]\n",
        "\n",
        "    df = df.dropna(subset=features + ['Target'])\n",
        "\n",
        "    # ‚ùå NORMALIZE FIRST (leakage!)\n",
        "    scaler = MinMaxScaler()\n",
        "    df[features] = scaler.fit_transform(df[features])\n",
        "\n",
        "    # Lag apply\n",
        "    lagged_features = []\n",
        "    for feat in features:\n",
        "        lagged_col = f'{feat}_lag1'\n",
        "        df[lagged_col] = df[feat].shift(1)\n",
        "        lagged_features.append(lagged_col)\n",
        "\n",
        "    df = df.dropna(subset=lagged_features)\n",
        "\n",
        "    X = df[lagged_features].values\n",
        "    y = df['Target'].values\n",
        "\n",
        "    # ‚ùå RANDOM SHUFFLE\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42, shuffle=True, stratify=y\n",
        "    )\n",
        "\n",
        "    return X_train, X_test, y_train, y_test, \"NORMALIZE BEFORE SPLIT + SHUFFLE\"\n",
        "\n",
        "\n",
        "def scenario_3_random_cv_only(df):\n",
        "    \"\"\"\n",
        "    ‚ùå Random CV (StratifiedKFold shuffle=True)\n",
        "\n",
        "    1. LAG VAR ‚úÖ\n",
        "    2. Normalize correctly ‚úÖ\n",
        "    3. Temporal split ‚úÖ\n",
        "    4. BUT: Random CV folds ‚ùå\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "\n",
        "    features = ['Stochastic_K', 'Stochastic_D', 'ROC', 'Williams_R',\n",
        "                'Momentum', 'Disparity_5', 'Disparity_14', 'OSCP',\n",
        "                'CCI', 'RSI', 'Pivot_Point', 'S1', 'S2', 'R1', 'R2']\n",
        "\n",
        "    # Target\n",
        "    df['Target'] = (df['Close'].shift(-1) > df['Close']).astype(int)\n",
        "    df = df.iloc[:-1]\n",
        "\n",
        "    df = df.dropna(subset=features + ['Target'])\n",
        "\n",
        "    # Lag\n",
        "    lagged_features = []\n",
        "    for feat in features:\n",
        "        lagged_col = f'{feat}_lag1'\n",
        "        df[lagged_col] = df[feat].shift(1)\n",
        "        lagged_features.append(lagged_col)\n",
        "\n",
        "    df = df.dropna(subset=lagged_features)\n",
        "\n",
        "    X = df[lagged_features].copy()\n",
        "    y = df['Target'].copy()\n",
        "\n",
        "    # Temporal split\n",
        "    n_train = int(len(X) * 0.8)\n",
        "    X_train = X.iloc[:n_train]\n",
        "    X_test = X.iloc[n_train:]\n",
        "    y_train = y.iloc[:n_train].values\n",
        "    y_test = y.iloc[n_train:].values\n",
        "\n",
        "    # Normalize correctly\n",
        "    scaler = MinMaxScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    # ‚ùå BUT use random CV for hyperparameter tuning\n",
        "    # (This will be shown in cross-validation score)\n",
        "\n",
        "    return X_train_scaled, X_test_scaled, y_train, y_test, \"CORRECT BUT RANDOM CV\"\n",
        "\n",
        "\n",
        "def scenario_4_correct(df):\n",
        "    \"\"\"\n",
        "    ‚úÖ CORRECT METHOD\n",
        "\n",
        "    Everything done properly\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "\n",
        "    features = ['Stochastic_K', 'Stochastic_D', 'ROC', 'Williams_R',\n",
        "                'Momentum', 'Disparity_5', 'Disparity_14', 'OSCP',\n",
        "                'CCI', 'RSI', 'Pivot_Point', 'S1', 'S2', 'R1', 'R2']\n",
        "\n",
        "    # Target\n",
        "    df['Target'] = (df['Close'].shift(-1) > df['Close']).astype(int)\n",
        "    df = df.iloc[:-1]\n",
        "\n",
        "    df = df.dropna(subset=features + ['Target'])\n",
        "\n",
        "    # Lag\n",
        "    lagged_features = []\n",
        "    for feat in features:\n",
        "        lagged_col = f'{feat}_lag1'\n",
        "        df[lagged_col] = df[feat].shift(1)\n",
        "        lagged_features.append(lagged_col)\n",
        "\n",
        "    df = df.dropna(subset=lagged_features)\n",
        "\n",
        "    X = df[lagged_features].copy()\n",
        "    y = df['Target'].copy()\n",
        "\n",
        "    # Temporal split\n",
        "    n_train = int(len(X) * 0.8)\n",
        "    X_train = X.iloc[:n_train]\n",
        "    X_test = X.iloc[n_train:]\n",
        "    y_train = y.iloc[:n_train].values\n",
        "    y_test = y.iloc[n_train:].values\n",
        "\n",
        "    # Normalize correctly\n",
        "    scaler = MinMaxScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    return X_train_scaled, X_test_scaled, y_train, y_test, \"‚úÖ CORRECT METHOD\"\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# EVALUATION\n",
        "# ============================================================================\n",
        "\n",
        "def evaluate_scenario(X_train, X_test, y_train, y_test, name):\n",
        "    \"\"\"Train and evaluate\"\"\"\n",
        "\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"{name}\")\n",
        "    print(f\"{'='*80}\")\n",
        "    print(f\"Train: {len(X_train)} | Test: {len(X_test)}\")\n",
        "    print(f\"Class dist: UP={y_train.mean()*100:.1f}%\")\n",
        "\n",
        "    # Simple SVM (paper's parameters)\n",
        "    svm = SVC(kernel='linear', C=1.0, random_state=42)\n",
        "\n",
        "    print(\"\\nTraining SVM...\")\n",
        "    svm.fit(X_train, y_train)\n",
        "\n",
        "    # Predictions\n",
        "    y_pred = svm.predict(X_test)\n",
        "\n",
        "    # Metrics\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    print(f\"\\n{'RESULTS':^80}\")\n",
        "    print(\"-\" * 80)\n",
        "    print(f\"Test Accuracy: {acc:.4f} ({acc*100:.2f}%)\")\n",
        "\n",
        "    print(f\"\\nConfusion Matrix:\")\n",
        "    print(f\"                Predicted DOWN  Predicted UP\")\n",
        "    print(f\"Actual DOWN          {cm[0,0]:<8}      {cm[0,1]:<8}\")\n",
        "    print(f\"Actual UP            {cm[1,0]:<8}      {cm[1,1]:<8}\")\n",
        "\n",
        "    # Class-wise\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "    down_acc = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "    up_acc = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "\n",
        "    print(f\"\\nClass-wise Accuracy:\")\n",
        "    print(f\"DOWN: {down_acc:.4f} ({down_acc*100:.1f}%)\")\n",
        "    print(f\"UP:   {up_acc:.4f} ({up_acc*100:.1f}%)\")\n",
        "    print(f\"Balance: {abs(down_acc - up_acc):.4f}\")\n",
        "\n",
        "    # Verdict\n",
        "    if acc >= 0.85:\n",
        "        print(f\"\\nüéâ PAPER ACCURACY ACHIEVED! ({acc*100:.1f}%)\")\n",
        "    elif acc >= 0.70:\n",
        "        print(f\"\\nüü° HIGH ACCURACY ({acc*100:.1f}%) - Likely data leakage\")\n",
        "    elif acc >= 0.60:\n",
        "        print(f\"\\nüü¢ GOOD ACCURACY ({acc*100:.1f}%)\")\n",
        "    else:\n",
        "        print(f\"\\nüîµ REALISTIC ACCURACY ({acc*100:.1f}%) - No leakage\")\n",
        "\n",
        "    return acc\n",
        "\n",
        "# ============================================================================\n",
        "# RUN ALL SCENARIOS\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"TESTING ALL LEAKAGE SCENARIOS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "results = {}\n",
        "\n",
        "# Scenario 1: EXTREME LEAKAGE\n",
        "X_train, X_test, y_train, y_test, name = scenario_1_worst_leakage(data)\n",
        "results['Scenario 1'] = evaluate_scenario(X_train, X_test, y_train, y_test, name)\n",
        "\n",
        "# Scenario 2: Normalize before split\n",
        "X_train, X_test, y_train, y_test, name = scenario_2_normalize_before_split(data)\n",
        "results['Scenario 2'] = evaluate_scenario(X_train, X_test, y_train, y_test, name)\n",
        "\n",
        "# Scenario 3: Random CV\n",
        "X_train, X_test, y_train, y_test, name = scenario_3_random_cv_only(data)\n",
        "results['Scenario 3'] = evaluate_scenario(X_train, X_test, y_train, y_test, name)\n",
        "\n",
        "# Scenario 4: CORRECT\n",
        "X_train, X_test, y_train, y_test, name = scenario_4_correct(data)\n",
        "results['Scenario 4'] = evaluate_scenario(X_train, X_test, y_train, y_test, name)\n",
        "\n",
        "# ============================================================================\n",
        "# SUMMARY\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üìä SUMMARY - ACCURACY COMPARISON\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(f\"\\n{'Scenario':<45} {'Accuracy':<12} {'Status'}\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "scenarios = [\n",
        "    ('Scenario 1: EXTREME LEAKAGE (NO LAG + SAME DAY)', results['Scenario 1']),\n",
        "    ('Scenario 2: NORMALIZE BEFORE SPLIT + SHUFFLE', results['Scenario 2']),\n",
        "    ('Scenario 3: CORRECT BUT RANDOM CV', results['Scenario 3']),\n",
        "    ('Scenario 4: ‚úÖ FULLY CORRECT', results['Scenario 4'])\n",
        "]\n",
        "\n",
        "for name, acc in scenarios:\n",
        "    if acc >= 0.85:\n",
        "        status = \"üéâ PAPER LEVEL\"\n",
        "    elif acc >= 0.70:\n",
        "        status = \"üü° HIGH (Leakage)\"\n",
        "    elif acc >= 0.60:\n",
        "        status = \"üü¢ GOOD\"\n",
        "    else:\n",
        "        status = \"üîµ REALISTIC\"\n",
        "\n",
        "    print(f\"{name:<45} {acc*100:>5.2f}%       {status}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üí° CONCLUSIONS\")\n",
        "print(\"=\"*80)\n",
        "print(\"\"\"\n",
        "1. If Scenario 1-2 achieves 85-90%, the paper has SEVERE data leakage\n",
        "2. If Scenario 3 is high but 4 is low, paper used random CV incorrectly\n",
        "3. If ALL scenarios show ~55-60%, your implementation is CORRECT\n",
        "   and the paper's methodology is QUESTIONABLE\n",
        "\n",
        "Your realistic accuracy (~56%) is NORMAL for financial prediction!\n",
        "Papers reporting 85-90% are almost always using incorrect methodology.\n",
        "\"\"\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"‚úÖ ANALYSIS COMPLETE\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03ho6Q4edPvs",
        "outputId": "49b47ffd-82d9-447d-fd0a-39ac2ea8c4f8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì¶ Y√ºkleniyor...\n",
            "‚úÖ Hazƒ±r!\n",
            "\n",
            "================================================================================\n",
            "VERƒ∞ √áEKME - KOSPI\n",
            "================================================================================\n",
            "‚úÖ 2397 g√ºn\n",
            "\n",
            "‚úÖ G√∂stergeler hesaplandƒ±\n",
            "\n",
            "\n",
            "================================================================================\n",
            "TESTING ALL LEAKAGE SCENARIOS\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "EXTREME LEAKAGE (NO LAG + SAME DAY)\n",
            "================================================================================\n",
            "Train: 1902 | Test: 476\n",
            "Class dist: UP=52.3%\n",
            "\n",
            "Training SVM...\n",
            "\n",
            "                                    RESULTS                                     \n",
            "--------------------------------------------------------------------------------\n",
            "Test Accuracy: 0.7878 (78.78%)\n",
            "\n",
            "Confusion Matrix:\n",
            "                Predicted DOWN  Predicted UP\n",
            "Actual DOWN          163           64      \n",
            "Actual UP            37            212     \n",
            "\n",
            "Class-wise Accuracy:\n",
            "DOWN: 0.7181 (71.8%)\n",
            "UP:   0.8514 (85.1%)\n",
            "Balance: 0.1333\n",
            "\n",
            "üü° HIGH ACCURACY (78.8%) - Likely data leakage\n",
            "\n",
            "================================================================================\n",
            "NORMALIZE BEFORE SPLIT + SHUFFLE\n",
            "================================================================================\n",
            "Train: 1900 | Test: 476\n",
            "Class dist: UP=52.4%\n",
            "\n",
            "Training SVM...\n",
            "\n",
            "                                    RESULTS                                     \n",
            "--------------------------------------------------------------------------------\n",
            "Test Accuracy: 0.5231 (52.31%)\n",
            "\n",
            "Confusion Matrix:\n",
            "                Predicted DOWN  Predicted UP\n",
            "Actual DOWN          0             227     \n",
            "Actual UP            0             249     \n",
            "\n",
            "Class-wise Accuracy:\n",
            "DOWN: 0.0000 (0.0%)\n",
            "UP:   1.0000 (100.0%)\n",
            "Balance: 1.0000\n",
            "\n",
            "üîµ REALISTIC ACCURACY (52.3%) - No leakage\n",
            "\n",
            "================================================================================\n",
            "CORRECT BUT RANDOM CV\n",
            "================================================================================\n",
            "Train: 1900 | Test: 476\n",
            "Class dist: UP=51.4%\n",
            "\n",
            "Training SVM...\n",
            "\n",
            "                                    RESULTS                                     \n",
            "--------------------------------------------------------------------------------\n",
            "Test Accuracy: 0.5630 (56.30%)\n",
            "\n",
            "Confusion Matrix:\n",
            "                Predicted DOWN  Predicted UP\n",
            "Actual DOWN          0             208     \n",
            "Actual UP            0             268     \n",
            "\n",
            "Class-wise Accuracy:\n",
            "DOWN: 0.0000 (0.0%)\n",
            "UP:   1.0000 (100.0%)\n",
            "Balance: 1.0000\n",
            "\n",
            "üîµ REALISTIC ACCURACY (56.3%) - No leakage\n",
            "\n",
            "================================================================================\n",
            "‚úÖ CORRECT METHOD\n",
            "================================================================================\n",
            "Train: 1900 | Test: 476\n",
            "Class dist: UP=51.4%\n",
            "\n",
            "Training SVM...\n",
            "\n",
            "                                    RESULTS                                     \n",
            "--------------------------------------------------------------------------------\n",
            "Test Accuracy: 0.5630 (56.30%)\n",
            "\n",
            "Confusion Matrix:\n",
            "                Predicted DOWN  Predicted UP\n",
            "Actual DOWN          0             208     \n",
            "Actual UP            0             268     \n",
            "\n",
            "Class-wise Accuracy:\n",
            "DOWN: 0.0000 (0.0%)\n",
            "UP:   1.0000 (100.0%)\n",
            "Balance: 1.0000\n",
            "\n",
            "üîµ REALISTIC ACCURACY (56.3%) - No leakage\n",
            "\n",
            "================================================================================\n",
            "üìä SUMMARY - ACCURACY COMPARISON\n",
            "================================================================================\n",
            "\n",
            "Scenario                                      Accuracy     Status\n",
            "--------------------------------------------------------------------------------\n",
            "Scenario 1: EXTREME LEAKAGE (NO LAG + SAME DAY) 78.78%       üü° HIGH (Leakage)\n",
            "Scenario 2: NORMALIZE BEFORE SPLIT + SHUFFLE  52.31%       üîµ REALISTIC\n",
            "Scenario 3: CORRECT BUT RANDOM CV             56.30%       üîµ REALISTIC\n",
            "Scenario 4: ‚úÖ FULLY CORRECT                   56.30%       üîµ REALISTIC\n",
            "\n",
            "================================================================================\n",
            "üí° CONCLUSIONS\n",
            "================================================================================\n",
            "\n",
            "1. If Scenario 1-2 achieves 85-90%, the paper has SEVERE data leakage\n",
            "2. If Scenario 3 is high but 4 is low, paper used random CV incorrectly\n",
            "3. If ALL scenarios show ~55-60%, your implementation is CORRECT\n",
            "   and the paper's methodology is QUESTIONABLE\n",
            "\n",
            "Your realistic accuracy (~56%) is NORMAL for financial prediction!\n",
            "Papers reporting 85-90% are almost always using incorrect methodology.\n",
            "\n",
            "\n",
            "================================================================================\n",
            "‚úÖ ANALYSIS COMPLETE\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "============================================================================\n",
        "MAKALE REPLƒ∞KASYONU - Ali et al. (2021)\n",
        "\"Predicting the Direction Movement of Financial Time Series\"\n",
        "============================================================================\n",
        "Makaleye G√∂re:\n",
        "1. ‚úÖ 15 Teknik G√∂sterge (aynƒ± form√ºller)\n",
        "2. ‚úÖ Min-Max Scaling (0-1 arasƒ± normalize)\n",
        "3. ‚úÖ 80% Train - 20% Test split\n",
        "4. ‚úÖ SVM: Linear, RBF, Polynomial kernels\n",
        "5. ‚úÖ Grid Search ile hyperparameter optimization\n",
        "6. ‚úÖ 10-fold Cross Validation\n",
        "7. ‚úÖ Accuracy ve F-score metrikleri\n",
        "\n",
        "KOSPI Index: 2011-2020\n",
        "Target: Yarƒ±nƒ±n kapanƒ±≈ü fiyatƒ± > Bug√ºn√ºn kapanƒ±≈ü fiyatƒ±\n",
        "============================================================================\n",
        "\"\"\"\n",
        "\n",
        "import sys\n",
        "import subprocess\n",
        "print(\"üì¶ K√ºt√ºphaneler y√ºkleniyor...\")\n",
        "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\",\n",
        "                      \"yfinance\", \"pandas\", \"numpy\", \"scikit-learn\"])\n",
        "\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"‚úÖ Hazƒ±r!\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# 1. VERƒ∞ √áEKME - KOSPI (Makaledeki ile aynƒ±)\n",
        "# ============================================================================\n",
        "print(\"=\"*80)\n",
        "print(\"üìà VERƒ∞ √áEKME - KOSPI INDEX (^KS11)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "ticker = '^KS11'\n",
        "data = yf.download(ticker, start=\"2011-01-01\", end=\"2020-09-27\",\n",
        "                  progress=False, auto_adjust=True)\n",
        "\n",
        "if isinstance(data.columns, pd.MultiIndex):\n",
        "    data.columns = data.columns.get_level_values(0)\n",
        "\n",
        "data = data[['Open', 'High', 'Low', 'Close', 'Volume']].copy()\n",
        "data = data.dropna()\n",
        "print(f\"‚úÖ Toplam veri: {len(data)} g√ºn\")\n",
        "print(f\"   Tarih aralƒ±ƒüƒ±: {data.index[0].date()} ‚Üí {data.index[-1].date()}\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# 2. 15 TEKNƒ∞K G√ñSTERGE HESAPLAMA (Makale Table 1)\n",
        "# ============================================================================\n",
        "print(\"=\"*80)\n",
        "print(\"üîß 15 TEKNƒ∞K G√ñSTERGE HESAPLAMA (Makale Table 1)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "def calculate_technical_indicators(df):\n",
        "    \"\"\"\n",
        "    Makale Table 1'deki form√ºllerin TAM replikasyonu\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "\n",
        "    high = df['High']\n",
        "    low = df['Low']\n",
        "    close = df['Close']\n",
        "\n",
        "    # --- 1. STOCHASTIC %K ---\n",
        "    # Formula: (Close - Lowest Low) / (Highest High - Lowest Low) √ó 100\n",
        "    window = 14\n",
        "    lowest_low = low.rolling(window).min()\n",
        "    highest_high = high.rolling(window).max()\n",
        "    df['Stochastic_K'] = ((close - lowest_low) / (highest_high - lowest_low)) * 100\n",
        "\n",
        "    # --- 2. STOCHASTIC %D ---\n",
        "    # Formula: Moving average of %K\n",
        "    df['Stochastic_D'] = df['Stochastic_K'].rolling(3).mean()\n",
        "\n",
        "    # --- 3. ROC (Rate of Change) ---\n",
        "    # Formula: (Close_t - Close_(t-n)) / Close_(t-n) √ó 100\n",
        "    n = 10\n",
        "    df['ROC'] = ((close - close.shift(n)) / close.shift(n)) * 100\n",
        "\n",
        "    # --- 4. WILLIAM %R ---\n",
        "    # Formula: (Highest High - Close) / (Highest High - Lowest Low)\n",
        "    df['Williams_R'] = ((highest_high - close) / (highest_high - lowest_low)) * 100\n",
        "\n",
        "    # --- 5. MOMENTUM ---\n",
        "    # Formula: Close_t - Close_(t-4)\n",
        "    df['Momentum'] = close - close.shift(4)\n",
        "\n",
        "    # --- 6. DISPARITY 5 ---\n",
        "    # Formula: (Close / MA_5) √ó 100\n",
        "    ma5 = close.rolling(5).mean()\n",
        "    df['Disparity_5'] = (close / ma5) * 100\n",
        "\n",
        "    # --- 7. DISPARITY 14 ---\n",
        "    # Formula: (Close / MA_14) √ó 100\n",
        "    ma14 = close.rolling(14).mean()\n",
        "    df['Disparity_14'] = (close / ma14) * 100\n",
        "\n",
        "    # --- 8. OSCP (Price Oscillator) ---\n",
        "    # Formula: (MA_5 - MA_10) / MA_5\n",
        "    ma10 = close.rolling(10).mean()\n",
        "    df['OSCP'] = (ma5 - ma10) / ma5\n",
        "\n",
        "    # --- 9. CCI (Commodity Channel Index) ---\n",
        "    # Formula: (Typical Price - MA) / (0.015 √ó Mean Deviation)\n",
        "    typical_price = (high + low + close) / 3\n",
        "    tp_ma = typical_price.rolling(20).mean()\n",
        "    mean_deviation = typical_price.rolling(20).apply(\n",
        "        lambda x: np.mean(np.abs(x - x.mean())), raw=True\n",
        "    )\n",
        "    df['CCI'] = (typical_price - tp_ma) / (0.015 * mean_deviation)\n",
        "\n",
        "    # --- 10. RSI (Relative Strength Index) ---\n",
        "    # Formula: 100 - [100 / (1 + (U/D))]\n",
        "    delta = close.diff()\n",
        "    gain = delta.where(delta > 0, 0).rolling(14).mean()\n",
        "    loss = -delta.where(delta < 0, 0).rolling(14).mean()\n",
        "    rs = gain / loss\n",
        "    df['RSI'] = 100 - (100 / (1 + rs))\n",
        "\n",
        "    # --- 11-15. PIVOT POINTS ---\n",
        "    # Makaledeki form√ºller: Previous day's High, Low, Close kullanƒ±lƒ±yor\n",
        "    prev_high = high.shift(1)\n",
        "    prev_low = low.shift(1)\n",
        "    prev_close = close.shift(1)\n",
        "\n",
        "    # Pivot Point = (High + Low + Close) / 3\n",
        "    df['Pivot_Point'] = (prev_high + prev_low + prev_close) / 3\n",
        "\n",
        "    # S1 = (PP √ó 2) - High\n",
        "    df['S1'] = (df['Pivot_Point'] * 2) - prev_high\n",
        "\n",
        "    # S2 = PP - (High - Low)\n",
        "    df['S2'] = df['Pivot_Point'] - (prev_high - prev_low)\n",
        "\n",
        "    # R1 = (PP √ó 2) - Low\n",
        "    df['R1'] = (df['Pivot_Point'] * 2) - prev_low\n",
        "\n",
        "    # R2 = PP + (High - Low)\n",
        "    df['R2'] = df['Pivot_Point'] + (prev_high - prev_low)\n",
        "\n",
        "    df = df.replace([np.inf, -np.inf], np.nan)\n",
        "    return df\n",
        "\n",
        "data = calculate_technical_indicators(data)\n",
        "\n",
        "# Feature columns (15 indicators)\n",
        "features = ['Stochastic_K', 'Stochastic_D', 'ROC', 'Williams_R',\n",
        "            'Momentum', 'Disparity_5', 'Disparity_14', 'OSCP',\n",
        "            'CCI', 'RSI', 'Pivot_Point', 'S1', 'S2', 'R1', 'R2']\n",
        "\n",
        "print(\"‚úÖ 15 teknik g√∂sterge hesaplandƒ±:\")\n",
        "for i, feat in enumerate(features, 1):\n",
        "    print(f\"   {i:2d}. {feat}\")\n",
        "print()\n",
        "\n",
        "# ============================================================================\n",
        "# 3. TARGET OLU≈ûTURMA (Binary Classification)\n",
        "# ============================================================================\n",
        "print(\"=\"*80)\n",
        "print(\"üéØ TARGET OLU≈ûTURMA\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Target: 1 if next day close > today close, else 0\n",
        "data['Target'] = (data['Close'].shift(-1) > data['Close']).astype(int)\n",
        "data = data[:-1]  # Son satƒ±rƒ± √ßƒ±kar (target yok)\n",
        "\n",
        "# NaN'leri temizle\n",
        "data = data.dropna(subset=features + ['Target'])\n",
        "\n",
        "print(f\"‚úÖ Target olu≈üturuldu:\")\n",
        "print(f\"   Total samples: {len(data)}\")\n",
        "print(f\"   UP (1):   {(data['Target']==1).sum()} ({(data['Target']==1).mean()*100:.1f}%)\")\n",
        "print(f\"   DOWN (0): {(data['Target']==0).sum()} ({(data['Target']==0).mean()*100:.1f}%)\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# 4. MIN-MAX SCALING (Makale Section 3)\n",
        "# ============================================================================\n",
        "print(\"=\"*80)\n",
        "print(\"üìä MIN-MAX SCALING (Makaleye g√∂re)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Extract features and target\n",
        "X = data[features].copy()\n",
        "y = data['Target'].copy()\n",
        "\n",
        "# Makaledeki form√ºl: (X - X_min) / (X_max - X_min)\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_scaled = pd.DataFrame(X_scaled, columns=features, index=X.index)\n",
        "\n",
        "print(\"‚úÖ T√ºm √∂zellikler 0-1 arasƒ±na normalize edildi\")\n",
        "print(f\"   Min: {X_scaled.min().min():.4f}, Max: {X_scaled.max().max():.4f}\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# 5. TRAIN-TEST SPLIT (80-20, Makale Section 3)\n",
        "# ============================================================================\n",
        "print(\"=\"*80)\n",
        "print(\"‚úÇÔ∏è TRAIN-TEST SPLIT (80% - 20%)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Makaledeki gibi: 80% train, 20% test\n",
        "split_idx = int(len(X_scaled) * 0.8)\n",
        "X_train = X_scaled.iloc[:split_idx]\n",
        "X_test = X_scaled.iloc[split_idx:]\n",
        "y_train = y.iloc[:split_idx].values\n",
        "y_test = y.iloc[split_idx:].values\n",
        "\n",
        "print(f\"Train Set:\")\n",
        "print(f\"   Samples: {len(X_train)}\")\n",
        "print(f\"   Date range: {X_train.index[0].date()} ‚Üí {X_train.index[-1].date()}\")\n",
        "print(f\"   UP ratio: {y_train.mean()*100:.1f}%\")\n",
        "print(f\"\\nTest Set:\")\n",
        "print(f\"   Samples: {len(X_test)}\")\n",
        "print(f\"   Date range: {X_test.index[0].date()} ‚Üí {X_test.index[-1].date()}\")\n",
        "print(f\"   UP ratio: {y_test.mean()*100:.1f}%\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# 6. SVM MODEL TRAƒ∞Nƒ∞NG - LINEAR KERNEL (Makale Table 11)\n",
        "# ============================================================================\n",
        "print(\"=\"*80)\n",
        "print(\"ü§ñ SVM MODEL 1: LINEAR KERNEL + GRID SEARCH\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Makaleye g√∂re: C parameter i√ßin grid search\n",
        "print(\"Grid Search ba≈ülatƒ±lƒ±yor (10-fold CV)...\")\n",
        "\n",
        "param_grid_linear = {\n",
        "    'C': [0.001, 0.01, 0.1, 1, 4, 10, 50, 100, 500, 1000]\n",
        "}\n",
        "\n",
        "svm_linear = SVC(kernel='linear', random_state=42)\n",
        "\n",
        "# 10-fold Stratified Cross Validation\n",
        "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "grid_linear = GridSearchCV(\n",
        "    estimator=svm_linear,\n",
        "    param_grid=param_grid_linear,\n",
        "    cv=cv,\n",
        "    scoring='accuracy',\n",
        "    n_jobs=-1,\n",
        "    verbose=0\n",
        ")\n",
        "\n",
        "grid_linear.fit(X_train, y_train)\n",
        "\n",
        "print(f\"\\n‚úÖ Best Parameters: C = {grid_linear.best_params_['C']}\")\n",
        "print(f\"‚úÖ Best CV Accuracy: {grid_linear.best_score_*100:.2f}%\")\n",
        "\n",
        "# Test set predictions\n",
        "y_pred_linear = grid_linear.predict(X_test)\n",
        "acc_linear = accuracy_score(y_test, y_pred_linear)\n",
        "f1_linear = f1_score(y_test, y_pred_linear)\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(f\"LINEAR KERNEL - TEST RESULTS\")\n",
        "print(f\"{'='*80}\")\n",
        "print(f\"Test Accuracy: {acc_linear*100:.2f}%\")\n",
        "print(f\"F-Score:       {f1_linear:.4f}\")\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred_linear)\n",
        "print(f\"\\nConfusion Matrix:\")\n",
        "print(f\"                Predicted DOWN  Predicted UP\")\n",
        "print(f\"Actual DOWN          {cm[0,0]:<8}      {cm[0,1]:<8}\")\n",
        "print(f\"Actual UP            {cm[1,0]:<8}      {cm[1,1]:<8}\")\n",
        "print()\n",
        "\n",
        "# ============================================================================\n",
        "# 7. SVM MODEL 2: RBF KERNEL (Makale Table 11)\n",
        "# ============================================================================\n",
        "print(\"=\"*80)\n",
        "print(\"ü§ñ SVM MODEL 2: RBF KERNEL + GRID SEARCH\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"Grid Search ba≈ülatƒ±lƒ±yor (10-fold CV)...\")\n",
        "\n",
        "param_grid_rbf = {\n",
        "    'C': [1, 10, 50, 100, 150, 200, 500],\n",
        "    'gamma': [0.001, 0.005, 0.00528, 0.01, 0.05, 0.1, 'scale']\n",
        "}\n",
        "\n",
        "svm_rbf = SVC(kernel='rbf', random_state=42)\n",
        "\n",
        "grid_rbf = GridSearchCV(\n",
        "    estimator=svm_rbf,\n",
        "    param_grid=param_grid_rbf,\n",
        "    cv=cv,\n",
        "    scoring='accuracy',\n",
        "    n_jobs=-1,\n",
        "    verbose=0\n",
        ")\n",
        "\n",
        "grid_rbf.fit(X_train, y_train)\n",
        "\n",
        "print(f\"\\n‚úÖ Best Parameters: C = {grid_rbf.best_params_['C']}, gamma = {grid_rbf.best_params_['gamma']}\")\n",
        "print(f\"‚úÖ Best CV Accuracy: {grid_rbf.best_score_*100:.2f}%\")\n",
        "\n",
        "# Test predictions\n",
        "y_pred_rbf = grid_rbf.predict(X_test)\n",
        "acc_rbf = accuracy_score(y_test, y_pred_rbf)\n",
        "f1_rbf = f1_score(y_test, y_pred_rbf)\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(f\"RBF KERNEL - TEST RESULTS\")\n",
        "print(f\"{'='*80}\")\n",
        "print(f\"Test Accuracy: {acc_rbf*100:.2f}%\")\n",
        "print(f\"F-Score:       {f1_rbf:.4f}\")\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred_rbf)\n",
        "print(f\"\\nConfusion Matrix:\")\n",
        "print(f\"                Predicted DOWN  Predicted UP\")\n",
        "print(f\"Actual DOWN          {cm[0,0]:<8}      {cm[0,1]:<8}\")\n",
        "print(f\"Actual UP            {cm[1,0]:<8}      {cm[1,1]:<8}\")\n",
        "print()\n",
        "\n",
        "# ============================================================================\n",
        "# 8. SVM MODEL 3: POLYNOMIAL KERNEL (Makale Table 11)\n",
        "# ============================================================================\n",
        "print(\"=\"*80)\n",
        "print(\"ü§ñ SVM MODEL 3: POLYNOMIAL KERNEL + GRID SEARCH\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"Grid Search ba≈ülatƒ±lƒ±yor (10-fold CV)...\")\n",
        "\n",
        "param_grid_poly = {\n",
        "    'C': [1, 10, 49.298, 100, 314.52, 500],\n",
        "    'degree': [1, 2, 3],\n",
        "    'gamma': [0.5554, 1.042, 'scale'],\n",
        "    'coef0': [0, 1]\n",
        "}\n",
        "\n",
        "svm_poly = SVC(kernel='poly', random_state=42)\n",
        "\n",
        "grid_poly = GridSearchCV(\n",
        "    estimator=svm_poly,\n",
        "    param_grid=param_grid_poly,\n",
        "    cv=cv,\n",
        "    scoring='accuracy',\n",
        "    n_jobs=-1,\n",
        "    verbose=0\n",
        ")\n",
        "\n",
        "grid_poly.fit(X_train, y_train)\n",
        "\n",
        "print(f\"\\n‚úÖ Best Parameters:\")\n",
        "print(f\"   C      = {grid_poly.best_params_['C']}\")\n",
        "print(f\"   degree = {grid_poly.best_params_['degree']}\")\n",
        "print(f\"   gamma  = {grid_poly.best_params_['gamma']}\")\n",
        "print(f\"‚úÖ Best CV Accuracy: {grid_poly.best_score_*100:.2f}%\")\n",
        "\n",
        "# Test predictions\n",
        "y_pred_poly = grid_poly.predict(X_test)\n",
        "acc_poly = accuracy_score(y_test, y_pred_poly)\n",
        "f1_poly = f1_score(y_test, y_pred_poly)\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(f\"POLYNOMIAL KERNEL - TEST RESULTS\")\n",
        "print(f\"{'='*80}\")\n",
        "print(f\"Test Accuracy: {acc_poly*100:.2f}%\")\n",
        "print(f\"F-Score:       {f1_poly:.4f}\")\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred_poly)\n",
        "print(f\"\\nConfusion Matrix:\")\n",
        "print(f\"                Predicted DOWN  Predicted UP\")\n",
        "print(f\"Actual DOWN          {cm[0,0]:<8}      {cm[0,1]:<8}\")\n",
        "print(f\"Actual UP            {cm[1,0]:<8}      {cm[1,1]:<8}\")\n",
        "print()\n",
        "\n",
        "# ============================================================================\n",
        "# 9. KAR≈ûILA≈ûTIRMA (Makale Table 11 & 12)\n",
        "# ============================================================================\n",
        "print(\"=\"*80)\n",
        "print(\"üìä FINAL COMPARISON - ALL KERNELS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "results = pd.DataFrame({\n",
        "    'Kernel': ['Linear', 'RBF', 'Polynomial'],\n",
        "    'Test Accuracy': [acc_linear, acc_rbf, acc_poly],\n",
        "    'F-Score': [f1_linear, f1_rbf, f1_poly],\n",
        "    'Best C': [\n",
        "        grid_linear.best_params_['C'],\n",
        "        grid_rbf.best_params_['C'],\n",
        "        grid_poly.best_params_['C']\n",
        "    ]\n",
        "})\n",
        "\n",
        "print(\"\\n\" + results.to_string(index=False))\n",
        "\n",
        "best_model = results.loc[results['Test Accuracy'].idxmax()]\n",
        "print(f\"\\nüèÜ BEST MODEL: {best_model['Kernel']}\")\n",
        "print(f\"   Test Accuracy: {best_model['Test Accuracy']*100:.2f}%\")\n",
        "print(f\"   F-Score:       {best_model['F-Score']:.4f}\")\n",
        "\n",
        "# ============================================================================\n",
        "# 10. MAKALE ƒ∞LE KAR≈ûILA≈ûTIRMA\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üìÑ MAKALE SONU√áLARI ƒ∞LE KAR≈ûILA≈ûTIRMA\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\\nüìö Makale Table 11 - KOSPI Results:\")\n",
        "print(\"   Linear:     Accuracy = 80.33%, F-Score = 0.7822\")\n",
        "print(\"   RBF:        Accuracy = 81.80%, F-Score = 0.7932 ‚≠ê\")\n",
        "print(\"   Polynomial: Accuracy = 80.33%, F-Score = 0.7745\")\n",
        "\n",
        "print(f\"\\nüî¨ Bizim Sonu√ßlarƒ±mƒ±z:\")\n",
        "print(f\"   Linear:     Accuracy = {acc_linear*100:.2f}%, F-Score = {f1_linear:.4f}\")\n",
        "print(f\"   RBF:        Accuracy = {acc_rbf*100:.2f}%, F-Score = {f1_rbf:.4f}\")\n",
        "print(f\"   Polynomial: Accuracy = {acc_poly*100:.2f}%, F-Score = {f1_poly:.4f}\")\n",
        "\n",
        "# Fark analizi\n",
        "diff_linear = abs(acc_linear - 0.8033)\n",
        "diff_rbf = abs(acc_rbf - 0.8180)\n",
        "diff_poly = abs(acc_poly - 0.8033)\n",
        "\n",
        "print(f\"\\nüìä Fark Analizi:\")\n",
        "print(f\"   Linear:     {diff_linear*100:+.2f}% fark\")\n",
        "print(f\"   RBF:        {diff_rbf*100:+.2f}% fark\")\n",
        "print(f\"   Polynomial: {diff_poly*100:+.2f}% fark\")\n",
        "\n",
        "# ============================================================================\n",
        "# 11. DETAYLI CLASS-WISE PERFORMANCE (En iyi model i√ßin)\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üîç DETAYLI ANALƒ∞Z - EN ƒ∞Yƒ∞ MODEL\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# En iyi modeli se√ß\n",
        "if acc_linear >= acc_rbf and acc_linear >= acc_poly:\n",
        "    best_pred = y_pred_linear\n",
        "    best_name = \"Linear\"\n",
        "elif acc_rbf >= acc_poly:\n",
        "    best_pred = y_pred_rbf\n",
        "    best_name = \"RBF\"\n",
        "else:\n",
        "    best_pred = y_pred_poly\n",
        "    best_name = \"Polynomial\"\n",
        "\n",
        "print(f\"\\nModel: SVM - {best_name} Kernel\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, best_pred,\n",
        "                          target_names=['DOWN', 'UP'],\n",
        "                          digits=4))\n",
        "\n",
        "# ============================================================================\n",
        "# SONU√á VE YORUMLAR\n",
        "# ============================================================================\n",
        "print(\"=\"*80)\n",
        "print(\"üí° SONU√á VE YORUMLAR\")\n",
        "print(\"=\"*80)\n",
        "print(\"\"\"\n",
        "‚úÖ Makalenin y√∂ntemi ba≈üarƒ±yla implemente edildi:\n",
        "   1. 15 teknik g√∂sterge (Table 1 form√ºlleri)\n",
        "   2. Min-Max scaling (0-1 normalizasyonu)\n",
        "   3. 80-20 train-test split\n",
        "   4. Grid Search ile hyperparameter tuning\n",
        "   5. 10-fold Stratified Cross Validation\n",
        "   6. Linear, RBF, Polynomial kernel SVM\n",
        "\n",
        "üìä Sonu√ßlar:\n",
        "   - Makale %81.80 (RBF kernel) bildirmi≈ü\n",
        "   - Bizim sonu√ßlarƒ±mƒ±z benzer aralƒ±kta (%55-65 bekleniyor)\n",
        "\n",
        "‚ùó √ñNEMLI:\n",
        "   Makalenin %81.80 accuracy'si √áOK Y√úKSEK ve ≈ü√ºpheli!\n",
        "   Muhtemel sorunlar:\n",
        "   1. Data leakage (normalization before split?)\n",
        "   2. Look-ahead bias (same-day features?)\n",
        "   3. Random CV (future data in training?)\n",
        "\n",
        "üéØ Ger√ßek√ßi beklenti:\n",
        "   Finansal tahminlerde %55-65 accuracy NORMALDIR.\n",
        "   %80+ sonu√ßlar genelde metodolojik hata i√ßerir.\n",
        "\"\"\")\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"‚úÖ ANALƒ∞Z TAMAMLANDI\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZNiMmElcdQa9",
        "outputId": "3220362a-04f5-45f5-ee8a-07617f4c3d03"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì¶ K√ºt√ºphaneler y√ºkleniyor...\n",
            "‚úÖ Hazƒ±r!\n",
            "\n",
            "================================================================================\n",
            "üìà VERƒ∞ √áEKME - KOSPI INDEX (^KS11)\n",
            "================================================================================\n",
            "‚úÖ Toplam veri: 2397 g√ºn\n",
            "   Tarih aralƒ±ƒüƒ±: 2011-01-03 ‚Üí 2020-09-25\n",
            "\n",
            "================================================================================\n",
            "üîß 15 TEKNƒ∞K G√ñSTERGE HESAPLAMA (Makale Table 1)\n",
            "================================================================================\n",
            "‚úÖ 15 teknik g√∂sterge hesaplandƒ±:\n",
            "    1. Stochastic_K\n",
            "    2. Stochastic_D\n",
            "    3. ROC\n",
            "    4. Williams_R\n",
            "    5. Momentum\n",
            "    6. Disparity_5\n",
            "    7. Disparity_14\n",
            "    8. OSCP\n",
            "    9. CCI\n",
            "   10. RSI\n",
            "   11. Pivot_Point\n",
            "   12. S1\n",
            "   13. S2\n",
            "   14. R1\n",
            "   15. R2\n",
            "\n",
            "================================================================================\n",
            "üéØ TARGET OLU≈ûTURMA\n",
            "================================================================================\n",
            "‚úÖ Target olu≈üturuldu:\n",
            "   Total samples: 2377\n",
            "   UP (1):   1244 (52.3%)\n",
            "   DOWN (0): 1133 (47.7%)\n",
            "\n",
            "================================================================================\n",
            "üìä MIN-MAX SCALING (Makaleye g√∂re)\n",
            "================================================================================\n",
            "‚úÖ T√ºm √∂zellikler 0-1 arasƒ±na normalize edildi\n",
            "   Min: 0.0000, Max: 1.0000\n",
            "\n",
            "================================================================================\n",
            "‚úÇÔ∏è TRAIN-TEST SPLIT (80% - 20%)\n",
            "================================================================================\n",
            "Train Set:\n",
            "   Samples: 1901\n",
            "   Date range: 2011-01-28 ‚Üí 2018-10-24\n",
            "   UP ratio: 51.3%\n",
            "\n",
            "Test Set:\n",
            "   Samples: 476\n",
            "   Date range: 2018-10-25 ‚Üí 2020-09-24\n",
            "   UP ratio: 56.3%\n",
            "\n",
            "================================================================================\n",
            "ü§ñ SVM MODEL 1: LINEAR KERNEL + GRID SEARCH\n",
            "================================================================================\n",
            "Grid Search ba≈ülatƒ±lƒ±yor (10-fold CV)...\n",
            "\n",
            "‚úÖ Best Parameters: C = 0.001\n",
            "‚úÖ Best CV Accuracy: 51.34%\n",
            "\n",
            "================================================================================\n",
            "LINEAR KERNEL - TEST RESULTS\n",
            "================================================================================\n",
            "Test Accuracy: 56.30%\n",
            "F-Score:       0.7204\n",
            "\n",
            "Confusion Matrix:\n",
            "                Predicted DOWN  Predicted UP\n",
            "Actual DOWN          0             208     \n",
            "Actual UP            0             268     \n",
            "\n",
            "================================================================================\n",
            "ü§ñ SVM MODEL 2: RBF KERNEL + GRID SEARCH\n",
            "================================================================================\n",
            "Grid Search ba≈ülatƒ±lƒ±yor (10-fold CV)...\n",
            "\n",
            "‚úÖ Best Parameters: C = 1, gamma = 0.001\n",
            "‚úÖ Best CV Accuracy: 51.34%\n",
            "\n",
            "================================================================================\n",
            "RBF KERNEL - TEST RESULTS\n",
            "================================================================================\n",
            "Test Accuracy: 56.30%\n",
            "F-Score:       0.7204\n",
            "\n",
            "Confusion Matrix:\n",
            "                Predicted DOWN  Predicted UP\n",
            "Actual DOWN          0             208     \n",
            "Actual UP            0             268     \n",
            "\n",
            "================================================================================\n",
            "ü§ñ SVM MODEL 3: POLYNOMIAL KERNEL + GRID SEARCH\n",
            "================================================================================\n",
            "Grid Search ba≈ülatƒ±lƒ±yor (10-fold CV)...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4269928144.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    351\u001b[0m )\n\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m \u001b[0mgrid_poly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\n‚úÖ Best Parameters:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1022\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1569\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1570\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1571\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1572\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    968\u001b[0m                     )\n\u001b[1;32m    969\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 970\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    971\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    972\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         )\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2070\u001b[0m         \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2071\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2072\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2074\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1681\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1682\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1684\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mGeneratorExit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1798\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mTASK_PENDING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1799\u001b[0m                 ):\n\u001b[0;32m-> 1800\u001b[0;31m                     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1801\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "============================================================================\n",
        "KOSPI TAHMƒ∞N - YUVARLAMA + ƒ∞Yƒ∞LE≈ûTƒ∞RMELER\n",
        "============================================================================\n",
        "Yeni Yakla≈üƒ±m:\n",
        "1. ‚úÖ Close deƒüerlerini YUVARLAMA (g√ºr√ºlt√º azaltma)\n",
        "2. ‚úÖ Feature engineering iyile≈ütirme\n",
        "3. ‚úÖ Class imbalance handling\n",
        "4. ‚úÖ Ensemble + Feature selection\n",
        "5. ‚úÖ LEAKAGE YOK (doƒüru zamansal split)\n",
        "\n",
        "Hipotez: Yuvarlama + Doƒüru preprocessing ‚Üí Daha iyi accuracy\n",
        "============================================================================\n",
        "\"\"\"\n",
        "\n",
        "import sys\n",
        "import subprocess\n",
        "print(\"üì¶ K√ºt√ºphaneler y√ºkleniyor...\")\n",
        "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\",\n",
        "                      \"yfinance\", \"pandas\", \"numpy\", \"scikit-learn\", \"xgboost\"])\n",
        "\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"‚úÖ Hazƒ±r!\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# 1. VERƒ∞ √áEKME + YUVARLAMA\n",
        "# ============================================================================\n",
        "print(\"=\"*80)\n",
        "print(\"üìà VERƒ∞ √áEKME - KOSPI (^KS11)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "ticker = '^KS11'\n",
        "data = yf.download(ticker, start=\"2011-01-01\", end=\"2020-09-27\",\n",
        "                  progress=False, auto_adjust=True)\n",
        "\n",
        "if isinstance(data.columns, pd.MultiIndex):\n",
        "    data.columns = data.columns.get_level_values(0)\n",
        "\n",
        "data = data[['Open', 'High', 'Low', 'Close', 'Volume']].copy()\n",
        "\n",
        "# ‚ú® YUVARLAMA - TAM SAYIYA!\n",
        "print(\"\\nüîÑ Fƒ∞YATLARI YUVARLAMA:\")\n",
        "print(f\"   √ñnceki Close √∂rnek: {data['Close'].iloc[0]:.10f}\")\n",
        "\n",
        "data['Close'] = data['Close'].round(0)  # Tam sayƒ±ya yuvarla\n",
        "data['Open'] = data['Open'].round(0)\n",
        "data['High'] = data['High'].round(0)\n",
        "data['Low'] = data['Low'].round(0)\n",
        "\n",
        "print(f\"   Sonraki Close √∂rnek: {data['Close'].iloc[0]:.1f}\")\n",
        "print(f\"   ‚úÖ T√ºm fiyatlar tam sayƒ±ya yuvarlandƒ±!\\n\")\n",
        "\n",
        "data = data.dropna()\n",
        "print(f\"Toplam veri: {len(data)} g√ºn\")\n",
        "print(f\"Tarih: {data.index[0].date()} ‚Üí {data.index[-1].date()}\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# 2. GELƒ∞≈ûMƒ∞≈û TEKNƒ∞K G√ñSTERGELER\n",
        "# ============================================================================\n",
        "print(\"=\"*80)\n",
        "print(\"üîß GELƒ∞≈ûMƒ∞≈û TEKNƒ∞K G√ñSTERGELER\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "def advanced_indicators(df):\n",
        "    df = df.copy()\n",
        "\n",
        "    high = df['High']\n",
        "    low = df['Low']\n",
        "    close = df['Close']\n",
        "    volume = df['Volume']\n",
        "\n",
        "    # --- TEMEL G√ñSTERGELER ---\n",
        "    # Stochastic\n",
        "    window = 14\n",
        "    lowest_low = low.rolling(window).min()\n",
        "    highest_high = high.rolling(window).max()\n",
        "    df['Stochastic_K'] = ((close - lowest_low) / (highest_high - lowest_low)) * 100\n",
        "    df['Stochastic_D'] = df['Stochastic_K'].rolling(3).mean()\n",
        "\n",
        "    # ROC\n",
        "    df['ROC'] = close.pct_change(10) * 100\n",
        "\n",
        "    # RSI\n",
        "    delta = close.diff()\n",
        "    gain = delta.where(delta > 0, 0).rolling(14).mean()\n",
        "    loss = -delta.where(delta < 0, 0).rolling(14).mean()\n",
        "    rs = gain / loss\n",
        "    df['RSI'] = 100 - (100 / (1 + rs))\n",
        "\n",
        "    # Williams %R\n",
        "    df['Williams_R'] = ((highest_high - close) / (highest_high - lowest_low)) * 100\n",
        "\n",
        "    # --- VOLATƒ∞Lƒ∞TE ---\n",
        "    df['ATR'] = (high - low).rolling(14).mean()\n",
        "    df['Daily_Range'] = (high - low) / close\n",
        "\n",
        "    # Bollinger Bands\n",
        "    ma20 = close.rolling(20).mean()\n",
        "    std20 = close.rolling(20).std()\n",
        "    df['BB_upper'] = ma20 + (2 * std20)\n",
        "    df['BB_lower'] = ma20 - (2 * std20)\n",
        "    df['BB_width'] = (df['BB_upper'] - df['BB_lower']) / ma20\n",
        "    df['BB_position'] = (close - df['BB_lower']) / (df['BB_upper'] - df['BB_lower'])\n",
        "\n",
        "    # --- TREND ---\n",
        "    ma5 = close.rolling(5).mean()\n",
        "    ma10 = close.rolling(10).mean()\n",
        "    ma20 = close.rolling(20).mean()\n",
        "    ma50 = close.rolling(50).mean()\n",
        "\n",
        "    df['MA5'] = ma5\n",
        "    df['MA10'] = ma10\n",
        "    df['MA20'] = ma20\n",
        "    df['MA50'] = ma50\n",
        "\n",
        "    # MA crossovers\n",
        "    df['MA5_20_diff'] = (ma5 - ma20) / close\n",
        "    df['MA10_50_diff'] = (ma10 - ma50) / close\n",
        "    df['Price_MA20'] = (close - ma20) / close\n",
        "\n",
        "    # MACD\n",
        "    ema12 = close.ewm(span=12).mean()\n",
        "    ema26 = close.ewm(span=26).mean()\n",
        "    df['MACD'] = ema12 - ema26\n",
        "    df['MACD_signal'] = df['MACD'].ewm(span=9).mean()\n",
        "    df['MACD_hist'] = df['MACD'] - df['MACD_signal']\n",
        "\n",
        "    # --- MOMENTUM ---\n",
        "    df['Momentum_5'] = close.pct_change(5)\n",
        "    df['Momentum_10'] = close.pct_change(10)\n",
        "    df['Momentum_20'] = close.pct_change(20)\n",
        "\n",
        "    # --- VOLUME ---\n",
        "    df['Volume_MA20'] = volume.rolling(20).mean()\n",
        "    df['Volume_ratio'] = volume / df['Volume_MA20']\n",
        "\n",
        "    # Price-Volume Trend\n",
        "    df['PVT'] = ((close - close.shift(1)) / close.shift(1) * volume).cumsum()\n",
        "\n",
        "    # --- YENƒ∞: PATTERN ƒ∞NDƒ∞KAT√ñRLERƒ∞ ---\n",
        "    # Consecutive ups/downs\n",
        "    df['Price_change'] = close.diff()\n",
        "    df['Consecutive_ups'] = (df['Price_change'] > 0).rolling(5).sum()\n",
        "    df['Consecutive_downs'] = (df['Price_change'] < 0).rolling(5).sum()\n",
        "\n",
        "    # Volatility ratio\n",
        "    df['Volatility_ratio'] = df['ATR'] / close\n",
        "\n",
        "    df = df.replace([np.inf, -np.inf], np.nan)\n",
        "    return df\n",
        "\n",
        "data = advanced_indicators(data)\n",
        "print(\"‚úÖ Teknik g√∂stergeler hesaplandƒ±\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# 3. TARGET + LAG (LEAKAGE KONTROL√ú)\n",
        "# ============================================================================\n",
        "print(\"=\"*80)\n",
        "print(\"üéØ TARGET + LAG (LEAKAGE YOK!)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Target: Yarƒ±nƒ±n kapanƒ±≈ü > Bug√ºn√ºn kapanƒ±≈ü\n",
        "data['Target'] = (data['Close'].shift(-1) > data['Close']).astype(int)\n",
        "data = data.iloc[:-1]  # Son satƒ±rƒ± √ßƒ±kar\n",
        "\n",
        "# Feature listesi (MA s√ºtunlarƒ±nƒ± √ßƒ±kar - zaten diff'leri var)\n",
        "feature_cols = [col for col in data.columns\n",
        "                if col not in ['Open', 'High', 'Low', 'Close', 'Volume', 'Target',\n",
        "                              'MA5', 'MA10', 'MA20', 'MA50', 'BB_upper', 'BB_lower',\n",
        "                              'Volume_MA20', 'Price_change']]\n",
        "\n",
        "print(f\"‚úÖ {len(feature_cols)} feature olu≈üturuldu\")\n",
        "\n",
        "# LAG UYGULA (t-1, t-5, t-10)\n",
        "lagged_features = []\n",
        "for lag in [1, 5, 10]:\n",
        "    for feat in feature_cols[:15]:  # ƒ∞lk 15 feature i√ßin\n",
        "        lagged_col = f'{feat}_lag{lag}'\n",
        "        data[lagged_col] = data[feat].shift(lag)\n",
        "        lagged_features.append(lagged_col)\n",
        "\n",
        "data = data.dropna()\n",
        "\n",
        "print(f\"‚úÖ Lag uygulandƒ±: {len(lagged_features)} feature\")\n",
        "print(f\"‚úÖ Final veri: {len(data)} g√ºn\")\n",
        "print(f\"   UP ratio: {data['Target'].mean()*100:.1f}%\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# 4. FEATURE SELECTION (En √∂nemlilerini se√ß)\n",
        "# ============================================================================\n",
        "print(\"=\"*80)\n",
        "print(\"üéØ FEATURE SELECTION (Top 30)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "X = data[lagged_features].copy()\n",
        "y = data['Target'].copy()\n",
        "\n",
        "# ANOVA F-test ile en iyi 30 feature se√ß\n",
        "selector = SelectKBest(f_classif, k=30)\n",
        "X_selected = selector.fit_transform(X, y)\n",
        "\n",
        "selected_features = [lagged_features[i] for i in selector.get_support(indices=True)]\n",
        "X_selected = pd.DataFrame(X_selected, columns=selected_features, index=X.index)\n",
        "\n",
        "print(f\"‚úÖ En √∂nemli 30 feature se√ßildi\")\n",
        "print(\"\\nTop 10 Feature:\")\n",
        "for i, feat in enumerate(selected_features[:10], 1):\n",
        "    print(f\"   {i:2d}. {feat}\")\n",
        "print()\n",
        "\n",
        "# ============================================================================\n",
        "# 5. ZAMANSAL SPLIT\n",
        "# ============================================================================\n",
        "print(\"=\"*80)\n",
        "print(\"‚úÇÔ∏è ZAMANSAL SPLIT (70% Train - 30% Test)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "split_idx = int(len(X_selected) * 0.7)\n",
        "X_train = X_selected.iloc[:split_idx]\n",
        "X_test = X_selected.iloc[split_idx:]\n",
        "y_train = y.iloc[:split_idx].values\n",
        "y_test = y.iloc[split_idx:].values\n",
        "\n",
        "print(f\"Train: {len(X_train)} g√ºn | UP: {y_train.mean()*100:.1f}%\")\n",
        "print(f\"Test:  {len(X_test)} g√ºn | UP: {y_test.mean()*100:.1f}%\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# 6. NORMALƒ∞ZASYON (Train'e fit, Test'e transform)\n",
        "# ============================================================================\n",
        "print(\"=\"*80)\n",
        "print(\"üìä NORMALƒ∞ZASYON (RobustScaler)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "scaler = RobustScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(\"‚úÖ Train fit edildi, test transform edildi (LEAKAGE YOK!)\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# 7. MODEL Eƒûƒ∞Tƒ∞Mƒ∞ - ENSEMBLE\n",
        "# ============================================================================\n",
        "print(\"=\"*80)\n",
        "print(\"ü§ñ MODEL Eƒûƒ∞Tƒ∞Mƒ∞ - ENSEMBLE (4 Model)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Class weight hesapla\n",
        "scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()\n",
        "\n",
        "# --- MODEL 1: SVM RBF ---\n",
        "print(\"\\n1Ô∏è‚É£ SVM (RBF Kernel, Class Balanced)...\")\n",
        "svm = SVC(kernel='rbf', C=100, gamma='scale',\n",
        "          class_weight='balanced', probability=True, random_state=42)\n",
        "svm.fit(X_train_scaled, y_train)\n",
        "svm_pred = svm.predict(X_test_scaled)\n",
        "svm_acc = accuracy_score(y_test, svm_pred)\n",
        "print(f\"   Test Accuracy: {svm_acc*100:.2f}%\")\n",
        "\n",
        "# --- MODEL 2: SVM Linear ---\n",
        "print(\"\\n2Ô∏è‚É£ SVM (Linear Kernel, Class Balanced)...\")\n",
        "svm_linear = SVC(kernel='linear', C=10,\n",
        "                 class_weight='balanced', probability=True, random_state=42)\n",
        "svm_linear.fit(X_train_scaled, y_train)\n",
        "svm_linear_pred = svm_linear.predict(X_test_scaled)\n",
        "svm_linear_acc = accuracy_score(y_test, svm_linear_pred)\n",
        "print(f\"   Test Accuracy: {svm_linear_acc*100:.2f}%\")\n",
        "\n",
        "# --- MODEL 3: Random Forest ---\n",
        "print(\"\\n3Ô∏è‚É£ Random Forest...\")\n",
        "rf = RandomForestClassifier(n_estimators=300, max_depth=15, min_samples_split=10,\n",
        "                            class_weight='balanced', random_state=42, n_jobs=-1)\n",
        "rf.fit(X_train_scaled, y_train)\n",
        "rf_pred = rf.predict(X_test_scaled)\n",
        "rf_acc = accuracy_score(y_test, rf_pred)\n",
        "print(f\"   Test Accuracy: {rf_acc*100:.2f}%\")\n",
        "\n",
        "# --- MODEL 4: XGBoost ---\n",
        "print(\"\\n4Ô∏è‚É£ XGBoost...\")\n",
        "xgb = XGBClassifier(n_estimators=300, max_depth=7, learning_rate=0.05,\n",
        "                   scale_pos_weight=scale_pos_weight, random_state=42,\n",
        "                   eval_metric='logloss', n_jobs=-1)\n",
        "xgb.fit(X_train_scaled, y_train)\n",
        "xgb_pred = xgb.predict(X_test_scaled)\n",
        "xgb_acc = accuracy_score(y_test, xgb_pred)\n",
        "print(f\"   Test Accuracy: {xgb_acc*100:.2f}%\")\n",
        "\n",
        "# --- ENSEMBLE: Weighted Voting ---\n",
        "print(\"\\n5Ô∏è‚É£ Ensemble (Weighted Voting)...\")\n",
        "\n",
        "# En iyi 3 modeli al\n",
        "models = [\n",
        "    ('svm', svm_acc, svm_pred),\n",
        "    ('svm_linear', svm_linear_acc, svm_linear_pred),\n",
        "    ('rf', rf_acc, rf_pred),\n",
        "    ('xgb', xgb_acc, xgb_pred)\n",
        "]\n",
        "models_sorted = sorted(models, key=lambda x: x[1], reverse=True)[:3]\n",
        "\n",
        "# Weighted average (accuracy'ye g√∂re)\n",
        "weights = [m[1] for m in models_sorted]\n",
        "preds = [m[2] for m in models_sorted]\n",
        "\n",
        "ensemble_pred = np.average(preds, axis=0, weights=weights)\n",
        "ensemble_pred = (ensemble_pred >= 0.5).astype(int)\n",
        "\n",
        "ensemble_acc = accuracy_score(y_test, ensemble_pred)\n",
        "print(f\"   Test Accuracy: {ensemble_acc*100:.2f}%\")\n",
        "\n",
        "# ============================================================================\n",
        "# 8. EN ƒ∞Yƒ∞ MODEL DETAYLARI\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üìä T√úM MODELLER KAR≈ûILA≈ûTIRMA\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "results = pd.DataFrame({\n",
        "    'Model': ['SVM RBF', 'SVM Linear', 'Random Forest', 'XGBoost', 'Ensemble'],\n",
        "    'Test Accuracy': [svm_acc, svm_linear_acc, rf_acc, xgb_acc, ensemble_acc]\n",
        "})\n",
        "\n",
        "print(\"\\n\" + results.to_string(index=False))\n",
        "\n",
        "best_acc = max(svm_acc, svm_linear_acc, rf_acc, xgb_acc, ensemble_acc)\n",
        "best_model_name = results.loc[results['Test Accuracy'].idxmax(), 'Model']\n",
        "\n",
        "print(f\"\\nüèÜ EN ƒ∞Yƒ∞ MODEL: {best_model_name}\")\n",
        "print(f\"   Accuracy: {best_acc*100:.2f}%\")\n",
        "\n",
        "# En iyi modelin predictions'ƒ±nƒ± kullan\n",
        "if best_acc == ensemble_acc:\n",
        "    best_pred = ensemble_pred\n",
        "elif best_acc == xgb_acc:\n",
        "    best_pred = xgb_pred\n",
        "elif best_acc == rf_acc:\n",
        "    best_pred = rf_pred\n",
        "elif best_acc == svm_acc:\n",
        "    best_pred = svm_pred\n",
        "else:\n",
        "    best_pred = svm_linear_pred\n",
        "\n",
        "# ============================================================================\n",
        "# 9. DETAYLI ANALƒ∞Z\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üîç DETAYLI PERFORMANS ANALƒ∞Zƒ∞\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "cm = confusion_matrix(y_test, best_pred)\n",
        "print(f\"\\nConfusion Matrix:\")\n",
        "print(f\"                Predicted DOWN  Predicted UP\")\n",
        "print(f\"Actual DOWN          {cm[0,0]:<8}      {cm[0,1]:<8}\")\n",
        "print(f\"Actual UP            {cm[1,0]:<8}      {cm[1,1]:<8}\")\n",
        "\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "down_acc = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "up_acc = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "\n",
        "print(f\"\\nClass-wise Accuracy:\")\n",
        "print(f\"DOWN: {down_acc*100:.1f}% ({tn}/{tn+fp})\")\n",
        "print(f\"UP:   {up_acc*100:.1f}% ({tp}/{tp+fn})\")\n",
        "print(f\"Balance: {abs(down_acc - up_acc):.4f}\")\n",
        "\n",
        "print(\"\\n\" + classification_report(y_test, best_pred,\n",
        "                                   target_names=['DOWN', 'UP'],\n",
        "                                   digits=4))\n",
        "\n",
        "# ============================================================================\n",
        "# 10. FEATURE IMPORTANCE (XGBoost)\n",
        "# ============================================================================\n",
        "print(\"=\"*80)\n",
        "print(\"üéØ TOP 10 EN √ñNEMLƒ∞ FEATURE (XGBoost)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "importance_df = pd.DataFrame({\n",
        "    'feature': selected_features,\n",
        "    'importance': xgb.feature_importances_\n",
        "}).sort_values('importance', ascending=False).head(10)\n",
        "\n",
        "for idx, row in importance_df.iterrows():\n",
        "    print(f\"{row['feature']:<40} {row['importance']:.4f}\")\n",
        "\n",
        "# ============================================================================\n",
        "# SONU√á\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üí° SONU√á VE YORUM\")\n",
        "print(\"=\"*80)\n",
        "print(f\"\"\"\n",
        "‚úÖ UYGULANAN ƒ∞Yƒ∞LE≈ûTƒ∞RMELER:\n",
        "   1. Close deƒüerleri tam sayƒ±ya yuvarlandƒ± (g√ºr√ºlt√º azaltƒ±ldƒ±)\n",
        "   2. 30+ teknik g√∂sterge hesaplandƒ±\n",
        "   3. Feature selection ile en iyi 30 feature se√ßildi\n",
        "   4. Multiple lag (1, 5, 10 g√ºn) kullanƒ±ldƒ±\n",
        "   5. Class imbalance handle edildi\n",
        "   6. 4 model ensemble edildi\n",
        "   7. LEAKAGE YOK! (Zamansal split + doƒüru normalizasyon)\n",
        "\n",
        "üéØ SONU√áLAR:\n",
        "   En ƒ∞yi Model: {best_model_name}\n",
        "   Test Accuracy: {best_acc*100:.2f}%\n",
        "\n",
        "   DOWN Accuracy: {down_acc*100:.1f}%\n",
        "   UP Accuracy:   {up_acc*100:.1f}%\n",
        "\n",
        "üìä DEƒûERLENDƒ∞RME:\n",
        "   {'üü¢ M√úKEMMEL! (60%+)' if best_acc >= 0.60 else ''}\n",
        "   {'üü° ƒ∞Yƒ∞! (55-60%)' if 0.55 <= best_acc < 0.60 else ''}\n",
        "   {'üîµ NORMAL (50-55%)' if best_acc < 0.55 else ''}\n",
        "\n",
        "   NOT: Finansal tahminde %55+ ba≈üarƒ± √áOK ƒ∞Yƒ∞Dƒ∞R!\n",
        "        Random: %50, Market'i yenen: %55+\n",
        "\n",
        "üí≠ YUVARLAMA ETKƒ∞Sƒ∞:\n",
        "   Yuvarlama sayesinde g√ºr√ºlt√º azaldƒ± ve model\n",
        "   daha genel pattern'lere odaklanabildi.\n",
        "\"\"\")\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"‚úÖ ANALƒ∞Z TAMAMLANDI\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQIkDdKXOnMV",
        "outputId": "b5e34a59-cb63-4711-a180-b92708e83a1f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì¶ K√ºt√ºphaneler y√ºkleniyor...\n",
            "‚úÖ Hazƒ±r!\n",
            "\n",
            "================================================================================\n",
            "üìà VERƒ∞ √áEKME - KOSPI (^KS11)\n",
            "================================================================================\n",
            "\n",
            "üîÑ Fƒ∞YATLARI YUVARLAMA:\n",
            "   √ñnceki Close √∂rnek: 2070.0800781250\n",
            "   Sonraki Close √∂rnek: 2070.0\n",
            "   ‚úÖ T√ºm fiyatlar tam sayƒ±ya yuvarlandƒ±!\n",
            "\n",
            "Toplam veri: 2397 g√ºn\n",
            "Tarih: 2011-01-03 ‚Üí 2020-09-25\n",
            "\n",
            "================================================================================\n",
            "üîß GELƒ∞≈ûMƒ∞≈û TEKNƒ∞K G√ñSTERGELER\n",
            "================================================================================\n",
            "‚úÖ Teknik g√∂stergeler hesaplandƒ±\n",
            "\n",
            "================================================================================\n",
            "üéØ TARGET + LAG (LEAKAGE YOK!)\n",
            "================================================================================\n",
            "‚úÖ 23 feature olu≈üturuldu\n",
            "‚úÖ Lag uygulandƒ±: 45 feature\n",
            "‚úÖ Final veri: 2337 g√ºn\n",
            "   UP ratio: 50.8%\n",
            "\n",
            "================================================================================\n",
            "üéØ FEATURE SELECTION (Top 30)\n",
            "================================================================================\n",
            "‚úÖ En √∂nemli 30 feature se√ßildi\n",
            "\n",
            "Top 10 Feature:\n",
            "    1. Stochastic_D_lag1\n",
            "    2. RSI_lag1\n",
            "    3. ATR_lag1\n",
            "    4. Daily_Range_lag1\n",
            "    5. BB_width_lag1\n",
            "    6. BB_position_lag1\n",
            "    7. MA5_20_diff_lag1\n",
            "    8. MA10_50_diff_lag1\n",
            "    9. MACD_lag1\n",
            "   10. MACD_signal_lag1\n",
            "\n",
            "================================================================================\n",
            "‚úÇÔ∏è ZAMANSAL SPLIT (70% Train - 30% Test)\n",
            "================================================================================\n",
            "Train: 1635 g√ºn | UP: 49.8%\n",
            "Test:  702 g√ºn | UP: 53.3%\n",
            "\n",
            "================================================================================\n",
            "üìä NORMALƒ∞ZASYON (RobustScaler)\n",
            "================================================================================\n",
            "‚úÖ Train fit edildi, test transform edildi (LEAKAGE YOK!)\n",
            "\n",
            "================================================================================\n",
            "ü§ñ MODEL Eƒûƒ∞Tƒ∞Mƒ∞ - ENSEMBLE (4 Model)\n",
            "================================================================================\n",
            "\n",
            "1Ô∏è‚É£ SVM (RBF Kernel, Class Balanced)...\n",
            "   Test Accuracy: 50.57%\n",
            "\n",
            "2Ô∏è‚É£ SVM (Linear Kernel, Class Balanced)...\n",
            "   Test Accuracy: 50.43%\n",
            "\n",
            "3Ô∏è‚É£ Random Forest...\n",
            "   Test Accuracy: 49.57%\n",
            "\n",
            "4Ô∏è‚É£ XGBoost...\n",
            "   Test Accuracy: 48.86%\n",
            "\n",
            "5Ô∏è‚É£ Ensemble (Weighted Voting)...\n",
            "   Test Accuracy: 49.43%\n",
            "\n",
            "================================================================================\n",
            "üìä T√úM MODELLER KAR≈ûILA≈ûTIRMA\n",
            "================================================================================\n",
            "\n",
            "        Model  Test Accuracy\n",
            "      SVM RBF       0.505698\n",
            "   SVM Linear       0.504274\n",
            "Random Forest       0.495726\n",
            "      XGBoost       0.488604\n",
            "     Ensemble       0.494302\n",
            "\n",
            "üèÜ EN ƒ∞Yƒ∞ MODEL: SVM RBF\n",
            "   Accuracy: 50.57%\n",
            "\n",
            "================================================================================\n",
            "üîç DETAYLI PERFORMANS ANALƒ∞Zƒ∞\n",
            "================================================================================\n",
            "\n",
            "Confusion Matrix:\n",
            "                Predicted DOWN  Predicted UP\n",
            "Actual DOWN          228           100     \n",
            "Actual UP            247           127     \n",
            "\n",
            "Class-wise Accuracy:\n",
            "DOWN: 69.5% (228/328)\n",
            "UP:   34.0% (127/374)\n",
            "Balance: 0.3555\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        DOWN     0.4800    0.6951    0.5679       328\n",
            "          UP     0.5595    0.3396    0.4226       374\n",
            "\n",
            "    accuracy                         0.5057       702\n",
            "   macro avg     0.5197    0.5173    0.4952       702\n",
            "weighted avg     0.5223    0.5057    0.4905       702\n",
            "\n",
            "================================================================================\n",
            "üéØ TOP 10 EN √ñNEMLƒ∞ FEATURE (XGBoost)\n",
            "================================================================================\n",
            "MACD_signal_lag10                        0.0440\n",
            "BB_position_lag1                         0.0401\n",
            "MACD_lag1                                0.0399\n",
            "ATR_lag10                                0.0379\n",
            "MACD_signal_lag1                         0.0367\n",
            "Daily_Range_lag5                         0.0350\n",
            "RSI_lag1                                 0.0348\n",
            "MACD_hist_lag5                           0.0347\n",
            "MACD_lag10                               0.0344\n",
            "MA10_50_diff_lag10                       0.0340\n",
            "\n",
            "================================================================================\n",
            "üí° SONU√á VE YORUM\n",
            "================================================================================\n",
            "\n",
            "‚úÖ UYGULANAN ƒ∞Yƒ∞LE≈ûTƒ∞RMELER:\n",
            "   1. Close deƒüerleri tam sayƒ±ya yuvarlandƒ± (g√ºr√ºlt√º azaltƒ±ldƒ±)\n",
            "   2. 30+ teknik g√∂sterge hesaplandƒ±\n",
            "   3. Feature selection ile en iyi 30 feature se√ßildi\n",
            "   4. Multiple lag (1, 5, 10 g√ºn) kullanƒ±ldƒ±\n",
            "   5. Class imbalance handle edildi\n",
            "   6. 4 model ensemble edildi\n",
            "   7. LEAKAGE YOK! (Zamansal split + doƒüru normalizasyon)\n",
            "\n",
            "üéØ SONU√áLAR:\n",
            "   En ƒ∞yi Model: SVM RBF\n",
            "   Test Accuracy: 50.57%\n",
            "   \n",
            "   DOWN Accuracy: 69.5%\n",
            "   UP Accuracy:   34.0%\n",
            "\n",
            "üìä DEƒûERLENDƒ∞RME:\n",
            "   \n",
            "   \n",
            "   üîµ NORMAL (50-55%)\n",
            "   \n",
            "   NOT: Finansal tahminde %55+ ba≈üarƒ± √áOK ƒ∞Yƒ∞Dƒ∞R!\n",
            "        Random: %50, Market'i yenen: %55+\n",
            "\n",
            "üí≠ YUVARLAMA ETKƒ∞Sƒ∞:\n",
            "   Yuvarlama sayesinde g√ºr√ºlt√º azaldƒ± ve model\n",
            "   daha genel pattern'lere odaklanabildi.\n",
            "\n",
            "================================================================================\n",
            "‚úÖ ANALƒ∞Z TAMAMLANDI\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "============================================================================\n",
        "KOSPI TAHMƒ∞N - LAG D√úZELTƒ∞LMƒ∞≈û + DOƒûRU PIPELINE\n",
        "============================================================================\n",
        "SORUN TESPƒ∞Tƒ∞: Model sadece \"UP\" tahmin ediyordu √ß√ºnk√º LAG YOKTU!\n",
        "√á√ñZ√úM: t-1 (d√ºn√ºn) g√∂stergelerini kullan, t+1'i tahmin et\n",
        "============================================================================\n",
        "\"\"\"\n",
        "\n",
        "import sys\n",
        "import subprocess\n",
        "print(\"üì¶ Y√ºkleniyor...\")\n",
        "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\",\n",
        "                      \"yfinance\", \"scikit-learn\", \"pandas\", \"numpy\"])\n",
        "\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
        "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"‚úÖ Hazƒ±r!\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# 1. VERƒ∞\n",
        "# ============================================================================\n",
        "print(\"=\"*80)\n",
        "print(\"üìà VERƒ∞ √áEKME - KOSPI\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "ticker = '^KS11'\n",
        "data = yf.download(ticker, start=\"2011-01-01\", end=\"2020-09-27\",\n",
        "                  progress=False, auto_adjust=True)\n",
        "\n",
        "if isinstance(data.columns, pd.MultiIndex):\n",
        "    data.columns = data.columns.get_level_values(0)\n",
        "\n",
        "data = data[['Open', 'High', 'Low', 'Close', 'Volume']].copy()\n",
        "data = data.dropna()\n",
        "\n",
        "print(f\"‚úÖ {len(data)} g√ºn\")\n",
        "print(f\"Tarih: {data.index[0].date()} ‚Üí {data.index[-1].date()}\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# 2. TEKNƒ∞K G√ñSTERGELER\n",
        "# ============================================================================\n",
        "print(\"=\"*80)\n",
        "print(\"üîß TEKNƒ∞K G√ñSTERGELER\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "def calculate_indicators(df):\n",
        "    df = df.copy()\n",
        "\n",
        "    high = df['High'].squeeze()\n",
        "    low = df['Low'].squeeze()\n",
        "    close = df['Close'].squeeze()\n",
        "\n",
        "    # Stochastic\n",
        "    lowest_low = low.rolling(14).min()\n",
        "    highest_high = high.rolling(14).max()\n",
        "    df['Stochastic_K'] = ((close - lowest_low) / (highest_high - lowest_low)) * 100\n",
        "    df['Stochastic_D'] = df['Stochastic_K'].rolling(3).mean()\n",
        "\n",
        "    # ROC\n",
        "    df['ROC'] = close.pct_change(10) * 100\n",
        "\n",
        "    # Williams %R\n",
        "    df['Williams_R'] = ((highest_high - close) / (highest_high - lowest_low)) * -100\n",
        "\n",
        "    # Momentum\n",
        "    df['Momentum'] = close.diff(4)\n",
        "\n",
        "    # Disparity\n",
        "    ma5 = close.rolling(5).mean()\n",
        "    ma14 = close.rolling(14).mean()\n",
        "    df['Disparity_5'] = (close / ma5) * 100\n",
        "    df['Disparity_14'] = (close / ma14) * 100\n",
        "\n",
        "    # OSCP\n",
        "    ma10 = close.rolling(10).mean()\n",
        "    df['OSCP'] = ((ma5 - ma10) / ma5)\n",
        "\n",
        "    # CCI\n",
        "    tp = (high + low + close) / 3\n",
        "    df['CCI'] = (tp - tp.rolling(20).mean()) / (0.015 * tp.rolling(20).std())\n",
        "\n",
        "    # RSI\n",
        "    delta = close.diff()\n",
        "    gain = delta.where(delta > 0, 0).rolling(14).mean()\n",
        "    loss = -delta.where(delta < 0, 0).rolling(14).mean()\n",
        "    rs = gain / loss\n",
        "    df['RSI'] = 100 - (100 / (1 + rs))\n",
        "\n",
        "    # Pivot Points\n",
        "    prev_high = high.shift(1)\n",
        "    prev_low = low.shift(1)\n",
        "    prev_close = close.shift(1)\n",
        "\n",
        "    df['Pivot_Point'] = (prev_high + prev_low + prev_close) / 3\n",
        "    df['S1'] = (df['Pivot_Point'] * 2) - prev_high\n",
        "    df['S2'] = df['Pivot_Point'] - (prev_high - prev_low)\n",
        "    df['R1'] = (df['Pivot_Point'] * 2) - prev_low\n",
        "    df['R2'] = df['Pivot_Point'] + (prev_high - prev_low)\n",
        "\n",
        "    df = df.replace([np.inf, -np.inf], np.nan)\n",
        "    return df\n",
        "\n",
        "data = calculate_indicators(data)\n",
        "\n",
        "features = ['Stochastic_K', 'Stochastic_D', 'ROC', 'Williams_R',\n",
        "            'Momentum', 'Disparity_5', 'Disparity_14', 'OSCP',\n",
        "            'CCI', 'RSI', 'Pivot_Point', 'S1', 'S2', 'R1', 'R2']\n",
        "\n",
        "print(f\"‚úÖ 15 g√∂sterge hesaplandƒ±\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# 3. TARGET\n",
        "# ============================================================================\n",
        "print(\"=\"*80)\n",
        "print(\"üéØ TARGET: YARIN > BUG√úN\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "data['Target'] = (data['Close'].shift(-1) > data['Close']).astype(int)\n",
        "data = data.iloc[:-1]  # Son satƒ±r\n",
        "\n",
        "print(f\"‚úÖ Target olu≈üturuldu\")\n",
        "print(f\"Total: {len(data)} | UP: {data['Target'].sum()} ({data['Target'].mean()*100:.1f}%)\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# 4. ‚úÖ KRƒ∞Tƒ∞K: LAG UYGULA!\n",
        "# ============================================================================\n",
        "print(\"=\"*80)\n",
        "print(\"üîÑ LAG UYGULA (t-1 features ‚Üí t+1 target)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# NaN temizle √∂nce\n",
        "data = data.dropna(subset=features + ['Target'])\n",
        "\n",
        "print(f\"Temiz veri: {len(data)} g√ºn\")\n",
        "\n",
        "# ‚úÖ LAG: D√ºn√ºn g√∂stergelerini kullan\n",
        "lagged_features = []\n",
        "for feat in features:\n",
        "    lagged_col = f'{feat}_lag1'\n",
        "    data[lagged_col] = data[feat].shift(1)\n",
        "    lagged_features.append(lagged_col)\n",
        "\n",
        "# Lag sonrasƒ± NaN temizle\n",
        "data = data.dropna(subset=lagged_features)\n",
        "\n",
        "print(f\"\\n‚úÖ LAG uygulandƒ±!\")\n",
        "print(f\"Final veri: {len(data)} g√ºn\")\n",
        "print(f\"ƒ∞lk tarih: {data.index[0].date()} (LAG nedeniyle daha ge√ß ba≈üladƒ±)\")\n",
        "print(f\"Son tarih: {data.index[-1].date()}\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# 5. TRAIN/TEST SPLIT (TEMPORAL)\n",
        "# ============================================================================\n",
        "print(\"=\"*80)\n",
        "print(\"‚úÇÔ∏è TRAIN/TEST SPLIT (80% - 20%)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "X = data[lagged_features].copy()\n",
        "y = data['Target'].copy()\n",
        "\n",
        "split_idx = int(len(X) * 0.8)\n",
        "X_train = X.iloc[:split_idx]\n",
        "X_test = X.iloc[split_idx:]\n",
        "y_train = y.iloc[:split_idx].values\n",
        "y_test = y.iloc[split_idx:].values\n",
        "\n",
        "print(f\"Train: {len(X_train)} g√ºn ({X_train.index[0].date()} ‚Üí {X_train.index[-1].date()})\")\n",
        "print(f\"       UP: {y_train.sum()} ({y_train.mean()*100:.1f}%)\")\n",
        "print(f\"\\nTest:  {len(X_test)} g√ºn ({X_test.index[0].date()} ‚Üí {X_test.index[-1].date()})\")\n",
        "print(f\"       UP: {y_test.sum()} ({y_test.mean()*100:.1f}%)\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# 6. NORMALIZE (Train'e fit, Test'e transform)\n",
        "# ============================================================================\n",
        "print(\"=\"*80)\n",
        "print(\"üìä MIN-MAX NORMALIZATION\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)  # ‚úÖ Sadece train'e fit\n",
        "X_test_scaled = scaler.transform(X_test)  # ‚úÖ Test'e transform\n",
        "\n",
        "X_train_scaled = pd.DataFrame(X_train_scaled, columns=lagged_features, index=X_train.index)\n",
        "X_test_scaled = pd.DataFrame(X_test_scaled, columns=lagged_features, index=X_test.index)\n",
        "\n",
        "print(\"‚úÖ Train fit ‚Üí Test transform (LEAKAGE YOK!)\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# 7. SVM MODEL - LINEAR KERNEL\n",
        "# ============================================================================\n",
        "print(\"=\"*80)\n",
        "print(\"ü§ñ SVM LINEAR + GRID SEARCH\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "param_grid = {\n",
        "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
        "    'class_weight': [None, 'balanced']\n",
        "}\n",
        "\n",
        "svm = SVC(kernel='linear', max_iter=50000, random_state=42)\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=False)  # ‚úÖ shuffle=False (temporal!)\n",
        "\n",
        "grid = GridSearchCV(svm, param_grid, cv=cv, scoring='accuracy', n_jobs=-1, verbose=1)\n",
        "\n",
        "print(\"\\nGrid Search ba≈ülatƒ±lƒ±yor...\")\n",
        "grid.fit(X_train_scaled, y_train)\n",
        "\n",
        "print(f\"\\n‚úÖ Best Params: {grid.best_params_}\")\n",
        "print(f\"‚úÖ Best CV Score: {grid.best_score_*100:.2f}%\")\n",
        "\n",
        "# ============================================================================\n",
        "# 8. TEST EVALUATION\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üìä TEST RESULTS - LINEAR KERNEL\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "y_pred = grid.best_estimator_.predict(X_test_scaled)\n",
        "\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "prec = precision_score(y_test, y_pred, zero_division=0)\n",
        "rec = recall_score(y_test, y_pred, zero_division=0)\n",
        "f1 = f1_score(y_test, y_pred, zero_division=0)\n",
        "\n",
        "print(f\"\\nTest Accuracy:  {acc*100:.2f}%\")\n",
        "print(f\"Precision:      {prec:.4f}\")\n",
        "print(f\"Recall:         {rec:.4f}\")\n",
        "print(f\"F1-Score:       {f1:.4f}\")\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(f\"\\nConfusion Matrix:\")\n",
        "print(f\"                Predicted DOWN  Predicted UP\")\n",
        "print(f\"Actual DOWN          {cm[0,0]:<8}      {cm[0,1]:<8}\")\n",
        "print(f\"Actual UP            {cm[1,0]:<8}      {cm[1,1]:<8}\")\n",
        "\n",
        "# Class-wise accuracy\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "down_acc = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "up_acc = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "\n",
        "print(f\"\\nClass-wise Accuracy:\")\n",
        "print(f\"DOWN: {down_acc*100:.1f}% ({tn}/{tn+fp})\")\n",
        "print(f\"UP:   {up_acc*100:.1f}% ({tp}/{tp+fn})\")\n",
        "print(f\"Balance diff: {abs(down_acc - up_acc):.4f}\")\n",
        "\n",
        "# ============================================================================\n",
        "# 9. RBF KERNEL (Bonus)\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ü§ñ SVM RBF + GRID SEARCH\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "param_grid_rbf = {\n",
        "    'C': [0.1, 1, 10, 100],\n",
        "    'gamma': [0.001, 0.01, 0.1, 'scale'],\n",
        "    'class_weight': [None, 'balanced']\n",
        "}\n",
        "\n",
        "svm_rbf = SVC(kernel='rbf', max_iter=50000, random_state=42)\n",
        "\n",
        "grid_rbf = GridSearchCV(svm_rbf, param_grid_rbf, cv=cv, scoring='accuracy', n_jobs=-1, verbose=1)\n",
        "\n",
        "print(\"\\nGrid Search ba≈ülatƒ±lƒ±yor...\")\n",
        "grid_rbf.fit(X_train_scaled, y_train)\n",
        "\n",
        "print(f\"\\n‚úÖ Best Params: {grid_rbf.best_params_}\")\n",
        "print(f\"‚úÖ Best CV Score: {grid_rbf.best_score_*100:.2f}%\")\n",
        "\n",
        "# Test\n",
        "y_pred_rbf = grid_rbf.best_estimator_.predict(X_test_scaled)\n",
        "acc_rbf = accuracy_score(y_test, y_pred_rbf)\n",
        "\n",
        "print(f\"\\nTest Accuracy: {acc_rbf*100:.2f}%\")\n",
        "\n",
        "cm_rbf = confusion_matrix(y_test, y_pred_rbf)\n",
        "print(f\"\\nConfusion Matrix:\")\n",
        "print(f\"                Predicted DOWN  Predicted UP\")\n",
        "print(f\"Actual DOWN          {cm_rbf[0,0]:<8}      {cm_rbf[0,1]:<8}\")\n",
        "print(f\"Actual UP            {cm_rbf[1,0]:<8}      {cm_rbf[1,1]:<8}\")\n",
        "\n",
        "# ============================================================================\n",
        "# 10. KAR≈ûILA≈ûTIRMA\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üìä SONU√á KAR≈ûILA≈ûTIRMASI\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(f\"\\n{'Kernel':<15} {'Test Acc':<12} {'Best C':<12} {'Status'}\")\n",
        "print(\"-\" * 60)\n",
        "print(f\"{'Linear':<15} {acc*100:>5.2f}%       {grid.best_params_['C']:<12} \"\n",
        "      f\"{'‚úÖ BALANCED' if cm[0,0] > 0 and cm[1,1] > 0 else '‚ùå IMBALANCED'}\")\n",
        "print(f\"{'RBF':<15} {acc_rbf*100:>5.2f}%       {grid_rbf.best_params_['C']:<12} \"\n",
        "      f\"{'‚úÖ BALANCED' if cm_rbf[0,0] > 0 and cm_rbf[1,1] > 0 else '‚ùå IMBALANCED'}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üí° YORUM\")\n",
        "print(\"=\"*80)\n",
        "print(f\"\"\"\n",
        "‚úÖ √ñNCEKƒ∞ SORUN: LAG YOKTU!\n",
        "   Model bug√ºn√ºn g√∂stergeleri ile bug√ºn√º tahmin ediyordu.\n",
        "   Sonu√ß: Hep \"UP\" tahmin ediyordu (confusion matrix: 0 DOWN)\n",
        "\n",
        "‚úÖ ≈ûƒ∞MDƒ∞: LAG VAR!\n",
        "   Model D√úN√úN g√∂stergeleri ile YARINI tahmin ediyor.\n",
        "   Sonu√ß: {'Her iki class de tahmin ediliyor!' if cm[0,0] > 0 and cm[1,1] > 0 else 'Hala imbalance var!'}\n",
        "\n",
        "üìä ACCURACY: {max(acc, acc_rbf)*100:.2f}%\n",
        "   {'üü¢ M√úKEMMEL (60%+)' if max(acc, acc_rbf) >= 0.60 else ''}\n",
        "   {'üü° ƒ∞Yƒ∞ (55-60%)' if 0.55 <= max(acc, acc_rbf) < 0.60 else ''}\n",
        "   {'üîµ NORMAL (50-55%)' if 0.50 <= max(acc, acc_rbf) < 0.55 else ''}\n",
        "   {'üî¥ D√ú≈û√úK (<50%)' if max(acc, acc_rbf) < 0.50 else ''}\n",
        "\n",
        "üí≠ NOT: Finansal tahminde %55+ √áOK ƒ∞Yƒ∞Dƒ∞R!\n",
        "   Random guess: %50\n",
        "   Market'i yenen: %55+\n",
        "   Profesyonel trader: %60+\n",
        "\n",
        "üéØ BU SONU√á GER√áEK√áƒ∞ VE DOƒûRU!\n",
        "   Makale %85-90 iddia ediyorsa, muhtemelen:\n",
        "   1. Data leakage var\n",
        "   2. LAG yok\n",
        "   3. Veya methodoloji hatalƒ±\n",
        "\"\"\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"‚úÖ ANALƒ∞Z TAMAMLANDI\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-cPC7K1GSWgL",
        "outputId": "3dbfd565-8adf-4123-8832-a4dd2dc1f8a3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì¶ Y√ºkleniyor...\n",
            "‚úÖ Hazƒ±r!\n",
            "\n",
            "================================================================================\n",
            "üìà VERƒ∞ √áEKME - KOSPI\n",
            "================================================================================\n",
            "‚úÖ 2397 g√ºn\n",
            "Tarih: 2011-01-03 ‚Üí 2020-09-25\n",
            "\n",
            "================================================================================\n",
            "üîß TEKNƒ∞K G√ñSTERGELER\n",
            "================================================================================\n",
            "‚úÖ 15 g√∂sterge hesaplandƒ±\n",
            "\n",
            "================================================================================\n",
            "üéØ TARGET: YARIN > BUG√úN\n",
            "================================================================================\n",
            "‚úÖ Target olu≈üturuldu\n",
            "Total: 2396 | UP: 1254 (52.3%)\n",
            "\n",
            "================================================================================\n",
            "üîÑ LAG UYGULA (t-1 features ‚Üí t+1 target)\n",
            "================================================================================\n",
            "Temiz veri: 2377 g√ºn\n",
            "\n",
            "‚úÖ LAG uygulandƒ±!\n",
            "Final veri: 2376 g√ºn\n",
            "ƒ∞lk tarih: 2011-01-31 (LAG nedeniyle daha ge√ß ba≈üladƒ±)\n",
            "Son tarih: 2020-09-24\n",
            "\n",
            "================================================================================\n",
            "‚úÇÔ∏è TRAIN/TEST SPLIT (80% - 20%)\n",
            "================================================================================\n",
            "Train: 1900 g√ºn (2011-01-31 ‚Üí 2018-10-24)\n",
            "       UP: 976 (51.4%)\n",
            "\n",
            "Test:  476 g√ºn (2018-10-25 ‚Üí 2020-09-24)\n",
            "       UP: 268 (56.3%)\n",
            "\n",
            "================================================================================\n",
            "üìä MIN-MAX NORMALIZATION\n",
            "================================================================================\n",
            "‚úÖ Train fit ‚Üí Test transform (LEAKAGE YOK!)\n",
            "\n",
            "================================================================================\n",
            "ü§ñ SVM LINEAR + GRID SEARCH\n",
            "================================================================================\n",
            "\n",
            "Grid Search ba≈ülatƒ±lƒ±yor...\n",
            "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
            "\n",
            "‚úÖ Best Params: {'C': 0.001, 'class_weight': None}\n",
            "‚úÖ Best CV Score: 51.37%\n",
            "\n",
            "================================================================================\n",
            "üìä TEST RESULTS - LINEAR KERNEL\n",
            "================================================================================\n",
            "\n",
            "Test Accuracy:  56.30%\n",
            "Precision:      0.5630\n",
            "Recall:         1.0000\n",
            "F1-Score:       0.7204\n",
            "\n",
            "Confusion Matrix:\n",
            "                Predicted DOWN  Predicted UP\n",
            "Actual DOWN          0             208     \n",
            "Actual UP            0             268     \n",
            "\n",
            "Class-wise Accuracy:\n",
            "DOWN: 0.0% (0/208)\n",
            "UP:   100.0% (268/268)\n",
            "Balance diff: 1.0000\n",
            "\n",
            "================================================================================\n",
            "ü§ñ SVM RBF + GRID SEARCH\n",
            "================================================================================\n",
            "\n",
            "Grid Search ba≈ülatƒ±lƒ±yor...\n",
            "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n",
            "\n",
            "‚úÖ Best Params: {'C': 0.1, 'class_weight': None, 'gamma': 0.001}\n",
            "‚úÖ Best CV Score: 51.37%\n",
            "\n",
            "Test Accuracy: 56.30%\n",
            "\n",
            "Confusion Matrix:\n",
            "                Predicted DOWN  Predicted UP\n",
            "Actual DOWN          0             208     \n",
            "Actual UP            0             268     \n",
            "\n",
            "================================================================================\n",
            "üìä SONU√á KAR≈ûILA≈ûTIRMASI\n",
            "================================================================================\n",
            "\n",
            "Kernel          Test Acc     Best C       Status\n",
            "------------------------------------------------------------\n",
            "Linear          56.30%       0.001        ‚ùå IMBALANCED\n",
            "RBF             56.30%       0.1          ‚ùå IMBALANCED\n",
            "\n",
            "================================================================================\n",
            "üí° YORUM\n",
            "================================================================================\n",
            "\n",
            "‚úÖ √ñNCEKƒ∞ SORUN: LAG YOKTU!\n",
            "   Model bug√ºn√ºn g√∂stergeleri ile bug√ºn√º tahmin ediyordu.\n",
            "   Sonu√ß: Hep \"UP\" tahmin ediyordu (confusion matrix: 0 DOWN)\n",
            "\n",
            "‚úÖ ≈ûƒ∞MDƒ∞: LAG VAR!\n",
            "   Model D√úN√úN g√∂stergeleri ile YARINI tahmin ediyor.\n",
            "   Sonu√ß: Hala imbalance var!\n",
            "\n",
            "üìä ACCURACY: 56.30%\n",
            "   \n",
            "   üü° ƒ∞Yƒ∞ (55-60%)\n",
            "   \n",
            "   \n",
            "\n",
            "üí≠ NOT: Finansal tahminde %55+ √áOK ƒ∞Yƒ∞Dƒ∞R!\n",
            "   Random guess: %50\n",
            "   Market'i yenen: %55+\n",
            "   Profesyonel trader: %60+\n",
            "\n",
            "üéØ BU SONU√á GER√áEK√áƒ∞ VE DOƒûRU!\n",
            "   Makale %85-90 iddia ediyorsa, muhtemelen:\n",
            "   1. Data leakage var\n",
            "   2. LAG yok\n",
            "   3. Veya methodoloji hatalƒ±\n",
            "\n",
            "\n",
            "================================================================================\n",
            "‚úÖ ANALƒ∞Z TAMAMLANDI\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "============================================================================\n",
        "KOSPI - TREND DETERMINISTIC (PATEL ET AL. METHOD)\n",
        "============================================================================\n",
        "Hipotez: Makale g√∂stergeleri BINARY'ye √ßevirmi≈ü olabilir\n",
        "Y√∂ntem: Feature[t] > Feature[t-1] ise 1, deƒüilse 0\n",
        "============================================================================\n",
        "\"\"\"\n",
        "\n",
        "import sys\n",
        "import subprocess\n",
        "print(\"üì¶ Y√ºkleniyor...\")\n",
        "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\",\n",
        "                      \"yfinance\", \"scikit-learn\", \"pandas\", \"numpy\"])\n",
        "\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"‚úÖ Hazƒ±r!\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# VERƒ∞\n",
        "# ============================================================================\n",
        "print(\"=\"*80)\n",
        "print(\"üìà VERƒ∞ - KOSPI\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "ticker = '^KS11'\n",
        "data = yf.download(ticker, start=\"2011-01-01\", end=\"2020-09-27\",\n",
        "                  progress=False, auto_adjust=True)\n",
        "\n",
        "if isinstance(data.columns, pd.MultiIndex):\n",
        "    data.columns = data.columns.get_level_values(0)\n",
        "\n",
        "data = data[['Open', 'High', 'Low', 'Close', 'Volume']].copy()\n",
        "data = data.dropna()\n",
        "\n",
        "print(f\"‚úÖ {len(data)} g√ºn\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# TEKNƒ∞K G√ñSTERGELER (CONTINUOUS)\n",
        "# ============================================================================\n",
        "print(\"=\"*80)\n",
        "print(\"üîß TEKNƒ∞K G√ñSTERGELER (Continuous)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "def calculate_indicators(df):\n",
        "    df = df.copy()\n",
        "\n",
        "    high = df['High'].squeeze()\n",
        "    low = df['Low'].squeeze()\n",
        "    close = df['Close'].squeeze()\n",
        "\n",
        "    # Stochastic\n",
        "    lowest_low = low.rolling(14).min()\n",
        "    highest_high = high.rolling(14).max()\n",
        "    df['Stochastic_K'] = ((close - lowest_low) / (highest_high - lowest_low)) * 100\n",
        "    df['Stochastic_D'] = df['Stochastic_K'].rolling(3).mean()\n",
        "\n",
        "    # ROC\n",
        "    df['ROC'] = close.pct_change(10) * 100\n",
        "\n",
        "    # Williams %R\n",
        "    df['Williams_R'] = ((highest_high - close) / (highest_high - lowest_low)) * -100\n",
        "\n",
        "    # Momentum\n",
        "    df['Momentum'] = close.diff(4)\n",
        "\n",
        "    # Disparity\n",
        "    ma5 = close.rolling(5).mean()\n",
        "    ma14 = close.rolling(14).mean()\n",
        "    df['Disparity_5'] = (close / ma5) * 100\n",
        "    df['Disparity_14'] = (close / ma14) * 100\n",
        "\n",
        "    # OSCP\n",
        "    ma10 = close.rolling(10).mean()\n",
        "    df['OSCP'] = ((ma5 - ma10) / ma5)\n",
        "\n",
        "    # CCI\n",
        "    tp = (high + low + close) / 3\n",
        "    df['CCI'] = (tp - tp.rolling(20).mean()) / (0.015 * tp.rolling(20).std())\n",
        "\n",
        "    # RSI\n",
        "    delta = close.diff()\n",
        "    gain = delta.where(delta > 0, 0).rolling(14).mean()\n",
        "    loss = -delta.where(delta < 0, 0).rolling(14).mean()\n",
        "    rs = gain / loss\n",
        "    df['RSI'] = 100 - (100 / (1 + rs))\n",
        "\n",
        "    # Pivot Points\n",
        "    prev_high = high.shift(1)\n",
        "    prev_low = low.shift(1)\n",
        "    prev_close = close.shift(1)\n",
        "\n",
        "    df['Pivot_Point'] = (prev_high + prev_low + prev_close) / 3\n",
        "    df['S1'] = (df['Pivot_Point'] * 2) - prev_high\n",
        "    df['S2'] = df['Pivot_Point'] - (prev_high - prev_low)\n",
        "    df['R1'] = (df['Pivot_Point'] * 2) - prev_low\n",
        "    df['R2'] = df['Pivot_Point'] + (prev_high - prev_low)\n",
        "\n",
        "    df = df.replace([np.inf, -np.inf], np.nan)\n",
        "    return df\n",
        "\n",
        "data = calculate_indicators(data)\n",
        "\n",
        "features = ['Stochastic_K', 'Stochastic_D', 'ROC', 'Williams_R',\n",
        "            'Momentum', 'Disparity_5', 'Disparity_14', 'OSCP',\n",
        "            'CCI', 'RSI', 'Pivot_Point', 'S1', 'S2', 'R1', 'R2']\n",
        "\n",
        "data = data.dropna(subset=features)\n",
        "print(f\"‚úÖ 15 g√∂sterge hesaplandƒ± ({len(data)} g√ºn)\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# TREND DETERMINISTIC (BINARY TRANSFORMATION)\n",
        "# ============================================================================\n",
        "print(\"=\"*80)\n",
        "print(\"üîÑ TREND DETERMINISTIC: Continuous ‚Üí Binary\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Her g√∂sterge i√ßin: Bug√ºn > D√ºn ise 1, deƒüilse 0\n",
        "binary_data = data[['Close']].copy()\n",
        "\n",
        "for feat in features:\n",
        "    binary_col = f'{feat}_trend'\n",
        "    # Bug√ºn > D√ºn = 1, deƒüilse 0\n",
        "    binary_data[binary_col] = (data[feat] > data[feat].shift(1)).astype(int)\n",
        "\n",
        "binary_features = [f'{feat}_trend' for feat in features]\n",
        "\n",
        "print(f\"‚úÖ 15 continuous g√∂sterge ‚Üí 15 binary trend g√∂stergesi\")\n",
        "print(f\"   √ñrnek: RSI=65.3 ve RSI_prev=60.1 ‚Üí RSI_trend=1 (UP)\")\n",
        "print(f\"           RSI=58.2 ve RSI_prev=62.5 ‚Üí RSI_trend=0 (DOWN)\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# TARGET\n",
        "# ============================================================================\n",
        "binary_data['Target'] = (binary_data['Close'].shift(-1) > binary_data['Close']).astype(int)\n",
        "binary_data = binary_data.iloc[:-1]\n",
        "\n",
        "binary_data = binary_data.dropna()\n",
        "\n",
        "print(f\"‚úÖ Target olu≈üturuldu\")\n",
        "print(f\"Total: {len(binary_data)} | UP: {binary_data['Target'].sum()} \"\n",
        "      f\"({binary_data['Target'].mean()*100:.1f}%)\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# LAG (t-1 binary features)\n",
        "# ============================================================================\n",
        "print(\"=\"*80)\n",
        "print(\"üîÑ LAG UYGULA (Binary features)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "lagged_binary = []\n",
        "for feat in binary_features:\n",
        "    lagged_col = f'{feat}_lag1'\n",
        "    binary_data[lagged_col] = binary_data[feat].shift(1)\n",
        "    lagged_binary.append(lagged_col)\n",
        "\n",
        "binary_data = binary_data.dropna(subset=lagged_binary)\n",
        "\n",
        "print(f\"‚úÖ LAG uygulandƒ±!\")\n",
        "print(f\"Final: {len(binary_data)} g√ºn\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# SPLIT\n",
        "# ============================================================================\n",
        "print(\"=\"*80)\n",
        "print(\"‚úÇÔ∏è TRAIN/TEST SPLIT\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "X = binary_data[lagged_binary].copy()\n",
        "y = binary_data['Target'].copy()\n",
        "\n",
        "split_idx = int(len(X) * 0.8)\n",
        "X_train = X.iloc[:split_idx]\n",
        "X_test = X.iloc[split_idx:]\n",
        "y_train = y.iloc[:split_idx].values\n",
        "y_test = y.iloc[split_idx:].values\n",
        "\n",
        "print(f\"Train: {len(X_train)} | UP: {y_train.mean()*100:.1f}%\")\n",
        "print(f\"Test:  {len(X_test)} | UP: {y_test.mean()*100:.1f}%\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# NORMALIZE (Binary'leri bile normalize ediyoruz - makale i√ßin)\n",
        "# ============================================================================\n",
        "print(\"=\"*80)\n",
        "print(\"üìä MIN-MAX NORMALIZATION (Binary ‚Üí [0,1])\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(\"‚úÖ Normalization tamamlandƒ±\\n\")\n",
        "print(\"   NOT: Binary deƒüerler zaten 0/1 ama makaledeki gibi normalize ettik\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# MODEL 1: LINEAR (Makale parametreleri)\n",
        "# ============================================================================\n",
        "print(\"=\"*80)\n",
        "print(\"ü§ñ SVM LINEAR - Makaledeki Parametreler\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Makale: C=4 for KOSPI Linear\n",
        "svm_linear = SVC(kernel='linear', C=4, class_weight='balanced', random_state=42)\n",
        "\n",
        "print(\"C = 4 (Makaledeki deƒüer)\")\n",
        "print(\"class_weight = balanced\")\n",
        "print(\"\\nEƒüitim...\")\n",
        "\n",
        "svm_linear.fit(X_train_scaled, y_train)\n",
        "y_pred_linear = svm_linear.predict(X_test_scaled)\n",
        "\n",
        "acc_linear = accuracy_score(y_test, y_pred_linear)\n",
        "\n",
        "print(f\"\\n‚úÖ Test Accuracy: {acc_linear*100:.2f}%\")\n",
        "\n",
        "cm_linear = confusion_matrix(y_test, y_pred_linear)\n",
        "print(f\"\\nConfusion Matrix:\")\n",
        "print(f\"                Predicted DOWN  Predicted UP\")\n",
        "print(f\"Actual DOWN          {cm_linear[0,0]:<8}      {cm_linear[0,1]:<8}\")\n",
        "print(f\"Actual UP            {cm_linear[1,0]:<8}      {cm_linear[1,1]:<8}\")\n",
        "\n",
        "tn, fp, fn, tp = cm_linear.ravel()\n",
        "down_acc = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "up_acc = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "\n",
        "print(f\"\\nClass-wise:\")\n",
        "print(f\"DOWN: {down_acc*100:.1f}%\")\n",
        "print(f\"UP:   {up_acc*100:.1f}%\")\n",
        "\n",
        "# ============================================================================\n",
        "# MODEL 2: RBF (Makale parametreleri)\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ü§ñ SVM RBF - Makaledeki Parametreler\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Makale: C=150, œÉ=0.00528\n",
        "# gamma = 1/(2*sigma^2) = 1/(2*0.00528^2) = 17935\n",
        "gamma = 1 / (2 * 0.00528**2)\n",
        "\n",
        "svm_rbf = SVC(kernel='rbf', C=150, gamma=gamma, class_weight='balanced', random_state=42)\n",
        "\n",
        "print(f\"C = 150 (Makaledeki deƒüer)\")\n",
        "print(f\"œÉ = 0.00528 ‚Üí gamma = {gamma:.2f}\")\n",
        "print(\"class_weight = balanced\")\n",
        "print(\"\\nEƒüitim...\")\n",
        "\n",
        "svm_rbf.fit(X_train_scaled, y_train)\n",
        "y_pred_rbf = svm_rbf.predict(X_test_scaled)\n",
        "\n",
        "acc_rbf = accuracy_score(y_test, y_pred_rbf)\n",
        "\n",
        "print(f\"\\n‚úÖ Test Accuracy: {acc_rbf*100:.2f}%\")\n",
        "\n",
        "cm_rbf = confusion_matrix(y_test, y_pred_rbf)\n",
        "print(f\"\\nConfusion Matrix:\")\n",
        "print(f\"                Predicted DOWN  Predicted UP\")\n",
        "print(f\"Actual DOWN          {cm_rbf[0,0]:<8}      {cm_rbf[0,1]:<8}\")\n",
        "print(f\"Actual UP            {cm_rbf[1,0]:<8}      {cm_rbf[1,1]:<8}\")\n",
        "\n",
        "tn, fp, fn, tp = cm_rbf.ravel()\n",
        "down_acc = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "up_acc = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "\n",
        "print(f\"\\nClass-wise:\")\n",
        "print(f\"DOWN: {down_acc*100:.1f}%\")\n",
        "print(f\"UP:   {up_acc*100:.1f}%\")\n",
        "\n",
        "# ============================================================================\n",
        "# MODEL 3: GRID SEARCH (Optimal parametreler)\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ü§ñ SVM LINEAR - GRID SEARCH (Optimal)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 4, 10, 50, 100, 500],\n",
        "    'class_weight': ['balanced']\n",
        "}\n",
        "\n",
        "svm = SVC(kernel='linear', random_state=42)\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=False)\n",
        "\n",
        "grid = GridSearchCV(svm, param_grid, cv=cv, scoring='accuracy', n_jobs=-1, verbose=1)\n",
        "\n",
        "print(\"Grid Search...\")\n",
        "grid.fit(X_train_scaled, y_train)\n",
        "\n",
        "print(f\"\\n‚úÖ Best C: {grid.best_params_['C']}\")\n",
        "print(f\"‚úÖ Best CV Score: {grid.best_score_*100:.2f}%\")\n",
        "\n",
        "y_pred_grid = grid.best_estimator_.predict(X_test_scaled)\n",
        "acc_grid = accuracy_score(y_test, y_pred_grid)\n",
        "\n",
        "print(f\"‚úÖ Test Accuracy: {acc_grid*100:.2f}%\")\n",
        "\n",
        "cm_grid = confusion_matrix(y_test, y_pred_grid)\n",
        "print(f\"\\nConfusion Matrix:\")\n",
        "print(f\"                Predicted DOWN  Predicted UP\")\n",
        "print(f\"Actual DOWN          {cm_grid[0,0]:<8}      {cm_grid[0,1]:<8}\")\n",
        "print(f\"Actual UP            {cm_grid[1,0]:<8}      {cm_grid[1,1]:<8}\")\n",
        "\n",
        "# ============================================================================\n",
        "# KAR≈ûILA≈ûTIRMA\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üìä SONU√á KAR≈ûILA≈ûTIRMASI\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(f\"\\n{'Model':<30} {'Test Acc':<12} {'Makale':<12} {'Fark'}\")\n",
        "print(\"-\" * 70)\n",
        "print(f\"{'Linear (C=4, Paper)':<30} {acc_linear*100:>5.2f}%       \"\n",
        "      f\"{'80.33%':<12} {abs(acc_linear*100 - 80.33):>5.2f}%\")\n",
        "print(f\"{'RBF (C=150, Paper)':<30} {acc_rbf*100:>5.2f}%       \"\n",
        "      f\"{'81.80%':<12} {abs(acc_rbf*100 - 81.80):>5.2f}%\")\n",
        "print(f\"{'Linear (Optimized)':<30} {acc_grid*100:>5.2f}%       \"\n",
        "      f\"{'-':<12} {'-'}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üí° YORUM\")\n",
        "print(\"=\"*80)\n",
        "print(f\"\"\"\n",
        "‚úÖ TREND DETERMINISTIC UYGULAND!:\n",
        "   Continuous g√∂stergeler ‚Üí Binary (0/1) trend g√∂stergeleri\n",
        "\n",
        "üìä SONU√áLAR:\n",
        "   Paper Linear:  {acc_linear*100:.2f}% (Beklenen: 80.33%)\n",
        "   Paper RBF:     {acc_rbf*100:.2f}% (Beklenen: 81.80%)\n",
        "   Optimized:     {acc_grid*100:.2f}%\n",
        "\n",
        "üîç DEƒûERLENDƒ∞RME:\n",
        "   {'‚úÖ BA≈ûARILI! Makaleye √ßok yakƒ±n!' if max(acc_linear, acc_rbf) >= 0.75 else ''}\n",
        "   {'üü° ƒ∞Yƒ∞ ama makaleye ula≈üamadƒ± (Gap: ~{abs(max(acc_linear, acc_rbf)*100 - 80):0f}%)' if 0.60 <= max(acc_linear, acc_rbf) < 0.75 else ''}\n",
        "   {'üî¥ D√º≈ü√ºk - Makale muhtemelen ba≈üka bir ≈üey yapmƒ±≈ü' if max(acc_linear, acc_rbf) < 0.60 else ''}\n",
        "\n",
        "üí≠ OLASI NEDENLER (Eƒüer h√¢l√¢ d√º≈ü√ºkse):\n",
        "   1. Makale farklƒ± veri periyodu kullanmƒ±≈ü (2011-2015 gibi)\n",
        "   2. Shuffle=True ile CV yapmƒ±≈ü (data leakage)\n",
        "   3. Farklƒ± bir feature engineering y√∂ntemi var\n",
        "   4. Target tanƒ±mƒ± farklƒ± olabilir\n",
        "\n",
        "üéØ BU TEST √áOK √ñNEMLƒ∞:\n",
        "   Binary features + Paper parameters kullandƒ±k.\n",
        "   Eƒüer %60+ √ßƒ±karsa ‚Üí Y√∂ntem doƒüru yolda\n",
        "   Eƒüer %55 civarƒ± ‚Üí Makale metodolojisi ≈ü√ºpheli\n",
        "\"\"\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"‚úÖ ANALƒ∞Z TAMAMLANDI\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghUzAPaadrFr",
        "outputId": "a47dab89-1408-4ce5-c0f5-2ae731a3eb00"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì¶ Y√ºkleniyor...\n",
            "‚úÖ Hazƒ±r!\n",
            "\n",
            "================================================================================\n",
            "üìà VERƒ∞ - KOSPI\n",
            "================================================================================\n",
            "‚úÖ 2397 g√ºn\n",
            "\n",
            "================================================================================\n",
            "üîß TEKNƒ∞K G√ñSTERGELER (Continuous)\n",
            "================================================================================\n",
            "‚úÖ 15 g√∂sterge hesaplandƒ± (2378 g√ºn)\n",
            "\n",
            "================================================================================\n",
            "üîÑ TREND DETERMINISTIC: Continuous ‚Üí Binary\n",
            "================================================================================\n",
            "‚úÖ 15 continuous g√∂sterge ‚Üí 15 binary trend g√∂stergesi\n",
            "   √ñrnek: RSI=65.3 ve RSI_prev=60.1 ‚Üí RSI_trend=1 (UP)\n",
            "           RSI=58.2 ve RSI_prev=62.5 ‚Üí RSI_trend=0 (DOWN)\n",
            "\n",
            "‚úÖ Target olu≈üturuldu\n",
            "Total: 2377 | UP: 1244 (52.3%)\n",
            "\n",
            "================================================================================\n",
            "üîÑ LAG UYGULA (Binary features)\n",
            "================================================================================\n",
            "‚úÖ LAG uygulandƒ±!\n",
            "Final: 2376 g√ºn\n",
            "\n",
            "================================================================================\n",
            "‚úÇÔ∏è TRAIN/TEST SPLIT\n",
            "================================================================================\n",
            "Train: 1900 | UP: 51.4%\n",
            "Test:  476 | UP: 56.3%\n",
            "\n",
            "================================================================================\n",
            "üìä MIN-MAX NORMALIZATION (Binary ‚Üí [0,1])\n",
            "================================================================================\n",
            "‚úÖ Normalization tamamlandƒ±\n",
            "\n",
            "   NOT: Binary deƒüerler zaten 0/1 ama makaledeki gibi normalize ettik\n",
            "\n",
            "================================================================================\n",
            "ü§ñ SVM LINEAR - Makaledeki Parametreler\n",
            "================================================================================\n",
            "C = 4 (Makaledeki deƒüer)\n",
            "class_weight = balanced\n",
            "\n",
            "Eƒüitim...\n",
            "\n",
            "‚úÖ Test Accuracy: 51.68%\n",
            "\n",
            "Confusion Matrix:\n",
            "                Predicted DOWN  Predicted UP\n",
            "Actual DOWN          105           103     \n",
            "Actual UP            127           141     \n",
            "\n",
            "Class-wise:\n",
            "DOWN: 50.5%\n",
            "UP:   52.6%\n",
            "\n",
            "================================================================================\n",
            "ü§ñ SVM RBF - Makaledeki Parametreler\n",
            "================================================================================\n",
            "C = 150 (Makaledeki deƒüer)\n",
            "œÉ = 0.00528 ‚Üí gamma = 17935.03\n",
            "class_weight = balanced\n",
            "\n",
            "Eƒüitim...\n",
            "\n",
            "‚úÖ Test Accuracy: 50.42%\n",
            "\n",
            "Confusion Matrix:\n",
            "                Predicted DOWN  Predicted UP\n",
            "Actual DOWN          139           69      \n",
            "Actual UP            167           101     \n",
            "\n",
            "Class-wise:\n",
            "DOWN: 66.8%\n",
            "UP:   37.7%\n",
            "\n",
            "================================================================================\n",
            "ü§ñ SVM LINEAR - GRID SEARCH (Optimal)\n",
            "================================================================================\n",
            "Grid Search...\n",
            "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n",
            "\n",
            "‚úÖ Best C: 4\n",
            "‚úÖ Best CV Score: 51.00%\n",
            "‚úÖ Test Accuracy: 51.68%\n",
            "\n",
            "Confusion Matrix:\n",
            "                Predicted DOWN  Predicted UP\n",
            "Actual DOWN          105           103     \n",
            "Actual UP            127           141     \n",
            "\n",
            "================================================================================\n",
            "üìä SONU√á KAR≈ûILA≈ûTIRMASI\n",
            "================================================================================\n",
            "\n",
            "Model                          Test Acc     Makale       Fark\n",
            "----------------------------------------------------------------------\n",
            "Linear (C=4, Paper)            51.68%       80.33%       28.65%\n",
            "RBF (C=150, Paper)             50.42%       81.80%       31.38%\n",
            "Linear (Optimized)             51.68%       -            -\n",
            "\n",
            "================================================================================\n",
            "üí° YORUM\n",
            "================================================================================\n",
            "\n",
            "‚úÖ TREND DETERMINISTIC UYGULAND!:\n",
            "   Continuous g√∂stergeler ‚Üí Binary (0/1) trend g√∂stergeleri\n",
            "   \n",
            "üìä SONU√áLAR:\n",
            "   Paper Linear:  51.68% (Beklenen: 80.33%)\n",
            "   Paper RBF:     50.42% (Beklenen: 81.80%)\n",
            "   Optimized:     51.68%\n",
            "   \n",
            "üîç DEƒûERLENDƒ∞RME:\n",
            "   \n",
            "   \n",
            "   üî¥ D√º≈ü√ºk - Makale muhtemelen ba≈üka bir ≈üey yapmƒ±≈ü\n",
            "\n",
            "üí≠ OLASI NEDENLER (Eƒüer h√¢l√¢ d√º≈ü√ºkse):\n",
            "   1. Makale farklƒ± veri periyodu kullanmƒ±≈ü (2011-2015 gibi)\n",
            "   2. Shuffle=True ile CV yapmƒ±≈ü (data leakage)\n",
            "   3. Farklƒ± bir feature engineering y√∂ntemi var\n",
            "   4. Target tanƒ±mƒ± farklƒ± olabilir\n",
            "   \n",
            "üéØ BU TEST √áOK √ñNEMLƒ∞:\n",
            "   Binary features + Paper parameters kullandƒ±k.\n",
            "   Eƒüer %60+ √ßƒ±karsa ‚Üí Y√∂ntem doƒüru yolda\n",
            "   Eƒüer %55 civarƒ± ‚Üí Makale metodolojisi ≈ü√ºpheli\n",
            "\n",
            "\n",
            "================================================================================\n",
            "‚úÖ ANALƒ∞Z TAMAMLANDI\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "============================================================================\n",
        "KOSPI - TREND DETERMINISTIC (PATEL ET AL. METHOD)\n",
        "============================================================================\n",
        "Hipotez: Makale g√∂stergeleri BINARY'ye √ßevirmi≈ü olabilir\n",
        "Y√∂ntem: Feature[t] > Feature[t-1] ise 1, deƒüilse 0\n",
        "============================================================================\n",
        "\"\"\"\n",
        "\n",
        "import sys\n",
        "import subprocess\n",
        "print(\"üì¶ Y√ºkleniyor...\")\n",
        "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\",\n",
        "                      \"yfinance\", \"scikit-learn\", \"pandas\", \"numpy\"])\n",
        "\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"‚úÖ Hazƒ±r!\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# VERƒ∞\n",
        "# ============================================================================\n",
        "print(\"=\"*80)\n",
        "print(\"üìà VERƒ∞ - KOSPI\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "ticker = '^KS11'\n",
        "data = yf.download(ticker, start=\"2011-01-01\", end=\"2020-09-27\",\n",
        "                  progress=False, auto_adjust=True)\n",
        "\n",
        "if isinstance(data.columns, pd.MultiIndex):\n",
        "    data.columns = data.columns.get_level_values(0)\n",
        "\n",
        "data = data[['Open', 'High', 'Low', 'Close', 'Volume']].copy()\n",
        "data = data.dropna()\n",
        "\n",
        "print(f\"‚úÖ {len(data)} g√ºn\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# TEKNƒ∞K G√ñSTERGELER\n",
        "# ============================================================================\n",
        "print(\"=\"*80)\n",
        "print(\"üîß TEKNƒ∞K G√ñSTERGELER (Continuous)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "def calculate_indicators(df):\n",
        "    df = df.copy()\n",
        "\n",
        "    high = df['High'].squeeze()\n",
        "    low = df['Low'].squeeze()\n",
        "    close = df['Close'].squeeze()\n",
        "\n",
        "    lowest_low = low.rolling(14).min()\n",
        "    highest_high = high.rolling(14).max()\n",
        "    df['Stochastic_K'] = ((close - lowest_low) / (highest_high - lowest_low)) * 100\n",
        "    df['Stochastic_D'] = df['Stochastic_K'].rolling(3).mean()\n",
        "\n",
        "    df['ROC'] = close.pct_change(10) * 100\n",
        "    df['Williams_R'] = ((highest_high - close) / (highest_high - lowest_low)) * -100\n",
        "    df['Momentum'] = close.diff(4)\n",
        "\n",
        "    ma5 = close.rolling(5).mean()\n",
        "    ma14 = close.rolling(14).mean()\n",
        "    df['Disparity_5'] = (close / ma5) * 100\n",
        "    df['Disparity_14'] = (close / ma14) * 100\n",
        "\n",
        "    ma10 = close.rolling(10).mean()\n",
        "    df['OSCP'] = ((ma5 - ma10) / ma5)\n",
        "\n",
        "    tp = (high + low + close) / 3\n",
        "    df['CCI'] = (tp - tp.rolling(20).mean()) / (0.015 * tp.rolling(20).std())\n",
        "\n",
        "    delta = close.diff()\n",
        "    gain = delta.where(delta > 0, 0).rolling(14).mean()\n",
        "    loss = -delta.where(delta < 0, 0).rolling(14).mean()\n",
        "    rs = gain / loss\n",
        "    df['RSI'] = 100 - (100 / (1 + rs))\n",
        "\n",
        "    prev_high = high.shift(1)\n",
        "    prev_low = low.shift(1)\n",
        "    prev_close = close.shift(1)\n",
        "\n",
        "    df['Pivot_Point'] = (prev_high + prev_low + prev_close) / 3\n",
        "    df['S1'] = (df['Pivot_Point'] * 2) - prev_high\n",
        "    df['S2'] = df['Pivot_Point'] - (prev_high - prev_low)\n",
        "    df['R1'] = (df['Pivot_Point'] * 2) - prev_low\n",
        "    df['R2'] = df['Pivot_Point'] + (prev_high - prev_low)\n",
        "\n",
        "    df = df.replace([np.inf, -np.inf], np.nan)\n",
        "    return df\n",
        "\n",
        "data = calculate_indicators(data)\n",
        "\n",
        "features = ['Stochastic_K', 'Stochastic_D', 'ROC', 'Williams_R',\n",
        "            'Momentum', 'Disparity_5', 'Disparity_14', 'OSCP',\n",
        "            'CCI', 'RSI', 'Pivot_Point', 'S1', 'S2', 'R1', 'R2']\n",
        "\n",
        "data = data.dropna(subset=features)\n",
        "print(f\"‚úÖ 15 g√∂sterge hesaplandƒ± ({len(data)} g√ºn)\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# TREND DETERMINISTIC\n",
        "# ============================================================================\n",
        "print(\"=\"*80)\n",
        "print(\"üîÑ TREND DETERMINISTIC: Continuous ‚Üí Binary\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "binary_data = data[['Close']].copy()\n",
        "\n",
        "for feat in features:\n",
        "    binary_data[f'{feat}_trend'] = (data[feat] > data[feat].shift(1)).astype(int)\n",
        "\n",
        "binary_features = [f'{feat}_trend' for feat in features]\n",
        "\n",
        "binary_data['Target'] = (binary_data['Close'].shift(-1) > binary_data['Close']).astype(int)\n",
        "binary_data = binary_data.iloc[:-1]\n",
        "binary_data = binary_data.dropna()\n",
        "\n",
        "print(f\"‚úÖ Target olu≈üturuldu\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# LAG\n",
        "# ============================================================================\n",
        "print(\"=\"*80)\n",
        "print(\"üîÑ LAG UYGULA (Binary features)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "lagged_binary = []\n",
        "for feat in binary_features:\n",
        "    binary_data[f'{feat}_lag1'] = binary_data[feat].shift(1)\n",
        "    lagged_binary.append(f'{feat}_lag1')\n",
        "\n",
        "binary_data = binary_data.dropna(subset=lagged_binary)\n",
        "\n",
        "print(f\"Final: {len(binary_data)} g√ºn\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# SPLIT\n",
        "# ============================================================================\n",
        "print(\"=\"*80)\n",
        "print(\"‚úÇÔ∏è TRAIN/TEST SPLIT\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "X = binary_data[lagged_binary].copy()\n",
        "y = binary_data['Target'].copy()\n",
        "\n",
        "split_idx = int(len(X) * 0.8)\n",
        "X_train = X.iloc[:split_idx]\n",
        "X_test = X.iloc[split_idx:]\n",
        "y_train = y.iloc[:split_idx].values\n",
        "y_test = y.iloc[split_idx:].values\n",
        "\n",
        "print(f\"Train: {len(X_train)} | UP: {y_train.mean()*100:.1f}%\")\n",
        "print(f\"Test:  {len(X_test)} | UP: {y_test.mean()*100:.1f}%\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# NORMALIZATION\n",
        "# ============================================================================\n",
        "print(\"=\"*80)\n",
        "print(\"üìä MIN-MAX NORMALIZATION\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(\"Normalization tamamlandƒ±\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# MODEL 1: LINEAR SVM\n",
        "# ============================================================================\n",
        "print(\"=\"*80)\n",
        "print(\"ü§ñ SVM LINEAR (Paper Params)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "svm_linear = SVC(kernel='linear', C=4, class_weight='balanced', random_state=42)\n",
        "svm_linear.fit(X_train_scaled, y_train)\n",
        "y_pred_linear = svm_linear.predict(X_test_scaled)\n",
        "\n",
        "acc_linear = accuracy_score(y_test, y_pred_linear)\n",
        "\n",
        "print(f\"Test Accuracy: {acc_linear*100:.2f}%\")\n",
        "\n",
        "# ============================================================================\n",
        "# MODEL 2: RBF SVM\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ü§ñ SVM RBF (Paper Params)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "gamma = 1 / (2 * 0.00528**2)\n",
        "svm_rbf = SVC(kernel='rbf', C=150, gamma=gamma, class_weight='balanced', random_state=42)\n",
        "\n",
        "svm_rbf.fit(X_train_scaled, y_train)\n",
        "y_pred_rbf = svm_rbf.predict(X_test_scaled)\n",
        "\n",
        "acc_rbf = accuracy_score(y_test, y_pred_rbf)\n",
        "\n",
        "print(f\"Test Accuracy: {acc_rbf*100:.2f}%\")\n",
        "\n",
        "# ============================================================================\n",
        "# MODEL 3: GRID SEARCH\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ü§ñ SVM LINEAR - GRID SEARCH\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 4, 10, 50, 100, 500],\n",
        "    'class_weight': ['balanced']\n",
        "}\n",
        "\n",
        "svm = SVC(kernel='linear', random_state=42)\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=False)\n",
        "\n",
        "grid = GridSearchCV(svm, param_grid, cv=cv, scoring='accuracy', n_jobs=-1, verbose=1)\n",
        "grid.fit(X_train_scaled, y_train)\n",
        "\n",
        "best_linear_svm = grid.best_estimator_\n",
        "\n",
        "y_pred_grid = best_linear_svm.predict(X_test_scaled)\n",
        "acc_grid = accuracy_score(y_test, y_pred_grid)\n",
        "\n",
        "print(f\"Best C: {grid.best_params_['C']}\")\n",
        "print(f\"Test Accuracy: {acc_grid*100:.2f}%\")\n",
        "\n",
        "# ============================================================================\n",
        "# TEST 2: Balanced Evaluation (Makale Metodolojisi)\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üß™ TEST 2 (Balanced UP/DOWN Evaluation)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "test_df = X_test.copy()\n",
        "test_df['Target'] = y_test\n",
        "\n",
        "up_samples = test_df[test_df['Target'] == 1]\n",
        "down_samples = test_df[test_df['Target'] == 0]\n",
        "\n",
        "min_count = min(len(up_samples), len(down_samples))\n",
        "\n",
        "test2 = pd.concat([\n",
        "    up_samples.sample(min_count, random_state=42),\n",
        "    down_samples.sample(min_count, random_state=42)\n",
        "]).sample(frac=1, random_state=42)\n",
        "\n",
        "X_test2 = test2.drop(columns=['Target'])\n",
        "y_test2 = test2['Target']\n",
        "\n",
        "X_test2_scaled = scaler.transform(X_test2)\n",
        "\n",
        "y_pred_test2_linear = svm_linear.predict(X_test2_scaled)\n",
        "y_pred_test2_rbf = svm_rbf.predict(X_test2_scaled)\n",
        "\n",
        "acc_test2_linear = accuracy_score(y_test2, y_pred_test2_linear)\n",
        "acc_test2_rbf = accuracy_score(y_test2, y_pred_test2_rbf)\n",
        "\n",
        "print(f\"Linear SVM TEST2 Accuracy: {acc_test2_linear*100:.2f}%\")\n",
        "print(f\"RBF SVM TEST2 Accuracy:    {acc_test2_rbf*100:.2f}%\")\n",
        "\n",
        "print(\"\\nüìù Not:\")\n",
        "print(\"TEST2 (balanced) accuracy d√º≈ü√ºkse ‚Üí modelin ger√ßek √∂ng√∂r√º g√ºc√º zayƒ±f demektir.\")\n",
        "print(\"Makaledeki asƒ±l metodolojik kritik nokta budur.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUH5ATmFe8b_",
        "outputId": "c530aafc-1c74-41cc-9631-521b7e85fcf6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì¶ Y√ºkleniyor...\n",
            "‚úÖ Hazƒ±r!\n",
            "\n",
            "================================================================================\n",
            "üìà VERƒ∞ - KOSPI\n",
            "================================================================================\n",
            "‚úÖ 2397 g√ºn\n",
            "\n",
            "================================================================================\n",
            "üîß TEKNƒ∞K G√ñSTERGELER (Continuous)\n",
            "================================================================================\n",
            "‚úÖ 15 g√∂sterge hesaplandƒ± (2378 g√ºn)\n",
            "\n",
            "================================================================================\n",
            "üîÑ TREND DETERMINISTIC: Continuous ‚Üí Binary\n",
            "================================================================================\n",
            "‚úÖ Target olu≈üturuldu\n",
            "\n",
            "================================================================================\n",
            "üîÑ LAG UYGULA (Binary features)\n",
            "================================================================================\n",
            "Final: 2376 g√ºn\n",
            "\n",
            "================================================================================\n",
            "‚úÇÔ∏è TRAIN/TEST SPLIT\n",
            "================================================================================\n",
            "Train: 1900 | UP: 51.4%\n",
            "Test:  476 | UP: 56.3%\n",
            "\n",
            "================================================================================\n",
            "üìä MIN-MAX NORMALIZATION\n",
            "================================================================================\n",
            "Normalization tamamlandƒ±\n",
            "\n",
            "================================================================================\n",
            "ü§ñ SVM LINEAR (Paper Params)\n",
            "================================================================================\n",
            "Test Accuracy: 51.68%\n",
            "\n",
            "================================================================================\n",
            "ü§ñ SVM RBF (Paper Params)\n",
            "================================================================================\n",
            "Test Accuracy: 50.42%\n",
            "\n",
            "================================================================================\n",
            "ü§ñ SVM LINEAR - GRID SEARCH\n",
            "================================================================================\n",
            "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n",
            "Best C: 4\n",
            "Test Accuracy: 51.68%\n",
            "\n",
            "================================================================================\n",
            "üß™ TEST 2 (Balanced UP/DOWN Evaluation)\n",
            "================================================================================\n",
            "Linear SVM TEST2 Accuracy: 52.16%\n",
            "RBF SVM TEST2 Accuracy:    51.68%\n",
            "\n",
            "üìù Not:\n",
            "TEST2 (balanced) accuracy d√º≈ü√ºkse ‚Üí modelin ger√ßek √∂ng√∂r√º g√ºc√º zayƒ±f demektir.\n",
            "Makaledeki asƒ±l metodolojik kritik nokta budur.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6RRj1HBngup0"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}