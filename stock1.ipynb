{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "============================================================================\n",
        "GELƒ∞≈ûTƒ∞Rƒ∞LMƒ∞≈û SVM - MULTI-FEATURE STRATEGY\n",
        "Claude\n",
        "============================================================================\n",
        "‚úÖ Data Leakage D√ºzeltildi\n",
        "‚úÖ Alternatif Feature Setleri Eklendi\n",
        "‚úÖ Ensemble Yakla≈üƒ±mƒ±\n",
        "============================================================================\n",
        "\"\"\"\n",
        "\n",
        "import sys\n",
        "import subprocess\n",
        "print(\"üì¶ K√ºt√ºphaneler y√ºkleniyor...\")\n",
        "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\",\n",
        "                      \"yfinance\", \"ta\", \"scikit-learn\", \"pandas\", \"numpy\",\n",
        "                      \"scikit-optimize\"])\n",
        "\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import ta\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "from skopt import BayesSearchCV\n",
        "from skopt.space import Real\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"‚úÖ Kurulum tamamlandƒ±!\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# VERƒ∞ √áEKME\n",
        "# ============================================================================\n",
        "print(\"=\"*80)\n",
        "print(\"VERƒ∞ √áEKME\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "tickers = {\n",
        "    'KSE100': '^KSE',\n",
        "    'KOSPI': '^KS11',\n",
        "    'Nikkei225': '^N225',\n",
        "    'SZSE': '000001.SS'\n",
        "}\n",
        "\n",
        "all_data = {}\n",
        "for name, ticker in tickers.items():\n",
        "    print(f\"{name}...\", end=\" \")\n",
        "    try:\n",
        "        data = yf.download(ticker, start=\"2011-01-01\", end=\"2020-09-27\",\n",
        "                          progress=False, auto_adjust=True)\n",
        "\n",
        "        if data.empty:\n",
        "            print(\"‚ùå\")\n",
        "            continue\n",
        "\n",
        "        if isinstance(data.columns, pd.MultiIndex):\n",
        "            data.columns = data.columns.get_level_values(0)\n",
        "\n",
        "        data = data[['Open', 'High', 'Low', 'Close', 'Volume']].copy()\n",
        "        data = data.dropna()\n",
        "        all_data[name] = data\n",
        "        print(f\"‚úÖ {len(data)} g√ºn\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå {e}\")\n",
        "\n",
        "print(f\"‚úÖ {len(all_data)} borsa\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# FEATURE SET 1: TEKNƒ∞K G√ñSTERGELER (Orijinal)\n",
        "# ============================================================================\n",
        "\n",
        "def feature_set_1_technical(df):\n",
        "    \"\"\"Orijinal teknik g√∂stergeler\"\"\"\n",
        "    df = df.copy()\n",
        "\n",
        "    high = df['High'].squeeze()\n",
        "    low = df['Low'].squeeze()\n",
        "    close = df['Close'].squeeze()\n",
        "\n",
        "    # Stochastic\n",
        "    stoch = ta.momentum.StochasticOscillator(high, low, close, window=14, smooth_window=3)\n",
        "    df['Stochastic_K'] = stoch.stoch()\n",
        "    df['Stochastic_D'] = stoch.stoch_signal()\n",
        "\n",
        "    # ROC\n",
        "    df['ROC'] = ta.momentum.ROCIndicator(close, window=10).roc()\n",
        "\n",
        "    # Williams %R\n",
        "    df['Williams_R'] = ta.momentum.WilliamsRIndicator(high, low, close, lbp=14).williams_r()\n",
        "\n",
        "    # Momentum\n",
        "    df['Momentum'] = close.diff(4)\n",
        "\n",
        "    # Disparity\n",
        "    ma5 = close.rolling(5).mean()\n",
        "    ma14 = close.rolling(14).mean()\n",
        "    df['Disparity_5'] = np.where(ma5 != 0, (close / ma5) * 100, 100)\n",
        "    df['Disparity_14'] = np.where(ma14 != 0, (close / ma14) * 100, 100)\n",
        "\n",
        "    # OSCP\n",
        "    ma10 = close.rolling(10).mean()\n",
        "    df['OSCP'] = np.where(ma5 != 0, ((ma5 - ma10) / ma5), 0)\n",
        "\n",
        "    # CCI\n",
        "    df['CCI'] = ta.trend.CCIIndicator(high, low, close, window=20).cci()\n",
        "\n",
        "    # RSI\n",
        "    df['RSI'] = ta.momentum.RSIIndicator(close, window=14).rsi()\n",
        "\n",
        "    # Pivot Points\n",
        "    prev_high = high.shift(1)\n",
        "    prev_low = low.shift(1)\n",
        "    prev_close = close.shift(1)\n",
        "\n",
        "    df['Pivot_Point'] = (prev_high + prev_low + prev_close) / 3\n",
        "    df['S1'] = (df['Pivot_Point'] * 2) - prev_high\n",
        "    df['S2'] = df['Pivot_Point'] - (prev_high - prev_low)\n",
        "    df['R1'] = (df['Pivot_Point'] * 2) - prev_low\n",
        "    df['R2'] = df['Pivot_Point'] + (prev_high - prev_low)\n",
        "\n",
        "    return df\n",
        "\n",
        "# ============================================================================\n",
        "# FEATURE SET 2: BASITLE≈ûTIRILMI≈û MOMENTUM/VOLATILITY\n",
        "# ============================================================================\n",
        "\n",
        "def feature_set_2_simplified(df):\n",
        "    \"\"\"Alternatif basitle≈ütirilmi≈ü √∂zellikler\"\"\"\n",
        "    df = df.copy()\n",
        "    close = df['Close']\n",
        "\n",
        "    # Binary Momentum (g√ºnl√ºk)\n",
        "    df['Daily_Momentum'] = (close > close.shift(1)).astype(int) * 2 - 1  # +1 veya -1\n",
        "\n",
        "    # Volatility (y√ºzdesel deƒüi≈üim)\n",
        "    df['Daily_Volatility'] = (close - close.shift(1)) / close.shift(1)\n",
        "\n",
        "    # 5-g√ºnl√ºk ortalamalar\n",
        "    df['Index_Momentum_5D'] = df['Daily_Momentum'].rolling(5).mean()\n",
        "    df['Index_Volatility_5D'] = df['Daily_Volatility'].rolling(5).mean()\n",
        "\n",
        "    # 10-g√ºnl√ºk ortalamalar\n",
        "    df['Index_Momentum_10D'] = df['Daily_Momentum'].rolling(10).mean()\n",
        "    df['Index_Volatility_10D'] = df['Daily_Volatility'].rolling(10).mean()\n",
        "\n",
        "    # Volume momentum\n",
        "    df['Volume_Change'] = df['Volume'].pct_change()\n",
        "    df['Volume_Momentum_5D'] = df['Volume_Change'].rolling(5).mean()\n",
        "\n",
        "    # Price position (mevcut fiyat / 20-g√ºnl√ºk max)\n",
        "    df['Price_Position'] = close / close.rolling(20).max()\n",
        "\n",
        "    return df\n",
        "\n",
        "# ============================================================================\n",
        "# FEATURE SET 3: TREND VE PATTERN\n",
        "# ============================================================================\n",
        "\n",
        "def feature_set_3_trends(df):\n",
        "    \"\"\"Trend ve pattern √∂zellikleri\"\"\"\n",
        "    df = df.copy()\n",
        "    close = df['Close']\n",
        "    high = df['High']\n",
        "    low = df['Low']\n",
        "\n",
        "    # Moving Average Crossovers\n",
        "    ma5 = close.rolling(5).mean()\n",
        "    ma20 = close.rolling(20).mean()\n",
        "    ma50 = close.rolling(50).mean()\n",
        "\n",
        "    df['MA5_20_Cross'] = (ma5 > ma20).astype(int)\n",
        "    df['MA5_50_Cross'] = (ma5 > ma50).astype(int)\n",
        "    df['Price_MA20_Ratio'] = close / ma20\n",
        "\n",
        "    # Bollinger Bands\n",
        "    bb = ta.volatility.BollingerBands(close, window=20, window_dev=2)\n",
        "    df['BB_High'] = bb.bollinger_hband_indicator()\n",
        "    df['BB_Low'] = bb.bollinger_lband_indicator()\n",
        "    df['BB_Width'] = bb.bollinger_wband()\n",
        "\n",
        "    # ATR (Average True Range)\n",
        "    df['ATR'] = ta.volatility.AverageTrueRange(high, low, close, window=14).average_true_range()\n",
        "\n",
        "    # ADX (Trend Strength)\n",
        "    df['ADX'] = ta.trend.ADXIndicator(high, low, close, window=14).adx()\n",
        "\n",
        "    # MACD\n",
        "    macd = ta.trend.MACD(close)\n",
        "    df['MACD'] = macd.macd()\n",
        "    df['MACD_Signal'] = macd.macd_signal()\n",
        "    df['MACD_Diff'] = macd.macd_diff()\n",
        "\n",
        "    return df\n",
        "\n",
        "# ============================================================================\n",
        "# VERƒ∞ HAZIRLAMA (DATA LEAKAGE D√úZELTƒ∞LDƒ∞!)\n",
        "# ============================================================================\n",
        "\n",
        "def prepare_data_no_leakage(df, feature_set='set1', test_ratio=0.2):\n",
        "    \"\"\"\n",
        "    ‚úÖ Data Leakage D√ºzeltildi:\n",
        "    1. LAG √∂nce uygulanƒ±r\n",
        "    2. Train/Test split yapƒ±lƒ±r\n",
        "    3. Scaler sadece TRAIN'e fit edilir\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "\n",
        "    # Feature setini se√ß\n",
        "    if feature_set == 'set1':\n",
        "        df = feature_set_1_technical(df)\n",
        "        features = ['Stochastic_K', 'Stochastic_D', 'ROC', 'Williams_R',\n",
        "                   'Momentum', 'Disparity_5', 'Disparity_14', 'OSCP',\n",
        "                   'CCI', 'RSI', 'Pivot_Point', 'S1', 'S2', 'R1', 'R2']\n",
        "    elif feature_set == 'set2':\n",
        "        df = feature_set_2_simplified(df)\n",
        "        features = ['Daily_Momentum', 'Daily_Volatility',\n",
        "                   'Index_Momentum_5D', 'Index_Volatility_5D',\n",
        "                   'Index_Momentum_10D', 'Index_Volatility_10D',\n",
        "                   'Volume_Momentum_5D', 'Price_Position']\n",
        "    elif feature_set == 'set3':\n",
        "        df = feature_set_3_trends(df)\n",
        "        features = ['MA5_20_Cross', 'MA5_50_Cross', 'Price_MA20_Ratio',\n",
        "                   'BB_High', 'BB_Low', 'BB_Width', 'ATR', 'ADX',\n",
        "                   'MACD', 'MACD_Signal', 'MACD_Diff']\n",
        "    else:  # 'all' - t√ºm feature'larƒ± birle≈ütir\n",
        "        df = feature_set_1_technical(df)\n",
        "        df = feature_set_2_simplified(df)\n",
        "        df = feature_set_3_trends(df)\n",
        "        features = ['Stochastic_K', 'Stochastic_D', 'ROC', 'Williams_R',\n",
        "                   'Momentum', 'Disparity_5', 'Disparity_14', 'OSCP',\n",
        "                   'CCI', 'RSI', 'Pivot_Point', 'S1', 'S2', 'R1', 'R2',\n",
        "                   'Daily_Momentum', 'Daily_Volatility', 'Index_Momentum_5D',\n",
        "                   'Index_Volatility_5D', 'Index_Momentum_10D', 'Index_Volatility_10D',\n",
        "                   'Volume_Momentum_5D', 'Price_Position',\n",
        "                   'MA5_20_Cross', 'MA5_50_Cross', 'Price_MA20_Ratio',\n",
        "                   'BB_High', 'BB_Low', 'BB_Width', 'ATR', 'ADX',\n",
        "                   'MACD', 'MACD_Signal', 'MACD_Diff']\n",
        "\n",
        "    # Target\n",
        "    df['Target'] = (df['Close'].shift(-1) > df['Close']).astype(int)\n",
        "    df = df.iloc[:-1].copy()\n",
        "\n",
        "    # NaN temizle\n",
        "    df = df.replace([np.inf, -np.inf], np.nan)\n",
        "    df = df.dropna(subset=features + ['Target'])\n",
        "\n",
        "    # ‚úÖ 1. √ñNCE LAG UYGULA (normalization √∂ncesi!)\n",
        "    lagged_features = []\n",
        "    for feat in features:\n",
        "        lagged_col = f'{feat}_lag1'\n",
        "        df[lagged_col] = df[feat].shift(1)\n",
        "        lagged_features.append(lagged_col)\n",
        "\n",
        "    df = df.dropna(subset=lagged_features)\n",
        "\n",
        "    X = df[lagged_features].copy()\n",
        "    y = df['Target'].copy()\n",
        "\n",
        "    # ‚úÖ 2. TRAIN/TEST SPLIT\n",
        "    n_train = int(len(X) * (1 - test_ratio))\n",
        "    X_train = X.iloc[:n_train].copy()\n",
        "    X_test = X.iloc[n_train:].copy()\n",
        "    y_train = y.iloc[:n_train].values\n",
        "    y_test = y.iloc[n_train:].values\n",
        "\n",
        "    # ‚úÖ 3. SCALER SADECE TRAIN'E FIT\n",
        "    scaler = MinMaxScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    X_train_scaled = pd.DataFrame(X_train_scaled, columns=lagged_features, index=X_train.index)\n",
        "    X_test_scaled = pd.DataFrame(X_test_scaled, columns=lagged_features, index=X_test.index)\n",
        "\n",
        "    print(f\"  Veri: {len(X)} | Train: {len(X_train)} | Test: {len(X_test)}\")\n",
        "    print(f\"  Features: {len(lagged_features)} | Up%: {y_train.mean()*100:.1f}%\")\n",
        "\n",
        "    return X_train_scaled, X_test_scaled, y_train, y_test\n",
        "\n",
        "# ============================================================================\n",
        "# MODEL Eƒûƒ∞Tƒ∞Mƒ∞\n",
        "# ============================================================================\n",
        "\n",
        "def train_model(X_train, y_train, X_test, y_test, model_name):\n",
        "    \"\"\"Bayesian Optimization ile SVM eƒüitimi\"\"\"\n",
        "\n",
        "    cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "    svm = SVC(kernel='linear', max_iter=50000, random_state=42)\n",
        "\n",
        "    search_spaces = {'C': Real(1e-4, 1e3, prior='log-uniform')}\n",
        "\n",
        "    bayes_search = BayesSearchCV(\n",
        "        svm, search_spaces, n_iter=50, cv=cv,\n",
        "        scoring='accuracy', n_jobs=-1, random_state=42\n",
        "    )\n",
        "\n",
        "    print(f\"\\n  {model_name} - Bayesian Optimization...\")\n",
        "    bayes_search.fit(X_train, y_train)\n",
        "\n",
        "    best_C = bayes_search.best_params_['C']\n",
        "    cv_score = bayes_search.best_score_\n",
        "\n",
        "    # Test\n",
        "    y_pred = bayes_search.best_estimator_.predict(X_test)\n",
        "    test_acc = accuracy_score(y_test, y_pred)\n",
        "    test_f1 = f1_score(y_test, y_pred, zero_division=0)\n",
        "\n",
        "    print(f\"  ‚úì Best C: {best_C:.4f}\")\n",
        "    print(f\"  ‚úì CV Score: {cv_score:.4f}\")\n",
        "    print(f\"  ‚úì Test Acc: {test_acc:.4f}\")\n",
        "    print(f\"  ‚úì Test F1: {test_f1:.4f}\")\n",
        "\n",
        "    return {\n",
        "        'model': bayes_search.best_estimator_,\n",
        "        'best_C': best_C,\n",
        "        'cv_score': cv_score,\n",
        "        'test_acc': test_acc,\n",
        "        'test_f1': test_f1,\n",
        "        'y_pred': y_pred\n",
        "    }\n",
        "\n",
        "# ============================================================================\n",
        "# √áALI≈ûTIR\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"MODEL Eƒûƒ∞Tƒ∞Mƒ∞ - FEATURE SET KAR≈ûILA≈ûTIRMASI\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "results_all = {}\n",
        "\n",
        "for index_name in ['KOSPI', 'Nikkei225']:  # ƒ∞ki borsa test\n",
        "    if index_name not in all_data:\n",
        "        continue\n",
        "\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"{index_name}\")\n",
        "    print(f\"{'='*80}\")\n",
        "\n",
        "    results_all[index_name] = {}\n",
        "\n",
        "    for feature_set, set_name in [('set1', 'Technical Indicators'),\n",
        "                                   ('set2', 'Simplified Momentum'),\n",
        "                                   ('set3', 'Trend & Pattern'),\n",
        "                                   ('all', 'Combined All')]:\n",
        "\n",
        "        print(f\"\\nüìä {set_name}\")\n",
        "        print(\"-\" * 80)\n",
        "\n",
        "        try:\n",
        "            X_train, X_test, y_train, y_test = prepare_data_no_leakage(\n",
        "                all_data[index_name],\n",
        "                feature_set=feature_set\n",
        "            )\n",
        "\n",
        "            result = train_model(X_train, y_train, X_test, y_test, set_name)\n",
        "            results_all[index_name][feature_set] = result\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  ‚ùå Error: {e}\")\n",
        "\n",
        "# ============================================================================\n",
        "# SONU√áLAR\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üìä FINAL RESULTS - FEATURE SET COMPARISON\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "for index_name, results in results_all.items():\n",
        "    print(f\"\\n{index_name}\")\n",
        "    print(\"-\" * 80)\n",
        "    print(f\"{'Feature Set':<25} {'Best C':<12} {'CV Score':<12} {'Test Acc':<12} {'Test F1':<12}\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "    for fset in ['set1', 'set2', 'set3', 'all']:\n",
        "        if fset in results:\n",
        "            r = results[fset]\n",
        "            set_names = {'set1': 'Technical', 'set2': 'Simplified',\n",
        "                        'set3': 'Trend', 'all': 'Combined'}\n",
        "            print(f\"{set_names[fset]:<25} {r['best_C']:<12.4f} {r['cv_score']:<12.4f} \"\n",
        "                  f\"{r['test_acc']:<12.4f} {r['test_f1']:<12.4f}\")\n",
        "\n",
        "    # En iyi model\n",
        "    best = max(results.items(), key=lambda x: x[1]['test_acc'])\n",
        "    set_names = {'set1': 'Technical', 'set2': 'Simplified',\n",
        "                'set3': 'Trend', 'all': 'Combined'}\n",
        "    print(f\"\\n‚≠ê BEST: {set_names[best[0]]} (Acc: {best[1]['test_acc']:.4f})\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"‚úÖ T√úM TESTLER TAMAMLANDI\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "id": "c-SE4FYG7X2l",
        "outputId": "f955b304-43e5-4951-ac27-faac5984168b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì¶ K√ºt√ºphaneler y√ºkleniyor...\n",
            "‚úÖ Kurulum tamamlandƒ±!\n",
            "\n",
            "================================================================================\n",
            "VERƒ∞ √áEKME\n",
            "================================================================================\n",
            "KSE100... ‚úÖ 2346 g√ºn\n",
            "KOSPI... ‚úÖ 2397 g√ºn\n",
            "Nikkei225... ‚úÖ 2382 g√ºn\n",
            "SZSE... ‚úÖ 2366 g√ºn\n",
            "‚úÖ 4 borsa\n",
            "\n",
            "\n",
            "================================================================================\n",
            "MODEL Eƒûƒ∞Tƒ∞Mƒ∞ - FEATURE SET KAR≈ûILA≈ûTIRMASI\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "KOSPI\n",
            "================================================================================\n",
            "\n",
            "üìä Technical Indicators\n",
            "--------------------------------------------------------------------------------\n",
            "  Veri: 2376 | Train: 1900 | Test: 476\n",
            "  Features: 15 | Up%: 51.4%\n",
            "\n",
            "  Technical Indicators - Bayesian Optimization...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1vGe985W7ZUX"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}