{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QS8NOw3pqKSB",
        "outputId": "b47bfd83-0246-422b-ea81-4c888a11f136"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üì¶ VERSƒ∞YON 1: Normalization LAG √∂ncesi\n",
            "‚úÖ Kurulum tamamlandƒ±!\n",
            "\n",
            "================================================================================\n",
            "LEVEL 1: VERƒ∞ √áEKME (2011-01-01 to 2020-09-27)\n",
            "================================================================================\n",
            "\n",
            "üìä KSE100 (^KSE)... ‚úÖ 2346 g√ºn\n",
            "\n",
            "üìä KOSPI (^KS11)... ‚úÖ 2397 g√ºn\n",
            "\n",
            "üìä Nikkei225 (^N225)... ‚úÖ 2382 g√ºn\n",
            "\n",
            "üìä SZSE (000001.SS)... ‚úÖ 2366 g√ºn\n",
            "\n",
            "================================================================================\n",
            "‚úÖ 4 borsa √ßekildi\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "LEVEL 2: 15 TEKNƒ∞K G√ñSTERGE (Table 1)\n",
            "================================================================================\n",
            "\n",
            "KSE100... ‚úÖ 2346 satƒ±r\n",
            "\n",
            "KOSPI... ‚úÖ 2397 satƒ±r\n",
            "\n",
            "Nikkei225... ‚úÖ 2382 satƒ±r\n",
            "\n",
            "SZSE... ‚úÖ 2366 satƒ±r\n",
            "\n",
            "================================================================================\n",
            "‚úÖ G√∂stergeler hesaplandƒ±\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "LEVEL 3: VERƒ∞ HAZIRLAMA (NORMALIZATION LAG √ñNCESƒ∞)\n",
            "================================================================================\n",
            "\n",
            "KSE100:\n",
            " Veri: 2325 satƒ±r | Up: 53.5%\n",
            " Train: 1860 | Test: 465\n",
            "\n",
            "KOSPI:\n",
            " Veri: 2376 satƒ±r | Up: 52.4%\n",
            " Train: 1900 | Test: 476\n",
            "\n",
            "Nikkei225:\n",
            " Veri: 2361 satƒ±r | Up: 53.1%\n",
            " Train: 1888 | Test: 473\n",
            "\n",
            "SZSE:\n",
            " Veri: 2345 satƒ±r | Up: 52.8%\n",
            " Train: 1876 | Test: 469\n",
            "\n",
            "================================================================================\n",
            "‚úÖ 4 borsa hazƒ±r\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "LEVEL 4: SVM LINEAR KERNEL (Hƒ±zlƒ± Test)\n",
            "================================================================================\n",
            "\n",
            "KOSPI:\n",
            " ----------------------------------------------------------------------\n",
            " Best C: 0.001\n",
            " CV Score: 0.5137\n",
            " Test Acc: 0.5630 | F1: 0.7204\n",
            "\n",
            "================================================================================\n",
            "‚úÖ VERSƒ∞YON 1 TEST TAMAMLANDI\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "============================================================================\n",
        "VERSƒ∞YON 1: NORMALIZATION LAG √ñNCESƒ∞\n",
        "============================================================================\n",
        "Hipotez: Normalization indicator'lar hesaplandƒ±ktan hemen sonra yapƒ±lmalƒ±,\n",
        "         lag'den √ñNCE!\n",
        "============================================================================\n",
        "\"\"\"\n",
        "\n",
        "import sys\n",
        "import subprocess\n",
        "print(\"üì¶ VERSƒ∞YON 1: Normalization LAG √∂ncesi\")\n",
        "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\",\n",
        "                      \"yfinance\", \"ta\", \"scikit-learn\", \"pandas\", \"numpy\"])\n",
        "\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import ta\n",
        "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"‚úÖ Kurulum tamamlandƒ±!\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# LEVEL 1: VERƒ∞ √áEKME\n",
        "# ============================================================================\n",
        "print(\"=\"*80)\n",
        "print(\"LEVEL 1: VERƒ∞ √áEKME (2011-01-01 to 2020-09-27)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "tickers = {\n",
        "    'KSE100': '^KSE',\n",
        "    'KOSPI': '^KS11',\n",
        "    'Nikkei225': '^N225',\n",
        "    'SZSE': '000001.SS'\n",
        "}\n",
        "\n",
        "all_data = {}\n",
        "for name, ticker in tickers.items():\n",
        "    print(f\"\\nüìä {name} ({ticker})...\", end=\" \")\n",
        "    try:\n",
        "        data = yf.download(ticker, start=\"2011-01-01\", end=\"2020-09-27\",\n",
        "                          progress=False, auto_adjust=True)\n",
        "\n",
        "        if data.empty:\n",
        "            print(\"‚ùå VERƒ∞ YOK!\")\n",
        "            continue\n",
        "\n",
        "        if isinstance(data.columns, pd.MultiIndex):\n",
        "            data.columns = data.columns.get_level_values(0)\n",
        "\n",
        "        data = data[['Open', 'High', 'Low', 'Close', 'Volume']].copy()\n",
        "        data = data.dropna()\n",
        "\n",
        "        all_data[name] = data\n",
        "        print(f\"‚úÖ {len(data)} g√ºn\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå {e}\")\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(f\"‚úÖ {len(all_data)} borsa √ßekildi\")\n",
        "print(f\"{'='*80}\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# LEVEL 2: TEKNƒ∞K G√ñSTERGELER (Table 1)\n",
        "# ============================================================================\n",
        "print(\"=\"*80)\n",
        "print(\"LEVEL 2: 15 TEKNƒ∞K G√ñSTERGE (Table 1)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "def hesapla_teknik_gostergeler(df):\n",
        "    \"\"\"Makalenin Table 1 form√ºllerine g√∂re\"\"\"\n",
        "    df = df.copy()\n",
        "\n",
        "    high = df['High'].squeeze()\n",
        "    low = df['Low'].squeeze()\n",
        "    close = df['Close'].squeeze()\n",
        "\n",
        "    # 1-2. Stochastic Oscillator\n",
        "    stoch = ta.momentum.StochasticOscillator(high, low, close,\n",
        "                                             window=14, smooth_window=3)\n",
        "    df['Stochastic_K'] = stoch.stoch()\n",
        "    df['Stochastic_D'] = stoch.stoch_signal()\n",
        "\n",
        "    # 3. ROC (10 period)\n",
        "    df['ROC'] = ta.momentum.ROCIndicator(close, window=10).roc()\n",
        "\n",
        "    # 4. Williams %R (14 period)\n",
        "    df['Williams_R'] = ta.momentum.WilliamsRIndicator(high, low, close,\n",
        "                                                       lbp=14).williams_r()\n",
        "\n",
        "    # 5. Momentum (4 period: C_t - C_{t-4})\n",
        "    df['Momentum'] = close.diff(4)\n",
        "\n",
        "    # 6. Disparity 5\n",
        "    ma5 = close.rolling(5).mean()\n",
        "    df['Disparity_5'] = np.where(ma5 != 0, (close / ma5) * 100, 100)\n",
        "\n",
        "    # 7. Disparity 14 (makalede 15 yazƒ±yor ama 14 kullanƒ±lmƒ±≈ü)\n",
        "    ma14 = close.rolling(14).mean()\n",
        "    df['Disparity_14'] = np.where(ma14 != 0, (close / ma14) * 100, 100)\n",
        "\n",
        "    # 8. OSCP (Price Oscillator)\n",
        "    ma10 = close.rolling(10).mean()\n",
        "    df['OSCP'] = np.where(ma5 != 0, ((ma5 - ma10) / ma5), 0)\n",
        "\n",
        "    # 9. CCI (20 period)\n",
        "    df['CCI'] = ta.trend.CCIIndicator(high, low, close, window=20).cci()\n",
        "\n",
        "    # 10. RSI (14 period)\n",
        "    df['RSI'] = ta.momentum.RSIIndicator(close, window=14).rsi()\n",
        "\n",
        "    # 11-15. Pivot Points (Table 1 formulas)\n",
        "    prev_high = high.shift(1)\n",
        "    prev_low = low.shift(1)\n",
        "    prev_close = close.shift(1)\n",
        "\n",
        "    df['Pivot_Point'] = (prev_high + prev_low + prev_close) / 3\n",
        "    df['S1'] = (df['Pivot_Point'] * 2) - prev_high\n",
        "    df['S2'] = df['Pivot_Point'] - (prev_high - prev_low)\n",
        "    df['R1'] = (df['Pivot_Point'] * 2) - prev_low\n",
        "    df['R2'] = df['Pivot_Point'] + (prev_high - prev_low)\n",
        "\n",
        "    # Inf/NaN temizleme\n",
        "    df = df.replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "    return df\n",
        "\n",
        "all_data_indicators = {}\n",
        "for name, data in all_data.items():\n",
        "    print(f\"\\n{name}...\", end=\" \")\n",
        "    try:\n",
        "        result = hesapla_teknik_gostergeler(data)\n",
        "        all_data_indicators[name] = result\n",
        "        print(f\"‚úÖ {len(result)} satƒ±r\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå {e}\")\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(f\"‚úÖ G√∂stergeler hesaplandƒ±\")\n",
        "print(f\"{'='*80}\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# LEVEL 3: VERƒ∞ HAZIRLAMA - NORMALIZATION LAG √ñNCESƒ∞\n",
        "# ============================================================================\n",
        "print(\"=\"*80)\n",
        "print(\"LEVEL 3: VERƒ∞ HAZIRLAMA (NORMALIZATION LAG √ñNCESƒ∞)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "def veri_hazirla(df, test_ratio=0.2):\n",
        "    \"\"\"\n",
        "    üéØ VERSƒ∞YON 1: Normalization LAG √∂ncesi\n",
        "\n",
        "    1. Indicator'larƒ± hesapla\n",
        "    2. NORMALIZE ET (t√ºm veri seti)\n",
        "    3. Lag uygula\n",
        "    4. Train/Test split\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "\n",
        "    features = ['Stochastic_K', 'Stochastic_D', 'ROC', 'Williams_R',\n",
        "                'Momentum', 'Disparity_5', 'Disparity_14', 'OSCP',\n",
        "                'CCI', 'RSI', 'Pivot_Point', 'S1', 'S2', 'R1', 'R2']\n",
        "\n",
        "    # 1Ô∏è‚É£ Target olu≈ütur (forward-looking)\n",
        "    df['Next_Close'] = df['Close'].shift(-1)\n",
        "    df['Target'] = (df['Next_Close'] > df['Close']).astype(int)\n",
        "    df = df.iloc[:-1].copy()\n",
        "\n",
        "    # 2Ô∏è‚É£ NaN temizle\n",
        "    df = df.replace([np.inf, -np.inf], np.nan)\n",
        "    df = df.dropna(subset=features + ['Target'])\n",
        "\n",
        "    # 3Ô∏è‚É£ NORMALIZATION √ñNCE (t√ºm veri seti - data leakage var ama makale b√∂yle yapƒ±yor olabilir)\n",
        "    scaler = MinMaxScaler()\n",
        "    df[features] = scaler.fit_transform(df[features])\n",
        "\n",
        "    # 4Ô∏è‚É£ ≈ûƒ∞MDƒ∞ LAG UYGULA\n",
        "    lagged_features = []\n",
        "    for feat in features:\n",
        "        lagged_col = f'{feat}_lag1'\n",
        "        df[lagged_col] = df[feat].shift(1)\n",
        "        lagged_features.append(lagged_col)\n",
        "\n",
        "    # 5Ô∏è‚É£ Lag y√ºz√ºnden ilk satƒ±rƒ± drop\n",
        "    df = df.dropna(subset=lagged_features)\n",
        "\n",
        "    X = df[lagged_features].copy()\n",
        "    y = df['Target'].copy()\n",
        "\n",
        "    print(f\" Veri: {len(X)} satƒ±r | Up: {y.mean()*100:.1f}%\")\n",
        "\n",
        "    # 6Ô∏è‚É£ Zaman bazlƒ± split\n",
        "    n_train = int(len(X) * (1 - test_ratio))\n",
        "    X_train = X.iloc[:n_train].copy()\n",
        "    X_test = X.iloc[n_train:].copy()\n",
        "    y_train = y.iloc[:n_train].values\n",
        "    y_test = y.iloc[n_train:].values\n",
        "\n",
        "    print(f\" Train: {len(X_train)} | Test: {len(X_test)}\")\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "prepared_data = {}\n",
        "for name, data in all_data_indicators.items():\n",
        "    print(f\"\\n{name}:\")\n",
        "    try:\n",
        "        X_train, X_test, y_train, y_test = veri_hazirla(data)\n",
        "        prepared_data[name] = {\n",
        "            'X_train': X_train, 'X_test': X_test,\n",
        "            'y_train': y_train, 'y_test': y_test\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\" ‚ùå {e}\")\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(f\"‚úÖ {len(prepared_data)} borsa hazƒ±r\")\n",
        "print(f\"{'='*80}\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# LEVEL 4: SVM SADECE LINEAR (HIZLI TEST)\n",
        "# ============================================================================\n",
        "print(\"=\"*80)\n",
        "print(\"LEVEL 4: SVM LINEAR KERNEL (Hƒ±zlƒ± Test)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "for name in ['KOSPI']:  # Sadece KOSPI test\n",
        "    print(f\"\\n{name}:\")\n",
        "    print(f\" {'-'*70}\")\n",
        "\n",
        "    data = prepared_data[name]\n",
        "\n",
        "    try:\n",
        "        param_grid = {\n",
        "            'C': [0.001, 0.01, 0.1, 1, 4, 10, 50, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000]\n",
        "        }\n",
        "\n",
        "        cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "        svm = SVC(kernel='linear', max_iter=50000, random_state=42)\n",
        "        grid = GridSearchCV(svm, param_grid, cv=cv, scoring='accuracy', n_jobs=-1, verbose=0)\n",
        "        grid.fit(data['X_train'], data['y_train'])\n",
        "\n",
        "        best_model = grid.best_estimator_\n",
        "        y_pred = best_model.predict(data['X_test'])\n",
        "\n",
        "        acc = accuracy_score(data['y_test'], y_pred)\n",
        "        f1 = f1_score(data['y_test'], y_pred, zero_division=0)\n",
        "\n",
        "        print(f\" Best C: {grid.best_params_['C']}\")\n",
        "        print(f\" CV Score: {grid.best_score_:.4f}\")\n",
        "        print(f\" Test Acc: {acc:.4f} | F1: {f1:.4f}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\" ‚ùå {e}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"‚úÖ VERSƒ∞YON 1 TEST TAMAMLANDI\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8OvqzM_yqLSU",
        "outputId": "5114935b-b3f8-4dfe-ea0a-9eb31b43a45a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üì¶ VERSƒ∞YON 2: Target Same-Day\n",
            "‚úÖ Kurulum tamamlandƒ±!\n",
            "\n",
            "================================================================================\n",
            "LEVEL 1: VERƒ∞ √áEKME (2011-01-01 to 2020-09-27)\n",
            "================================================================================\n",
            "\n",
            "üìä KSE100 (^KSE)... ‚úÖ 2346 g√ºn\n",
            "\n",
            "üìä KOSPI (^KS11)... ‚úÖ 2397 g√ºn\n",
            "\n",
            "üìä Nikkei225 (^N225)... ‚úÖ 2382 g√ºn\n",
            "\n",
            "üìä SZSE (000001.SS)... ‚úÖ 2366 g√ºn\n",
            "\n",
            "================================================================================\n",
            "‚úÖ 4 borsa √ßekildi\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "LEVEL 2: 15 TEKNƒ∞K G√ñSTERGE (Table 1)\n",
            "================================================================================\n",
            "\n",
            "KSE100... ‚úÖ 2346 satƒ±r\n",
            "\n",
            "KOSPI... ‚úÖ 2397 satƒ±r\n",
            "\n",
            "Nikkei225... ‚úÖ 2382 satƒ±r\n",
            "\n",
            "SZSE... ‚úÖ 2366 satƒ±r\n",
            "\n",
            "================================================================================\n",
            "‚úÖ G√∂stergeler hesaplandƒ±\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "LEVEL 3: VERƒ∞ HAZIRLAMA (TARGET SAME-DAY)\n",
            "================================================================================\n",
            "\n",
            "KSE100:\n",
            " Veri: 2326 satƒ±r | Up: 53.5%\n",
            " Train: 1860 | Test: 466\n",
            "\n",
            "KOSPI:\n",
            " Veri: 2377 satƒ±r | Up: 52.3%\n",
            " Train: 1901 | Test: 476\n",
            "\n",
            "Nikkei225:\n",
            " Veri: 2362 satƒ±r | Up: 53.1%\n",
            " Train: 1889 | Test: 473\n",
            "\n",
            "SZSE:\n",
            " Veri: 2346 satƒ±r | Up: 52.9%\n",
            " Train: 1876 | Test: 470\n",
            "\n",
            "================================================================================\n",
            "‚úÖ 4 borsa hazƒ±r\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "LEVEL 4: SVM LINEAR KERNEL (Hƒ±zlƒ± Test)\n",
            "================================================================================\n",
            "\n",
            "KOSPI:\n",
            " ----------------------------------------------------------------------\n",
            " Best C: 900\n",
            " CV Score: 0.5187\n",
            " Test Acc: 0.5147 | F1: 0.5295\n",
            "\n",
            "================================================================================\n",
            "‚úÖ VERSƒ∞YON 2 TEST TAMAMLANDI\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "============================================================================\n",
        "VERSƒ∞YON 2: TARGET SAME-DAY\n",
        "============================================================================\n",
        "Hipotez: Target aynƒ± g√ºn i√ßinde olmalƒ±!\n",
        "         Feature: T-1 g√ºn√º indicator'larƒ±\n",
        "         Target: T g√ºn√º Close > T g√ºn√º Open mi? (veya T > T-1)\n",
        "============================================================================\n",
        "\"\"\"\n",
        "\n",
        "import sys\n",
        "import subprocess\n",
        "print(\"üì¶ VERSƒ∞YON 2: Target Same-Day\")\n",
        "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\",\n",
        "                      \"yfinance\", \"ta\", \"scikit-learn\", \"pandas\", \"numpy\"])\n",
        "\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import ta\n",
        "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"‚úÖ Kurulum tamamlandƒ±!\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# LEVEL 1: VERƒ∞ √áEKME\n",
        "# ============================================================================\n",
        "print(\"=\"*80)\n",
        "print(\"LEVEL 1: VERƒ∞ √áEKME (2011-01-01 to 2020-09-27)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "tickers = {\n",
        "    'KSE100': '^KSE',\n",
        "    'KOSPI': '^KS11',\n",
        "    'Nikkei225': '^N225',\n",
        "    'SZSE': '000001.SS'\n",
        "}\n",
        "\n",
        "all_data = {}\n",
        "for name, ticker in tickers.items():\n",
        "    print(f\"\\nüìä {name} ({ticker})...\", end=\" \")\n",
        "    try:\n",
        "        data = yf.download(ticker, start=\"2011-01-01\", end=\"2020-09-27\",\n",
        "                          progress=False, auto_adjust=True)\n",
        "\n",
        "        if data.empty:\n",
        "            print(\"‚ùå VERƒ∞ YOK!\")\n",
        "            continue\n",
        "\n",
        "        if isinstance(data.columns, pd.MultiIndex):\n",
        "            data.columns = data.columns.get_level_values(0)\n",
        "\n",
        "        data = data[['Open', 'High', 'Low', 'Close', 'Volume']].copy()\n",
        "        data = data.dropna()\n",
        "\n",
        "        all_data[name] = data\n",
        "        print(f\"‚úÖ {len(data)} g√ºn\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå {e}\")\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(f\"‚úÖ {len(all_data)} borsa √ßekildi\")\n",
        "print(f\"{'='*80}\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# LEVEL 2: TEKNƒ∞K G√ñSTERGELER (Table 1)\n",
        "# ============================================================================\n",
        "print(\"=\"*80)\n",
        "print(\"LEVEL 2: 15 TEKNƒ∞K G√ñSTERGE (Table 1)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "def hesapla_teknik_gostergeler(df):\n",
        "    \"\"\"Makalenin Table 1 form√ºllerine g√∂re\"\"\"\n",
        "    df = df.copy()\n",
        "\n",
        "    high = df['High'].squeeze()\n",
        "    low = df['Low'].squeeze()\n",
        "    close = df['Close'].squeeze()\n",
        "\n",
        "    # 1-2. Stochastic Oscillator\n",
        "    stoch = ta.momentum.StochasticOscillator(high, low, close,\n",
        "                                             window=14, smooth_window=3)\n",
        "    df['Stochastic_K'] = stoch.stoch()\n",
        "    df['Stochastic_D'] = stoch.stoch_signal()\n",
        "\n",
        "    # 3. ROC (10 period)\n",
        "    df['ROC'] = ta.momentum.ROCIndicator(close, window=10).roc()\n",
        "\n",
        "    # 4. Williams %R (14 period)\n",
        "    df['Williams_R'] = ta.momentum.WilliamsRIndicator(high, low, close,\n",
        "                                                       lbp=14).williams_r()\n",
        "\n",
        "    # 5. Momentum (4 period: C_t - C_{t-4})\n",
        "    df['Momentum'] = close.diff(4)\n",
        "\n",
        "    # 6. Disparity 5\n",
        "    ma5 = close.rolling(5).mean()\n",
        "    df['Disparity_5'] = np.where(ma5 != 0, (close / ma5) * 100, 100)\n",
        "\n",
        "    # 7. Disparity 14 (makalede 15 yazƒ±yor ama 14 kullanƒ±lmƒ±≈ü)\n",
        "    ma14 = close.rolling(14).mean()\n",
        "    df['Disparity_14'] = np.where(ma14 != 0, (close / ma14) * 100, 100)\n",
        "\n",
        "    # 8. OSCP (Price Oscillator)\n",
        "    ma10 = close.rolling(10).mean()\n",
        "    df['OSCP'] = np.where(ma5 != 0, ((ma5 - ma10) / ma5), 0)\n",
        "\n",
        "    # 9. CCI (20 period)\n",
        "    df['CCI'] = ta.trend.CCIIndicator(high, low, close, window=20).cci()\n",
        "\n",
        "    # 10. RSI (14 period)\n",
        "    df['RSI'] = ta.momentum.RSIIndicator(close, window=14).rsi()\n",
        "\n",
        "    # 11-15. Pivot Points (Table 1 formulas)\n",
        "    prev_high = high.shift(1)\n",
        "    prev_low = low.shift(1)\n",
        "    prev_close = close.shift(1)\n",
        "\n",
        "    df['Pivot_Point'] = (prev_high + prev_low + prev_close) / 3\n",
        "    df['S1'] = (df['Pivot_Point'] * 2) - prev_high\n",
        "    df['S2'] = df['Pivot_Point'] - (prev_high - prev_low)\n",
        "    df['R1'] = (df['Pivot_Point'] * 2) - prev_low\n",
        "    df['R2'] = df['Pivot_Point'] + (prev_high - prev_low)\n",
        "\n",
        "    # Inf/NaN temizleme\n",
        "    df = df.replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "    return df\n",
        "\n",
        "all_data_indicators = {}\n",
        "for name, data in all_data.items():\n",
        "    print(f\"\\n{name}...\", end=\" \")\n",
        "    try:\n",
        "        result = hesapla_teknik_gostergeler(data)\n",
        "        all_data_indicators[name] = result\n",
        "        print(f\"‚úÖ {len(result)} satƒ±r\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå {e}\")\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(f\"‚úÖ G√∂stergeler hesaplandƒ±\")\n",
        "print(f\"{'='*80}\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# LEVEL 3: VERƒ∞ HAZIRLAMA - TARGET SAME-DAY\n",
        "# ============================================================================\n",
        "print(\"=\"*80)\n",
        "print(\"LEVEL 3: VERƒ∞ HAZIRLAMA (TARGET SAME-DAY)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "def veri_hazirla(df, test_ratio=0.2):\n",
        "    \"\"\"\n",
        "    üéØ VERSƒ∞YON 2: Target same-day (T g√ºn√º)\n",
        "\n",
        "    Feature: T-1 g√ºn√º indicator'larƒ±\n",
        "    Target: T g√ºn√º Close > T-1 g√ºn√º Close mi?\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "\n",
        "    features = ['Stochastic_K', 'Stochastic_D', 'ROC', 'Williams_R',\n",
        "                'Momentum', 'Disparity_5', 'Disparity_14', 'OSCP',\n",
        "                'CCI', 'RSI', 'Pivot_Point', 'S1', 'S2', 'R1', 'R2']\n",
        "\n",
        "    # 1Ô∏è‚É£ Target: T g√ºn√º > T-1 g√ºn√º mi?\n",
        "    df['Target'] = (df['Close'] > df['Close'].shift(1)).astype(int)\n",
        "\n",
        "    # 2Ô∏è‚É£ Feature'larƒ± lag'le (T-1)\n",
        "    lagged_features = []\n",
        "    for feat in features:\n",
        "        lagged_col = f'{feat}_lag1'\n",
        "        df[lagged_col] = df[feat].shift(1)\n",
        "        lagged_features.append(lagged_col)\n",
        "\n",
        "    # 3Ô∏è‚É£ NaN temizle\n",
        "    df = df.replace([np.inf, -np.inf], np.nan)\n",
        "    df = df.dropna(subset=lagged_features + ['Target'])\n",
        "\n",
        "    X = df[lagged_features].copy()\n",
        "    y = df['Target'].copy()\n",
        "\n",
        "    print(f\" Veri: {len(X)} satƒ±r | Up: {y.mean()*100:.1f}%\")\n",
        "\n",
        "    # 4Ô∏è‚É£ Zaman bazlƒ± split\n",
        "    n_train = int(len(X) * (1 - test_ratio))\n",
        "    X_train = X.iloc[:n_train].copy()\n",
        "    X_test = X.iloc[n_train:].copy()\n",
        "    y_train = y.iloc[:n_train].copy()\n",
        "    y_test = y.iloc[n_train:].copy()\n",
        "\n",
        "    # 5Ô∏è‚É£ Normalization (train/test ayrƒ± ayrƒ±)\n",
        "    scaler = MinMaxScaler()\n",
        "    X_train_scaled = pd.DataFrame(\n",
        "        scaler.fit_transform(X_train),\n",
        "        columns=lagged_features,\n",
        "        index=X_train.index\n",
        "    )\n",
        "    X_test_scaled = pd.DataFrame(\n",
        "        scaler.transform(X_test),\n",
        "        columns=lagged_features,\n",
        "        index=X_test.index\n",
        "    )\n",
        "\n",
        "    print(f\" Train: {len(X_train_scaled)} | Test: {len(X_test_scaled)}\")\n",
        "\n",
        "    return X_train_scaled, X_test_scaled, y_train.values, y_test.values\n",
        "\n",
        "prepared_data = {}\n",
        "for name, data in all_data_indicators.items():\n",
        "    print(f\"\\n{name}:\")\n",
        "    try:\n",
        "        X_train, X_test, y_train, y_test = veri_hazirla(data)\n",
        "        prepared_data[name] = {\n",
        "            'X_train': X_train, 'X_test': X_test,\n",
        "            'y_train': y_train, 'y_test': y_test\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\" ‚ùå {e}\")\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(f\"‚úÖ {len(prepared_data)} borsa hazƒ±r\")\n",
        "print(f\"{'='*80}\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# LEVEL 4: SVM SADECE LINEAR (HIZLI TEST)\n",
        "# ============================================================================\n",
        "print(\"=\"*80)\n",
        "print(\"LEVEL 4: SVM LINEAR KERNEL (Hƒ±zlƒ± Test)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "for name in ['KOSPI']:  # Sadece KOSPI test\n",
        "    print(f\"\\n{name}:\")\n",
        "    print(f\" {'-'*70}\")\n",
        "\n",
        "    data = prepared_data[name]\n",
        "\n",
        "    try:\n",
        "        param_grid = {\n",
        "            'C': [0.001, 0.01, 0.1, 1, 4, 10, 50, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000]\n",
        "        }\n",
        "\n",
        "        cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "        svm = SVC(kernel='linear', max_iter=50000, random_state=42)\n",
        "        grid = GridSearchCV(svm, param_grid, cv=cv, scoring='accuracy', n_jobs=-1, verbose=0)\n",
        "        grid.fit(data['X_train'], data['y_train'])\n",
        "\n",
        "        best_model = grid.best_estimator_\n",
        "        y_pred = best_model.predict(data['X_test'])\n",
        "\n",
        "        acc = accuracy_score(data['y_test'], y_pred)\n",
        "        f1 = f1_score(data['y_test'], y_pred, zero_division=0)\n",
        "\n",
        "        print(f\" Best C: {grid.best_params_['C']}\")\n",
        "        print(f\" CV Score: {grid.best_score_:.4f}\")\n",
        "        print(f\" Test Acc: {acc:.4f} | F1: {f1:.4f}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\" ‚ùå {e}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"‚úÖ VERSƒ∞YON 2 TEST TAMAMLANDI\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8xWXdCo98t-u",
        "outputId": "a107e761-b115-49b7-870d-c6bb36eb905a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üì¶ VERSƒ∞YON 3: Pivot Points Double-Lag Fix\n",
            "‚úÖ Kurulum tamamlandƒ±!\n",
            "\n",
            "================================================================================\n",
            "LEVEL 1: VERƒ∞ √áEKME (2011-01-01 to 2020-09-27)\n",
            "================================================================================\n",
            "\n",
            "üìä KSE100 (^KSE)... ‚úÖ 2346 g√ºn\n",
            "\n",
            "üìä KOSPI (^KS11)... ‚úÖ 2397 g√ºn\n",
            "\n",
            "üìä Nikkei225 (^N225)... ‚úÖ 2382 g√ºn\n",
            "\n",
            "üìä SZSE (000001.SS)... ‚úÖ 2366 g√ºn\n",
            "\n",
            "================================================================================\n",
            "‚úÖ 4 borsa √ßekildi\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "LEVEL 2: 15 TEKNƒ∞K G√ñSTERGE (Pivot Points D√ºzeltildi)\n",
            "================================================================================\n",
            "\n",
            "KSE100... ‚úÖ 2346 satƒ±r\n",
            "\n",
            "KOSPI... ‚úÖ 2397 satƒ±r\n",
            "\n",
            "Nikkei225... ‚úÖ 2382 satƒ±r\n",
            "\n",
            "SZSE... ‚úÖ 2366 satƒ±r\n",
            "\n",
            "================================================================================\n",
            "‚úÖ G√∂stergeler hesaplandƒ±\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "LEVEL 3: VERƒ∞ HAZIRLAMA\n",
            "================================================================================\n",
            "\n",
            "KSE100:\n",
            " Veri: 2325 satƒ±r | Up: 53.5%\n",
            " Train: 1860 | Test: 465\n",
            "\n",
            "KOSPI:\n",
            " Veri: 2376 satƒ±r | Up: 52.4%\n",
            " Train: 1900 | Test: 476\n",
            "\n",
            "Nikkei225:\n",
            " Veri: 2361 satƒ±r | Up: 53.1%\n",
            " Train: 1888 | Test: 473\n",
            "\n",
            "SZSE:\n",
            " Veri: 2345 satƒ±r | Up: 52.8%\n",
            " Train: 1876 | Test: 469\n",
            "\n",
            "================================================================================\n",
            "‚úÖ 4 borsa hazƒ±r\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "LEVEL 4: SVM LINEAR KERNEL (Hƒ±zlƒ± Test)\n",
            "================================================================================\n",
            "\n",
            "KOSPI:\n",
            " ----------------------------------------------------------------------\n",
            " Best C: 0.001\n",
            " CV Score: 0.5137\n",
            " Test Acc: 0.5630 | F1: 0.7204\n",
            "\n",
            "================================================================================\n",
            "‚úÖ VERSƒ∞YON 3 TEST TAMAMLANDI\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "============================================================================\n",
        "VERSƒ∞YON 3: PIVOT POINTS DOUBLE-LAG D√úZELTMESƒ∞\n",
        "============================================================================\n",
        "Hipotez: Pivot Points zaten shift(1) ile hesaplanƒ±yor,\n",
        "         sonra bir de biz lag yapƒ±nca double-lag oluyor!\n",
        "============================================================================\n",
        "\"\"\"\n",
        "\n",
        "import sys\n",
        "import subprocess\n",
        "print(\"üì¶ VERSƒ∞YON 3: Pivot Points Double-Lag Fix\")\n",
        "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\",\n",
        "                      \"yfinance\", \"ta\", \"scikit-learn\", \"pandas\", \"numpy\"])\n",
        "\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import ta\n",
        "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"‚úÖ Kurulum tamamlandƒ±!\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# LEVEL 1: VERƒ∞ √áEKME\n",
        "# ============================================================================\n",
        "print(\"=\"*80)\n",
        "print(\"LEVEL 1: VERƒ∞ √áEKME (2011-01-01 to 2020-09-27)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "tickers = {\n",
        "    'KSE100': '^KSE',\n",
        "    'KOSPI': '^KS11',\n",
        "    'Nikkei225': '^N225',\n",
        "    'SZSE': '000001.SS'\n",
        "}\n",
        "\n",
        "all_data = {}\n",
        "for name, ticker in tickers.items():\n",
        "    print(f\"\\nüìä {name} ({ticker})...\", end=\" \")\n",
        "    try:\n",
        "        data = yf.download(ticker, start=\"2011-01-01\", end=\"2020-09-27\",\n",
        "                          progress=False, auto_adjust=True)\n",
        "\n",
        "        if data.empty:\n",
        "            print(\"‚ùå VERƒ∞ YOK!\")\n",
        "            continue\n",
        "\n",
        "        if isinstance(data.columns, pd.MultiIndex):\n",
        "            data.columns = data.columns.get_level_values(0)\n",
        "\n",
        "        data = data[['Open', 'High', 'Low', 'Close', 'Volume']].copy()\n",
        "        data = data.dropna()\n",
        "\n",
        "        all_data[name] = data\n",
        "        print(f\"‚úÖ {len(data)} g√ºn\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå {e}\")\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(f\"‚úÖ {len(all_data)} borsa √ßekildi\")\n",
        "print(f\"{'='*80}\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# LEVEL 2: TEKNƒ∞K G√ñSTERGELER - PIVOT POINTS D√úZELTƒ∞LDƒ∞\n",
        "# ============================================================================\n",
        "print(\"=\"*80)\n",
        "print(\"LEVEL 2: 15 TEKNƒ∞K G√ñSTERGE (Pivot Points D√ºzeltildi)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "def hesapla_teknik_gostergeler(df):\n",
        "    \"\"\"Makalenin Table 1 form√ºllerine g√∂re - Pivot Points d√ºzeltildi\"\"\"\n",
        "    df = df.copy()\n",
        "\n",
        "    high = df['High'].squeeze()\n",
        "    low = df['Low'].squeeze()\n",
        "    close = df['Close'].squeeze()\n",
        "\n",
        "    # 1-2. Stochastic Oscillator\n",
        "    stoch = ta.momentum.StochasticOscillator(high, low, close,\n",
        "                                             window=14, smooth_window=3)\n",
        "    df['Stochastic_K'] = stoch.stoch()\n",
        "    df['Stochastic_D'] = stoch.stoch_signal()\n",
        "\n",
        "    # 3. ROC (10 period)\n",
        "    df['ROC'] = ta.momentum.ROCIndicator(close, window=10).roc()\n",
        "\n",
        "    # 4. Williams %R (14 period)\n",
        "    df['Williams_R'] = ta.momentum.WilliamsRIndicator(high, low, close,\n",
        "                                                       lbp=14).williams_r()\n",
        "\n",
        "    # 5. Momentum (4 period: C_t - C_{t-4})\n",
        "    df['Momentum'] = close.diff(4)\n",
        "\n",
        "    # 6. Disparity 5\n",
        "    ma5 = close.rolling(5).mean()\n",
        "    df['Disparity_5'] = np.where(ma5 != 0, (close / ma5) * 100, 100)\n",
        "\n",
        "    # 7. Disparity 14 (makalede 15 yazƒ±yor ama 14 kullanƒ±lmƒ±≈ü)\n",
        "    ma14 = close.rolling(14).mean()\n",
        "    df['Disparity_14'] = np.where(ma14 != 0, (close / ma14) * 100, 100)\n",
        "\n",
        "    # 8. OSCP (Price Oscillator)\n",
        "    ma10 = close.rolling(10).mean()\n",
        "    df['OSCP'] = np.where(ma5 != 0, ((ma5 - ma10) / ma5), 0)\n",
        "\n",
        "    # 9. CCI (20 period)\n",
        "    df['CCI'] = ta.trend.CCIIndicator(high, low, close, window=20).cci()\n",
        "\n",
        "    # 10. RSI (14 period)\n",
        "    df['RSI'] = ta.momentum.RSIIndicator(close, window=14).rsi()\n",
        "\n",
        "    # 11-15. Pivot Points - ≈ûƒ∞MDƒ∞ SHIFT KULLANMIYORUZ\n",
        "    # √á√ºnk√º sonra zaten lag yapacaƒüƒ±z!\n",
        "    df['Pivot_Point'] = (high + low + close) / 3\n",
        "    df['S1'] = (df['Pivot_Point'] * 2) - high\n",
        "    df['S2'] = df['Pivot_Point'] - (high - low)\n",
        "    df['R1'] = (df['Pivot_Point'] * 2) - low\n",
        "    df['R2'] = df['Pivot_Point'] + (high - low)\n",
        "\n",
        "    # Inf/NaN temizleme\n",
        "    df = df.replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "    return df\n",
        "\n",
        "all_data_indicators = {}\n",
        "for name, data in all_data.items():\n",
        "    print(f\"\\n{name}...\", end=\" \")\n",
        "    try:\n",
        "        result = hesapla_teknik_gostergeler(data)\n",
        "        all_data_indicators[name] = result\n",
        "        print(f\"‚úÖ {len(result)} satƒ±r\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå {e}\")\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(f\"‚úÖ G√∂stergeler hesaplandƒ±\")\n",
        "print(f\"{'='*80}\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# LEVEL 3: VERƒ∞ HAZIRLAMA (Standart)\n",
        "# ============================================================================\n",
        "print(\"=\"*80)\n",
        "print(\"LEVEL 3: VERƒ∞ HAZIRLAMA\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "def veri_hazirla(df, test_ratio=0.2):\n",
        "    \"\"\"\n",
        "    üéØ VERSƒ∞YON 3: Pivot Points double-lag d√ºzeltildi\n",
        "\n",
        "    Feature: T-1 g√ºn√º indicator'larƒ±\n",
        "    Target: T g√ºn√º ‚Üí T+1 g√ºn√º y√ºkseli≈ü mi?\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "\n",
        "    features = ['Stochastic_K', 'Stochastic_D', 'ROC', 'Williams_R',\n",
        "                'Momentum', 'Disparity_5', 'Disparity_14', 'OSCP',\n",
        "                'CCI', 'RSI', 'Pivot_Point', 'S1', 'S2', 'R1', 'R2']\n",
        "\n",
        "    # 1Ô∏è‚É£ Feature'larƒ± lag'le (T-1)\n",
        "    lagged_features = []\n",
        "    for feat in features:\n",
        "        lagged_col = f'{feat}_lag1'\n",
        "        df[lagged_col] = df[feat].shift(1)\n",
        "        lagged_features.append(lagged_col)\n",
        "\n",
        "    # 2Ô∏è‚É£ Target: T g√ºn√º ‚Üí T+1 g√ºn√º y√ºkseli≈ü mi?\n",
        "    df['Next_Close'] = df['Close'].shift(-1)\n",
        "    df['Target'] = (df['Next_Close'] > df['Close']).astype(int)\n",
        "    df = df.iloc[:-1].copy()\n",
        "\n",
        "    # 3Ô∏è‚É£ NaN temizle\n",
        "    df = df.replace([np.inf, -np.inf], np.nan)\n",
        "    df = df.dropna(subset=lagged_features + ['Target'])\n",
        "\n",
        "    X = df[lagged_features].copy()\n",
        "    y = df['Target'].copy()\n",
        "\n",
        "    print(f\" Veri: {len(X)} satƒ±r | Up: {y.mean()*100:.1f}%\")\n",
        "\n",
        "    # 4Ô∏è‚É£ Zaman bazlƒ± split\n",
        "    n_train = int(len(X) * (1 - test_ratio))\n",
        "    X_train = X.iloc[:n_train].copy()\n",
        "    X_test = X.iloc[n_train:].copy()\n",
        "    y_train = y.iloc[:n_train].copy()\n",
        "    y_test = y.iloc[n_train:].copy()\n",
        "\n",
        "    # 5Ô∏è‚É£ Normalization\n",
        "    scaler = MinMaxScaler()\n",
        "    X_train_scaled = pd.DataFrame(\n",
        "        scaler.fit_transform(X_train),\n",
        "        columns=lagged_features,\n",
        "        index=X_train.index\n",
        "    )\n",
        "    X_test_scaled = pd.DataFrame(\n",
        "        scaler.transform(X_test),\n",
        "        columns=lagged_features,\n",
        "        index=X_test.index\n",
        "    )\n",
        "\n",
        "    print(f\" Train: {len(X_train_scaled)} | Test: {len(X_test_scaled)}\")\n",
        "\n",
        "    return X_train_scaled, X_test_scaled, y_train.values, y_test.values\n",
        "\n",
        "prepared_data = {}\n",
        "for name, data in all_data_indicators.items():\n",
        "    print(f\"\\n{name}:\")\n",
        "    try:\n",
        "        X_train, X_test, y_train, y_test = veri_hazirla(data)\n",
        "        prepared_data[name] = {\n",
        "            'X_train': X_train, 'X_test': X_test,\n",
        "            'y_train': y_train, 'y_test': y_test\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\" ‚ùå {e}\")\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(f\"‚úÖ {len(prepared_data)} borsa hazƒ±r\")\n",
        "print(f\"{'='*80}\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# LEVEL 4: SVM SADECE LINEAR (HIZLI TEST)\n",
        "# ============================================================================\n",
        "print(\"=\"*80)\n",
        "print(\"LEVEL 4: SVM LINEAR KERNEL (Hƒ±zlƒ± Test)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "for name in ['KOSPI']:  # Sadece KOSPI test\n",
        "    print(f\"\\n{name}:\")\n",
        "    print(f\" {'-'*70}\")\n",
        "\n",
        "    data = prepared_data[name]\n",
        "\n",
        "    try:\n",
        "        param_grid = {\n",
        "            'C': [0.001, 0.01, 0.1, 1, 4, 10, 50, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000]\n",
        "        }\n",
        "\n",
        "        cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "        svm = SVC(kernel='linear', max_iter=50000, random_state=42)\n",
        "        grid = GridSearchCV(svm, param_grid, cv=cv, scoring='accuracy', n_jobs=-1, verbose=0)\n",
        "        grid.fit(data['X_train'], data['y_train'])\n",
        "\n",
        "        best_model = grid.best_estimator_\n",
        "        y_pred = best_model.predict(data['X_test'])\n",
        "\n",
        "        acc = accuracy_score(data['y_test'], y_pred)\n",
        "        f1 = f1_score(data['y_test'], y_pred, zero_division=0)\n",
        "\n",
        "        print(f\" Best C: {grid.best_params_['C']}\")\n",
        "        print(f\" CV Score: {grid.best_score_:.4f}\")\n",
        "        print(f\" Test Acc: {acc:.4f} | F1: {f1:.4f}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\" ‚ùå {e}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"‚úÖ VERSƒ∞YON 3 TEST TAMAMLANDI\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "JYJpA3Ji9f_C",
        "outputId": "7045276e-b5e2-4feb-9688-c91202077b52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üì¶ VERSƒ∞YON 1 FULL: Normalization LAG √∂ncesi - T√úM SVM\n",
            "‚úÖ Kurulum tamamlandƒ±!\n",
            "\n",
            "================================================================================\n",
            "LEVEL 1: VERƒ∞ √áEKME (2011-01-01 to 2020-09-27)\n",
            "================================================================================\n",
            "\n",
            "üìä KSE100 (^KSE)... ‚úÖ 2346 g√ºn\n",
            "\n",
            "üìä KOSPI (^KS11)... ‚úÖ 2397 g√ºn\n",
            "\n",
            "üìä Nikkei225 (^N225)... ‚úÖ 2382 g√ºn\n",
            "\n",
            "üìä SZSE (000001.SS)... ‚úÖ 2366 g√ºn\n",
            "\n",
            "================================================================================\n",
            "‚úÖ 4 borsa √ßekildi\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "LEVEL 2: 15 TEKNƒ∞K G√ñSTERGE (Table 1)\n",
            "================================================================================\n",
            "\n",
            "KSE100... ‚úÖ 2346 satƒ±r\n",
            "\n",
            "KOSPI... ‚úÖ 2397 satƒ±r\n",
            "\n",
            "Nikkei225... ‚úÖ 2382 satƒ±r\n",
            "\n",
            "SZSE... ‚úÖ 2366 satƒ±r\n",
            "\n",
            "================================================================================\n",
            "‚úÖ G√∂stergeler hesaplandƒ±\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "LEVEL 3: VERƒ∞ HAZIRLAMA (NORMALIZATION LAG √ñNCESƒ∞)\n",
            "================================================================================\n",
            "\n",
            "KSE100:\n",
            " Veri: 2325 satƒ±r | Up: 53.5%\n",
            " Train: 1860 | Test: 465\n",
            "\n",
            "KOSPI:\n",
            " Veri: 2376 satƒ±r | Up: 52.4%\n",
            " Train: 1900 | Test: 476\n",
            "\n",
            "Nikkei225:\n",
            " Veri: 2361 satƒ±r | Up: 53.1%\n",
            " Train: 1888 | Test: 473\n",
            "\n",
            "SZSE:\n",
            " Veri: 2345 satƒ±r | Up: 52.8%\n",
            " Train: 1876 | Test: 469\n",
            "\n",
            "================================================================================\n",
            "‚úÖ 4 borsa hazƒ±r\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "LEVEL 4: SVM T√úM KERNELS (10-Fold CV + Grid Search)\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "KSE100\n",
            "================================================================================\n",
            "\n",
            " üîç LINEAR Kernel:\n",
            " ----------------------------------------------------------------------\n",
            " Best Params: {'C': 700}\n",
            " CV Score: 0.5457\n",
            " Test Acc: 0.5527 | F1: 0.5755\n",
            "\n",
            " üîç RBF Kernel:\n",
            " ----------------------------------------------------------------------\n",
            " ‚ùå cannot access local variable 'param_grid' where it is not associated with a value\n",
            "\n",
            " üîç POLY Kernel:\n",
            " ----------------------------------------------------------------------\n",
            " ‚ùå cannot access local variable 'param_grid' where it is not associated with a value\n",
            "\n",
            "================================================================================\n",
            "KOSPI\n",
            "================================================================================\n",
            "\n",
            " üîç LINEAR Kernel:\n",
            " ----------------------------------------------------------------------\n",
            " Best Params: {'C': 0.001}\n",
            " CV Score: 0.5137\n",
            " Test Acc: 0.5630 | F1: 0.7204\n",
            "\n",
            " üîç RBF Kernel:\n",
            " ----------------------------------------------------------------------\n",
            " ‚ùå cannot access local variable 'param_grid' where it is not associated with a value\n",
            "\n",
            " üîç POLY Kernel:\n",
            " ----------------------------------------------------------------------\n",
            " ‚ùå cannot access local variable 'param_grid' where it is not associated with a value\n",
            "\n",
            "================================================================================\n",
            "Nikkei225\n",
            "================================================================================\n",
            "\n",
            " üîç LINEAR Kernel:\n",
            " ----------------------------------------------------------------------\n",
            " Best Params: {'C': 0.001}\n",
            " CV Score: 0.5323\n",
            " Test Acc: 0.5243 | F1: 0.6879\n",
            "\n",
            " üîç RBF Kernel:\n",
            " ----------------------------------------------------------------------\n",
            " ‚ùå cannot access local variable 'param_grid' where it is not associated with a value\n",
            "\n",
            " üîç POLY Kernel:\n",
            " ----------------------------------------------------------------------\n",
            " ‚ùå cannot access local variable 'param_grid' where it is not associated with a value\n",
            "\n",
            "================================================================================\n",
            "SZSE\n",
            "================================================================================\n",
            "\n",
            " üîç LINEAR Kernel:\n",
            " ----------------------------------------------------------------------\n",
            " Best Params: {'C': 700}\n",
            " CV Score: 0.5272\n",
            " Test Acc: 0.5352 | F1: 0.6972\n",
            "\n",
            " üîç RBF Kernel:\n",
            " ----------------------------------------------------------------------\n",
            " ‚ùå cannot access local variable 'param_grid' where it is not associated with a value\n",
            "\n",
            " üîç POLY Kernel:\n",
            " ----------------------------------------------------------------------\n",
            " ‚ùå cannot access local variable 'param_grid' where it is not associated with a value\n",
            "\n",
            "================================================================================\n",
            "‚úÖ SVM tamamlandƒ±\n",
            "================================================================================\n",
            "\n",
            "\n",
            "================================================================================\n",
            "                    üìä FINAL SONU√áLAR - SVM\n",
            "               (Table 11 Makale Kar≈üƒ±la≈ütƒ±rmasƒ±)\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            " KSE100\n",
            "================================================================================\n",
            "\n",
            " Kernel          Accuracy     F-Score      Best Params\n",
            " ----------------------------------------------------------------------\n",
            " LINEAR          0.5527       0.5755       {'C': 700}\n",
            "\n",
            "================================================================================\n",
            " KOSPI\n",
            "================================================================================\n",
            "\n",
            " Kernel          Accuracy     F-Score      Best Params\n",
            " ----------------------------------------------------------------------\n",
            " LINEAR          0.5630       0.7204       {'C': 0.001}\n",
            "\n",
            "================================================================================\n",
            " Nikkei225\n",
            "================================================================================\n",
            "\n",
            " Kernel          Accuracy     F-Score      Best Params\n",
            " ----------------------------------------------------------------------\n",
            " LINEAR          0.5243       0.6879       {'C': 0.001}\n",
            "\n",
            "================================================================================\n",
            " SZSE\n",
            "================================================================================\n",
            "\n",
            " Kernel          Accuracy     F-Score      Best Params\n",
            " ----------------------------------------------------------------------\n",
            " LINEAR          0.5352       0.6972       {'C': 700}\n",
            "\n",
            "================================================================================\n",
            " üìà ORTALAMA PERFORMANS (4 Borsa)\n",
            "================================================================================\n",
            "\n",
            " Kernel          Avg Accuracy    Avg F-Score    \n",
            " --------------------------------------------------\n",
            " Linear          0.5438          0.6703         \n",
            " RBF             nan             nan            \n",
            " Poly            nan             nan            \n",
            "\n",
            "================================================================================\n",
            " üéØ MAKALE SONU√áLARI (Table 11 - SVM)\n",
            "================================================================================\n",
            "\n",
            " Index       Linear   RBF      Poly\n",
            " ---------------------------------------------\n",
            " KSE-100     0.8519   0.7688   0.8438\n",
            " KOSPI       0.8022   0.7626   0.7828\n",
            " Nikkei 225  0.8022   0.7626   0.7828\n",
            " SZSE        0.8998   0.8720   0.8941\n",
            "\n",
            "================================================================================\n",
            "‚úÖ VERSƒ∞YON 1 FULL SVM ANALƒ∞Zƒ∞ TAMAMLANDI\n",
            "================================================================================\n",
            "\n",
            "üí° √ñNEMLƒ∞ NOT:\n",
            " ‚ö†Ô∏è Bu versiyonda DATA LEAKAGE var!\n",
            " ‚ö†Ô∏è Normalization t√ºm veri setinde yapƒ±ldƒ± (train+test)\n",
            " ‚ö†Ô∏è Eƒüer sonu√ßlar makaleye yakƒ±nsa, makale de aynƒ± hatayƒ± yapƒ±yor olabilir!\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "============================================================================\n",
        "VERSƒ∞YON 1 FULL: NORMALIZATION LAG √ñNCESƒ∞ - T√úM SVM KERNELS\n",
        "============================================================================\n",
        "Hipotez: Makale normalization'ƒ± LAG √∂ncesi yapƒ±yor (data leakage var)\n",
        "         Bu y√ºzden y√ºksek accuracy elde ediyorlar!\n",
        "============================================================================\n",
        "\"\"\"\n",
        "\n",
        "import sys\n",
        "import subprocess\n",
        "print(\"üì¶ VERSƒ∞YON 1 FULL: Normalization LAG √∂ncesi - T√úM SVM\")\n",
        "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\",\n",
        "                      \"yfinance\", \"ta\", \"scikit-learn\", \"pandas\", \"numpy\"])\n",
        "\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import ta\n",
        "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"‚úÖ Kurulum tamamlandƒ±!\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# LEVEL 1: VERƒ∞ √áEKME\n",
        "# ============================================================================\n",
        "print(\"=\"*80)\n",
        "print(\"LEVEL 1: VERƒ∞ √áEKME (2011-01-01 to 2020-09-27)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "tickers = {\n",
        "    'KSE100': '^KSE',\n",
        "    'KOSPI': '^KS11',\n",
        "    'Nikkei225': '^N225',\n",
        "    'SZSE': '000001.SS'\n",
        "}\n",
        "\n",
        "all_data = {}\n",
        "for name, ticker in tickers.items():\n",
        "    print(f\"\\nüìä {name} ({ticker})...\", end=\" \")\n",
        "    try:\n",
        "        data = yf.download(ticker, start=\"2011-01-01\", end=\"2020-09-27\",\n",
        "                          progress=False, auto_adjust=True)\n",
        "\n",
        "        if data.empty:\n",
        "            print(\"‚ùå VERƒ∞ YOK!\")\n",
        "            continue\n",
        "\n",
        "        if isinstance(data.columns, pd.MultiIndex):\n",
        "            data.columns = data.columns.get_level_values(0)\n",
        "\n",
        "        data = data[['Open', 'High', 'Low', 'Close', 'Volume']].copy()\n",
        "        data = data.dropna()\n",
        "\n",
        "        all_data[name] = data\n",
        "        print(f\"‚úÖ {len(data)} g√ºn\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå {e}\")\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(f\"‚úÖ {len(all_data)} borsa √ßekildi\")\n",
        "print(f\"{'='*80}\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# LEVEL 2: TEKNƒ∞K G√ñSTERGELER (Table 1)\n",
        "# ============================================================================\n",
        "print(\"=\"*80)\n",
        "print(\"LEVEL 2: 15 TEKNƒ∞K G√ñSTERGE (Table 1)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "def hesapla_teknik_gostergeler(df):\n",
        "    \"\"\"Makalenin Table 1 form√ºllerine g√∂re\"\"\"\n",
        "    df = df.copy()\n",
        "\n",
        "    high = df['High'].squeeze()\n",
        "    low = df['Low'].squeeze()\n",
        "    close = df['Close'].squeeze()\n",
        "\n",
        "    # 1-2. Stochastic Oscillator\n",
        "    stoch = ta.momentum.StochasticOscillator(high, low, close,\n",
        "                                             window=14, smooth_window=3)\n",
        "    df['Stochastic_K'] = stoch.stoch()\n",
        "    df['Stochastic_D'] = stoch.stoch_signal()\n",
        "\n",
        "    # 3. ROC (10 period)\n",
        "    df['ROC'] = ta.momentum.ROCIndicator(close, window=10).roc()\n",
        "\n",
        "    # 4. Williams %R (14 period)\n",
        "    df['Williams_R'] = ta.momentum.WilliamsRIndicator(high, low, close,\n",
        "                                                       lbp=14).williams_r()\n",
        "\n",
        "    # 5. Momentum (4 period: C_t - C_{t-4})\n",
        "    df['Momentum'] = close.diff(4)\n",
        "\n",
        "    # 6. Disparity 5\n",
        "    ma5 = close.rolling(5).mean()\n",
        "    df['Disparity_5'] = np.where(ma5 != 0, (close / ma5) * 100, 100)\n",
        "\n",
        "    # 7. Disparity 14 (makalede 15 yazƒ±yor ama 14 kullanƒ±lmƒ±≈ü)\n",
        "    ma14 = close.rolling(14).mean()\n",
        "    df['Disparity_14'] = np.where(ma14 != 0, (close / ma14) * 100, 100)\n",
        "\n",
        "    # 8. OSCP (Price Oscillator)\n",
        "    ma10 = close.rolling(10).mean()\n",
        "    df['OSCP'] = np.where(ma5 != 0, ((ma5 - ma10) / ma5), 0)\n",
        "\n",
        "    # 9. CCI (20 period)\n",
        "    df['CCI'] = ta.trend.CCIIndicator(high, low, close, window=20).cci()\n",
        "\n",
        "    # 10. RSI (14 period)\n",
        "    df['RSI'] = ta.momentum.RSIIndicator(close, window=14).rsi()\n",
        "\n",
        "    # 11-15. Pivot Points (Table 1 formulas)\n",
        "    prev_high = high.shift(1)\n",
        "    prev_low = low.shift(1)\n",
        "    prev_close = close.shift(1)\n",
        "\n",
        "    df['Pivot_Point'] = (prev_high + prev_low + prev_close) / 3\n",
        "    df['S1'] = (df['Pivot_Point'] * 2) - prev_high\n",
        "    df['S2'] = df['Pivot_Point'] - (prev_high - prev_low)\n",
        "    df['R1'] = (df['Pivot_Point'] * 2) - prev_low\n",
        "    df['R2'] = df['Pivot_Point'] + (prev_high - prev_low)\n",
        "\n",
        "    # Inf/NaN temizleme\n",
        "    df = df.replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "    return df\n",
        "\n",
        "all_data_indicators = {}\n",
        "for name, data in all_data.items():\n",
        "    print(f\"\\n{name}...\", end=\" \")\n",
        "    try:\n",
        "        result = hesapla_teknik_gostergeler(data)\n",
        "        all_data_indicators[name] = result\n",
        "        print(f\"‚úÖ {len(result)} satƒ±r\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå {e}\")\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(f\"‚úÖ G√∂stergeler hesaplandƒ±\")\n",
        "print(f\"{'='*80}\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# LEVEL 3: VERƒ∞ HAZIRLAMA - NORMALIZATION LAG √ñNCESƒ∞\n",
        "# ============================================================================\n",
        "print(\"=\"*80)\n",
        "print(\"LEVEL 3: VERƒ∞ HAZIRLAMA (NORMALIZATION LAG √ñNCESƒ∞)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "def veri_hazirla(df, test_ratio=0.2):\n",
        "    \"\"\"\n",
        "    üéØ VERSƒ∞YON 1: Normalization LAG √∂ncesi (DATA LEAKAGE VAR!)\n",
        "\n",
        "    1. Indicator'larƒ± hesapla\n",
        "    2. NORMALIZE ET (t√ºm veri seti - data leakage!)\n",
        "    3. Lag uygula\n",
        "    4. Train/Test split\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "\n",
        "    features = ['Stochastic_K', 'Stochastic_D', 'ROC', 'Williams_R',\n",
        "                'Momentum', 'Disparity_5', 'Disparity_14', 'OSCP',\n",
        "                'CCI', 'RSI', 'Pivot_Point', 'S1', 'S2', 'R1', 'R2']\n",
        "\n",
        "    # 1Ô∏è‚É£ Target olu≈ütur (forward-looking)\n",
        "    df['Next_Close'] = df['Close'].shift(-1)\n",
        "    df['Target'] = (df['Next_Close'] > df['Close']).astype(int)\n",
        "    df = df.iloc[:-1].copy()\n",
        "\n",
        "    # 2Ô∏è‚É£ NaN temizle\n",
        "    df = df.replace([np.inf, -np.inf], np.nan)\n",
        "    df = df.dropna(subset=features + ['Target'])\n",
        "\n",
        "    # 3Ô∏è‚É£ ‚ö†Ô∏è NORMALIZATION √ñNCE (t√ºm veri seti - data leakage!)\n",
        "    scaler = MinMaxScaler()\n",
        "    df[features] = scaler.fit_transform(df[features])\n",
        "\n",
        "    # 4Ô∏è‚É£ ≈ûƒ∞MDƒ∞ LAG UYGULA\n",
        "    lagged_features = []\n",
        "    for feat in features:\n",
        "        lagged_col = f'{feat}_lag1'\n",
        "        df[lagged_col] = df[feat].shift(1)\n",
        "        lagged_features.append(lagged_col)\n",
        "\n",
        "    # 5Ô∏è‚É£ Lag y√ºz√ºnden ilk satƒ±rƒ± drop\n",
        "    df = df.dropna(subset=lagged_features)\n",
        "\n",
        "    X = df[lagged_features].copy()\n",
        "    y = df['Target'].copy()\n",
        "\n",
        "    print(f\" Veri: {len(X)} satƒ±r | Up: {y.mean()*100:.1f}%\")\n",
        "\n",
        "    # 6Ô∏è‚É£ Zaman bazlƒ± split\n",
        "    n_train = int(len(X) * (1 - test_ratio))\n",
        "    X_train = X.iloc[:n_train].copy()\n",
        "    X_test = X.iloc[n_train:].copy()\n",
        "    y_train = y.iloc[:n_train].values\n",
        "    y_test = y.iloc[n_train:].values\n",
        "\n",
        "    print(f\" Train: {len(X_train)} | Test: {len(X_test)}\")\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "prepared_data = {}\n",
        "for name, data in all_data_indicators.items():\n",
        "    print(f\"\\n{name}:\")\n",
        "    try:\n",
        "        X_train, X_test, y_train, y_test = veri_hazirla(data)\n",
        "        prepared_data[name] = {\n",
        "            'X_train': X_train, 'X_test': X_test,\n",
        "            'y_train': y_train, 'y_test': y_test\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\" ‚ùå {e}\")\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(f\"‚úÖ {len(prepared_data)} borsa hazƒ±r\")\n",
        "print(f\"{'='*80}\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# LEVEL 4: SVM T√úM KERNELS (Linear, RBF, Poly)\n",
        "# ============================================================================\n",
        "print(\"=\"*80)\n",
        "print(\"LEVEL 4: SVM T√úM KERNELS (10-Fold CV + Grid Search)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "def grid_search_svm(X_train, y_train, kernel='linear', n_folds=10):\n",
        "    \"\"\"Makalenin Figures 3-6'daki exact aralƒ±klar\"\"\"\n",
        "\n",
        "    if kernel == 'linear':\n",
        "        param_grid = {\n",
        "            'C': [0.001, 0.01, 0.1, 1, 4, 10, 50, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000]\n",
        "        }\n",
        "\n",
        "\n",
        "    cv = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
        "    svm = SVC(kernel=kernel, max_iter=50000, random_state=42)\n",
        "    grid = GridSearchCV(svm, param_grid, cv=cv, scoring='accuracy',\n",
        "                       n_jobs=-1, verbose=0)\n",
        "    grid.fit(X_train, y_train)\n",
        "\n",
        "    return grid.best_estimator_, grid.best_params_, grid.best_score_\n",
        "\n",
        "svm_results = {}\n",
        "\n",
        "for name in prepared_data.keys():\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"{name}\")\n",
        "    print(f\"{'='*80}\")\n",
        "\n",
        "    data = prepared_data[name]\n",
        "    svm_results[name] = {}\n",
        "\n",
        "    for kernel in ['linear', 'rbf', 'poly']:\n",
        "        print(f\"\\n üîç {kernel.upper()} Kernel:\")\n",
        "        print(f\" {'-'*70}\")\n",
        "\n",
        "        try:\n",
        "            best_model, best_params, cv_score = grid_search_svm(\n",
        "                data['X_train'], data['y_train'], kernel=kernel\n",
        "            )\n",
        "\n",
        "            y_pred = best_model.predict(data['X_test'])\n",
        "\n",
        "            acc = accuracy_score(data['y_test'], y_pred)\n",
        "            prec = precision_score(data['y_test'], y_pred, zero_division=0)\n",
        "            rec = recall_score(data['y_test'], y_pred, zero_division=0)\n",
        "            f1 = f1_score(data['y_test'], y_pred, zero_division=0)\n",
        "\n",
        "            svm_results[name][kernel] = {\n",
        "                'model': best_model,\n",
        "                'params': best_params,\n",
        "                'cv_score': cv_score,\n",
        "                'acc': acc,\n",
        "                'precision': prec,\n",
        "                'recall': rec,\n",
        "                'f1': f1\n",
        "            }\n",
        "\n",
        "            print(f\" Best Params: {best_params}\")\n",
        "            print(f\" CV Score: {cv_score:.4f}\")\n",
        "            print(f\" Test Acc: {acc:.4f} | F1: {f1:.4f}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\" ‚ùå {e}\")\n",
        "            svm_results[name][kernel] = None\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"‚úÖ SVM tamamlandƒ±\")\n",
        "print(f\"{'='*80}\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# SONU√áLAR (Table 11 Format - Makale Kar≈üƒ±la≈ütƒ±rmasƒ±)\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\" \"*20 + \"üìä FINAL SONU√áLAR - SVM\")\n",
        "print(\" \"*15 + \"(Table 11 Makale Kar≈üƒ±la≈ütƒ±rmasƒ±)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Her borsa i√ßin sonu√ßlar\n",
        "for name in prepared_data.keys():\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\" {name}\")\n",
        "    print(f\"{'='*80}\")\n",
        "\n",
        "    print(f\"\\n {'Kernel':<15} {'Accuracy':<12} {'F-Score':<12} {'Best Params'}\")\n",
        "    print(f\" {'-'*70}\")\n",
        "\n",
        "    for kernel in ['linear', 'rbf', 'poly']:\n",
        "        if svm_results[name][kernel] is not None:\n",
        "            r = svm_results[name][kernel]\n",
        "            params_str = str(r['params'])[:35] + \"...\" if len(str(r['params'])) > 35 else str(r['params'])\n",
        "            print(f\" {kernel.upper():<15} {r['acc']:<12.4f} {r['f1']:<12.4f} {params_str}\")\n",
        "\n",
        "# Ortalama sonu√ßlar\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\" üìà ORTALAMA PERFORMANS (4 Borsa)\")\n",
        "print(f\"{'='*80}\\n\")\n",
        "\n",
        "if len(prepared_data) > 0:\n",
        "    avg_svm_linear_acc = np.mean([svm_results[n]['linear']['acc'] for n in prepared_data.keys() if svm_results[n]['linear']])\n",
        "    avg_svm_rbf_acc = np.mean([svm_results[n]['rbf']['acc'] for n in prepared_data.keys() if svm_results[n]['rbf']])\n",
        "    avg_svm_poly_acc = np.mean([svm_results[n]['poly']['acc'] for n in prepared_data.keys() if svm_results[n]['poly']])\n",
        "\n",
        "    avg_svm_linear_f1 = np.mean([svm_results[n]['linear']['f1'] for n in prepared_data.keys() if svm_results[n]['linear']])\n",
        "    avg_svm_rbf_f1 = np.mean([svm_results[n]['rbf']['f1'] for n in prepared_data.keys() if svm_results[n]['rbf']])\n",
        "    avg_svm_poly_f1 = np.mean([svm_results[n]['poly']['f1'] for n in prepared_data.keys() if svm_results[n]['poly']])\n",
        "\n",
        "    print(f\" {'Kernel':<15} {'Avg Accuracy':<15} {'Avg F-Score':<15}\")\n",
        "    print(f\" {'-'*50}\")\n",
        "    print(f\" {'Linear':<15} {avg_svm_linear_acc:<15.4f} {avg_svm_linear_f1:<15.4f}\")\n",
        "    print(f\" {'RBF':<15} {avg_svm_rbf_acc:<15.4f} {avg_svm_rbf_f1:<15.4f}\")\n",
        "    print(f\" {'Poly':<15} {avg_svm_poly_acc:<15.4f} {avg_svm_poly_f1:<15.4f}\")\n",
        "\n",
        "# Makale sonu√ßlarƒ± (Table 11)\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\" üéØ MAKALE SONU√áLARI (Table 11 - SVM)\")\n",
        "print(f\"{'='*80}\\n\")\n",
        "print(\" Index       Linear   RBF      Poly\")\n",
        "print(\" \" + \"-\"*45)\n",
        "print(\" KSE-100     0.8519   0.7688   0.8438\")\n",
        "print(\" KOSPI       0.8022   0.7626   0.7828\")\n",
        "print(\" Nikkei 225  0.8022   0.7626   0.7828\")\n",
        "print(\" SZSE        0.8998   0.8720   0.8941\")\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"‚úÖ VERSƒ∞YON 1 FULL SVM ANALƒ∞Zƒ∞ TAMAMLANDI\")\n",
        "print(f\"{'='*80}\\n\")\n",
        "\n",
        "print(\"üí° √ñNEMLƒ∞ NOT:\")\n",
        "print(\" ‚ö†Ô∏è Bu versiyonda DATA LEAKAGE var!\")\n",
        "print(\" ‚ö†Ô∏è Normalization t√ºm veri setinde yapƒ±ldƒ± (train+test)\")\n",
        "print(\" ‚ö†Ô∏è Eƒüer sonu√ßlar makaleye yakƒ±nsa, makale de aynƒ± hatayƒ± yapƒ±yor olabilir!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-J3evlbF-WIk",
        "outputId": "b8480860-5905-4ffe-866e-d38c1993f73f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üì¶ Advanced Grid Search Y√ºkleniyor...\n",
            "‚úÖ Kurulum tamamlandƒ±!\n",
            "\n",
            "================================================================================\n",
            "LEVEL 1: VERƒ∞ √áEKME (2011-01-01 to 2020-09-27)\n",
            "================================================================================\n",
            "\n",
            "üìä KSE100 (^KSE)... ‚úÖ 2346 g√ºn\n",
            "\n",
            "üìä KOSPI (^KS11)... ‚úÖ 2397 g√ºn\n",
            "\n",
            "üìä Nikkei225 (^N225)... ‚úÖ 2382 g√ºn\n",
            "\n",
            "üìä SZSE (000001.SS)... ‚úÖ 2366 g√ºn\n",
            "\n",
            "================================================================================\n",
            "‚úÖ 4 borsa √ßekildi\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "LEVEL 2: 15 TEKNƒ∞K G√ñSTERGE (Table 1)\n",
            "================================================================================\n",
            "\n",
            "KSE100... ‚úÖ 2346 satƒ±r\n",
            "\n",
            "KOSPI... ‚úÖ 2397 satƒ±r\n",
            "\n",
            "Nikkei225... ‚úÖ 2382 satƒ±r\n",
            "\n",
            "SZSE... ‚úÖ 2366 satƒ±r\n",
            "\n",
            "================================================================================\n",
            "‚úÖ G√∂stergeler hesaplandƒ±\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "LEVEL 3: VERƒ∞ HAZIRLAMA (NORMALIZATION LAG √ñNCESƒ∞)\n",
            "================================================================================\n",
            "\n",
            "KSE100:\n",
            " Veri: 2325 satƒ±r | Up: 53.5%\n",
            " Train: 1860 | Test: 465\n",
            "\n",
            "KOSPI:\n",
            " Veri: 2376 satƒ±r | Up: 52.4%\n",
            " Train: 1900 | Test: 476\n",
            "\n",
            "Nikkei225:\n",
            " Veri: 2361 satƒ±r | Up: 53.1%\n",
            " Train: 1888 | Test: 473\n",
            "\n",
            "SZSE:\n",
            " Veri: 2345 satƒ±r | Up: 52.8%\n",
            " Train: 1876 | Test: 469\n",
            "\n",
            "================================================================================\n",
            "‚úÖ 4 borsa hazƒ±r\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "LEVEL 4: ADVANCED PARAMETER SEARCH\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            " KOSPI\n",
            "================================================================================\n",
            "\n",
            " ======================================================================\n",
            " STRATEGY 1: TWO-STAGE GRID SEARCH\n",
            " ======================================================================\n",
            "\n",
            " [Stage 1] Coarse Grid...\n",
            " ‚úì Best C (Coarse): 0.001\n",
            " ‚úì CV Score: 0.5137\n",
            "\n",
            " [Stage 2] Fine-tuning around 0.001...\n",
            " ‚úì Best C (Fine): 0.0005\n",
            " ‚úì CV Score: 0.5137\n",
            " ‚úì Test Acc: 0.5630 | F1: 0.7204\n",
            "\n",
            " ======================================================================\n",
            " STRATEGY 2: RANDOMIZED SEARCH\n",
            " ======================================================================\n",
            "\n",
            " [Randomized] 100 iterations with log-uniform distribution...\n",
            " ‚úì Best C (Random): 0.0419\n",
            " ‚úì CV Score: 0.5137\n",
            " ‚úì Test Acc: 0.5630 | F1: 0.7204\n",
            "\n",
            " ======================================================================\n",
            " STRATEGY 3: BAYESIAN OPTIMIZATION\n",
            " ======================================================================\n",
            "\n",
            " [Bayesian] 50 iterations with intelligent exploration...\n",
            " ‚úì Best C (Bayes): 2.0872\n",
            " ‚úì CV Score: 0.5142\n",
            " ‚úì Test Acc: 0.5630 | F1: 0.7204\n",
            "\n",
            "================================================================================\n",
            "                    üìä STRATEGY COMPARISON\n",
            "================================================================================\n",
            "\n",
            " KOSPI\n",
            " ---------------------------------------------------------------------------\n",
            " Strategy             Best C          CV Score     Test Acc     F1          \n",
            " ---------------------------------------------------------------------------\n",
            " TWO_STAGE            0.0005          0.5137       0.5630       0.7204      \n",
            " RANDOMIZED           0.0419          0.5137       0.5630       0.7204      \n",
            " BAYESIAN             2.0872          0.5142       0.5630       0.7204      \n",
            "\n",
            " ‚≠ê WINNER: TWO_STAGE (Acc: 0.5630)\n",
            "\n",
            "================================================================================\n",
            "‚úÖ ADVANCED SEARCH TAMAMLANDI\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "============================================================================\n",
        "ADVANCED GRID SEARCH: Two-Stage + Bayesian + Randomized\n",
        "============================================================================\n",
        "Hipotez: Best parametre k√ºs√ºratlƒ± olabilir, akƒ±llƒ± search stratejileri kullanalƒ±m!\n",
        "============================================================================\n",
        "\"\"\"\n",
        "\n",
        "import sys\n",
        "import subprocess\n",
        "print(\"üì¶ Advanced Grid Search Y√ºkleniyor...\")\n",
        "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\",\n",
        "                      \"yfinance\", \"ta\", \"scikit-learn\", \"pandas\", \"numpy\",\n",
        "                      \"scikit-optimize\"])  # Bayesian i√ßin\n",
        "\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import ta\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, StratifiedKFold\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from skopt import BayesSearchCV\n",
        "from skopt.space import Real, Integer\n",
        "from scipy.stats import uniform, loguniform\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"‚úÖ Kurulum tamamlandƒ±!\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# LEVEL 1: VERƒ∞ √áEKME\n",
        "# ============================================================================\n",
        "print(\"=\"*80)\n",
        "print(\"LEVEL 1: VERƒ∞ √áEKME (2011-01-01 to 2020-09-27)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "tickers = {\n",
        "    'KSE100': '^KSE',\n",
        "    'KOSPI': '^KS11',\n",
        "    'Nikkei225': '^N225',\n",
        "    'SZSE': '000001.SS'\n",
        "}\n",
        "\n",
        "all_data = {}\n",
        "for name, ticker in tickers.items():\n",
        "    print(f\"\\nüìä {name} ({ticker})...\", end=\" \")\n",
        "    try:\n",
        "        data = yf.download(ticker, start=\"2011-01-01\", end=\"2020-09-27\",\n",
        "                          progress=False, auto_adjust=True)\n",
        "\n",
        "        if data.empty:\n",
        "            print(\"‚ùå VERƒ∞ YOK!\")\n",
        "            continue\n",
        "\n",
        "        if isinstance(data.columns, pd.MultiIndex):\n",
        "            data.columns = data.columns.get_level_values(0)\n",
        "\n",
        "        data = data[['Open', 'High', 'Low', 'Close', 'Volume']].copy()\n",
        "        data = data.dropna()\n",
        "\n",
        "        all_data[name] = data\n",
        "        print(f\"‚úÖ {len(data)} g√ºn\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå {e}\")\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(f\"‚úÖ {len(all_data)} borsa √ßekildi\")\n",
        "print(f\"{'='*80}\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# LEVEL 2: TEKNƒ∞K G√ñSTERGELER (Table 1)\n",
        "# ============================================================================\n",
        "print(\"=\"*80)\n",
        "print(\"LEVEL 2: 15 TEKNƒ∞K G√ñSTERGE (Table 1)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "def hesapla_teknik_gostergeler(df):\n",
        "    \"\"\"Makalenin Table 1 form√ºllerine g√∂re\"\"\"\n",
        "    df = df.copy()\n",
        "\n",
        "    high = df['High'].squeeze()\n",
        "    low = df['Low'].squeeze()\n",
        "    close = df['Close'].squeeze()\n",
        "\n",
        "    # 1-2. Stochastic Oscillator\n",
        "    stoch = ta.momentum.StochasticOscillator(high, low, close,\n",
        "                                             window=14, smooth_window=3)\n",
        "    df['Stochastic_K'] = stoch.stoch()\n",
        "    df['Stochastic_D'] = stoch.stoch_signal()\n",
        "\n",
        "    # 3. ROC (10 period)\n",
        "    df['ROC'] = ta.momentum.ROCIndicator(close, window=10).roc()\n",
        "\n",
        "    # 4. Williams %R (14 period)\n",
        "    df['Williams_R'] = ta.momentum.WilliamsRIndicator(high, low, close,\n",
        "                                                       lbp=14).williams_r()\n",
        "\n",
        "    # 5. Momentum (4 period: C_t - C_{t-4})\n",
        "    df['Momentum'] = close.diff(4)\n",
        "\n",
        "    # 6. Disparity 5\n",
        "    ma5 = close.rolling(5).mean()\n",
        "    df['Disparity_5'] = np.where(ma5 != 0, (close / ma5) * 100, 100)\n",
        "\n",
        "    # 7. Disparity 14\n",
        "    ma14 = close.rolling(14).mean()\n",
        "    df['Disparity_14'] = np.where(ma14 != 0, (close / ma14) * 100, 100)\n",
        "\n",
        "    # 8. OSCP (Price Oscillator)\n",
        "    ma10 = close.rolling(10).mean()\n",
        "    df['OSCP'] = np.where(ma5 != 0, ((ma5 - ma10) / ma5), 0)\n",
        "\n",
        "    # 9. CCI (20 period)\n",
        "    df['CCI'] = ta.trend.CCIIndicator(high, low, close, window=20).cci()\n",
        "\n",
        "    # 10. RSI (14 period)\n",
        "    df['RSI'] = ta.momentum.RSIIndicator(close, window=14).rsi()\n",
        "\n",
        "    # 11-15. Pivot Points\n",
        "    prev_high = high.shift(1)\n",
        "    prev_low = low.shift(1)\n",
        "    prev_close = close.shift(1)\n",
        "\n",
        "    df['Pivot_Point'] = (prev_high + prev_low + prev_close) / 3\n",
        "    df['S1'] = (df['Pivot_Point'] * 2) - prev_high\n",
        "    df['S2'] = df['Pivot_Point'] - (prev_high - prev_low)\n",
        "    df['R1'] = (df['Pivot_Point'] * 2) - prev_low\n",
        "    df['R2'] = df['Pivot_Point'] + (prev_high - prev_low)\n",
        "\n",
        "    df = df.replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "    return df\n",
        "\n",
        "all_data_indicators = {}\n",
        "for name, data in all_data.items():\n",
        "    print(f\"\\n{name}...\", end=\" \")\n",
        "    try:\n",
        "        result = hesapla_teknik_gostergeler(data)\n",
        "        all_data_indicators[name] = result\n",
        "        print(f\"‚úÖ {len(result)} satƒ±r\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå {e}\")\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(f\"‚úÖ G√∂stergeler hesaplandƒ±\")\n",
        "print(f\"{'='*80}\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# LEVEL 3: VERƒ∞ HAZIRLAMA\n",
        "# ============================================================================\n",
        "print(\"=\"*80)\n",
        "print(\"LEVEL 3: VERƒ∞ HAZIRLAMA (NORMALIZATION LAG √ñNCESƒ∞)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "def veri_hazirla(df, test_ratio=0.2):\n",
        "    \"\"\"Normalization LAG √∂ncesi (Data leakage var)\"\"\"\n",
        "    df = df.copy()\n",
        "\n",
        "    features = ['Stochastic_K', 'Stochastic_D', 'ROC', 'Williams_R',\n",
        "                'Momentum', 'Disparity_5', 'Disparity_14', 'OSCP',\n",
        "                'CCI', 'RSI', 'Pivot_Point', 'S1', 'S2', 'R1', 'R2']\n",
        "\n",
        "    # Target\n",
        "    df['Next_Close'] = df['Close'].shift(-1)\n",
        "    df['Target'] = (df['Next_Close'] > df['Close']).astype(int)\n",
        "    df = df.iloc[:-1].copy()\n",
        "\n",
        "    # NaN temizle\n",
        "    df = df.replace([np.inf, -np.inf], np.nan)\n",
        "    df = df.dropna(subset=features + ['Target'])\n",
        "\n",
        "    # Normalization √ñNCE\n",
        "    scaler = MinMaxScaler()\n",
        "    df[features] = scaler.fit_transform(df[features])\n",
        "\n",
        "    # Lag uygula\n",
        "    lagged_features = []\n",
        "    for feat in features:\n",
        "        lagged_col = f'{feat}_lag1'\n",
        "        df[lagged_col] = df[feat].shift(1)\n",
        "        lagged_features.append(lagged_col)\n",
        "\n",
        "    df = df.dropna(subset=lagged_features)\n",
        "\n",
        "    X = df[lagged_features].copy()\n",
        "    y = df['Target'].copy()\n",
        "\n",
        "    print(f\" Veri: {len(X)} satƒ±r | Up: {y.mean()*100:.1f}%\")\n",
        "\n",
        "    # Split\n",
        "    n_train = int(len(X) * (1 - test_ratio))\n",
        "    X_train = X.iloc[:n_train].copy()\n",
        "    X_test = X.iloc[n_train:].copy()\n",
        "    y_train = y.iloc[:n_train].values\n",
        "    y_test = y.iloc[n_train:].values\n",
        "\n",
        "    print(f\" Train: {len(X_train)} | Test: {len(X_test)}\")\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "prepared_data = {}\n",
        "for name, data in all_data_indicators.items():\n",
        "    print(f\"\\n{name}:\")\n",
        "    try:\n",
        "        X_train, X_test, y_train, y_test = veri_hazirla(data)\n",
        "        prepared_data[name] = {\n",
        "            'X_train': X_train, 'X_test': X_test,\n",
        "            'y_train': y_train, 'y_test': y_test\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\" ‚ùå {e}\")\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(f\"‚úÖ {len(prepared_data)} borsa hazƒ±r\")\n",
        "print(f\"{'='*80}\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# LEVEL 4: ADVANCED PARAMETER SEARCH\n",
        "# ============================================================================\n",
        "print(\"=\"*80)\n",
        "print(\"LEVEL 4: ADVANCED PARAMETER SEARCH\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "def advanced_search_linear_svm(X_train, y_train, X_test, y_test, index_name):\n",
        "    \"\"\"\n",
        "    üéØ Multi-Strategy Search:\n",
        "    1. Two-Stage Grid Search (Coarse ‚Üí Fine)\n",
        "    2. Randomized Search (100 iterations)\n",
        "    3. Bayesian Optimization (50 iterations)\n",
        "    \"\"\"\n",
        "\n",
        "    cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "    results = {}\n",
        "\n",
        "    print(f\"\\n {'='*70}\")\n",
        "    print(f\" STRATEGY 1: TWO-STAGE GRID SEARCH\")\n",
        "    print(f\" {'='*70}\")\n",
        "\n",
        "    # STAGE 1: Coarse Grid\n",
        "    print(\"\\n [Stage 1] Coarse Grid...\")\n",
        "    coarse_grid = {\n",
        "        'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
        "    }\n",
        "\n",
        "    svm = SVC(kernel='linear', max_iter=50000, random_state=42)\n",
        "    grid_coarse = GridSearchCV(svm, coarse_grid, cv=cv, scoring='accuracy', n_jobs=-1)\n",
        "    grid_coarse.fit(X_train, y_train)\n",
        "\n",
        "    best_C_coarse = grid_coarse.best_params_['C']\n",
        "    print(f\" ‚úì Best C (Coarse): {best_C_coarse}\")\n",
        "    print(f\" ‚úì CV Score: {grid_coarse.best_score_:.4f}\")\n",
        "\n",
        "    # STAGE 2: Fine Grid around best\n",
        "    print(f\"\\n [Stage 2] Fine-tuning around {best_C_coarse}...\")\n",
        "\n",
        "    # Akƒ±llƒ± fine grid olu≈ütur\n",
        "    if best_C_coarse < 1:\n",
        "        fine_range = np.linspace(best_C_coarse * 0.5, best_C_coarse * 2, 15)\n",
        "    elif best_C_coarse < 100:\n",
        "        fine_range = np.linspace(best_C_coarse - 50, best_C_coarse + 50, 20)\n",
        "    else:\n",
        "        fine_range = np.linspace(best_C_coarse - 200, best_C_coarse + 200, 30)\n",
        "\n",
        "    fine_range = [max(0.0001, c) for c in fine_range]  # Pozitif tut\n",
        "\n",
        "    fine_grid = {'C': fine_range}\n",
        "\n",
        "    grid_fine = GridSearchCV(svm, fine_grid, cv=cv, scoring='accuracy', n_jobs=-1)\n",
        "    grid_fine.fit(X_train, y_train)\n",
        "\n",
        "    best_C_fine = grid_fine.best_params_['C']\n",
        "    print(f\" ‚úì Best C (Fine): {best_C_fine:.4f}\")\n",
        "    print(f\" ‚úì CV Score: {grid_fine.best_score_:.4f}\")\n",
        "\n",
        "    # Test\n",
        "    y_pred = grid_fine.best_estimator_.predict(X_test)\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred, zero_division=0)\n",
        "\n",
        "    results['two_stage'] = {\n",
        "        'best_C': best_C_fine,\n",
        "        'cv_score': grid_fine.best_score_,\n",
        "        'test_acc': acc,\n",
        "        'test_f1': f1,\n",
        "        'model': grid_fine.best_estimator_\n",
        "    }\n",
        "\n",
        "    print(f\" ‚úì Test Acc: {acc:.4f} | F1: {f1:.4f}\")\n",
        "\n",
        "    # ========================================================================\n",
        "\n",
        "    print(f\"\\n {'='*70}\")\n",
        "    print(f\" STRATEGY 2: RANDOMIZED SEARCH\")\n",
        "    print(f\" {'='*70}\")\n",
        "\n",
        "    print(\"\\n [Randomized] 100 iterations with log-uniform distribution...\")\n",
        "\n",
        "    param_dist = {\n",
        "        'C': loguniform(1e-4, 1e3)  # Log-uniform between 0.0001 and 1000\n",
        "    }\n",
        "\n",
        "    random_search = RandomizedSearchCV(\n",
        "        svm, param_dist, n_iter=100, cv=cv,\n",
        "        scoring='accuracy', n_jobs=-1, random_state=42\n",
        "    )\n",
        "    random_search.fit(X_train, y_train)\n",
        "\n",
        "    best_C_random = random_search.best_params_['C']\n",
        "    print(f\" ‚úì Best C (Random): {best_C_random:.4f}\")\n",
        "    print(f\" ‚úì CV Score: {random_search.best_score_:.4f}\")\n",
        "\n",
        "    # Test\n",
        "    y_pred = random_search.best_estimator_.predict(X_test)\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred, zero_division=0)\n",
        "\n",
        "    results['randomized'] = {\n",
        "        'best_C': best_C_random,\n",
        "        'cv_score': random_search.best_score_,\n",
        "        'test_acc': acc,\n",
        "        'test_f1': f1,\n",
        "        'model': random_search.best_estimator_\n",
        "    }\n",
        "\n",
        "    print(f\" ‚úì Test Acc: {acc:.4f} | F1: {f1:.4f}\")\n",
        "\n",
        "    # ========================================================================\n",
        "\n",
        "    print(f\"\\n {'='*70}\")\n",
        "    print(f\" STRATEGY 3: BAYESIAN OPTIMIZATION\")\n",
        "    print(f\" {'='*70}\")\n",
        "\n",
        "    print(\"\\n [Bayesian] 50 iterations with intelligent exploration...\")\n",
        "\n",
        "    search_spaces = {\n",
        "        'C': Real(1e-4, 1e3, prior='log-uniform')  # Bayesian log-uniform\n",
        "    }\n",
        "\n",
        "    bayes_search = BayesSearchCV(\n",
        "        svm, search_spaces, n_iter=50, cv=cv,\n",
        "        scoring='accuracy', n_jobs=-1, random_state=42\n",
        "    )\n",
        "    bayes_search.fit(X_train, y_train)\n",
        "\n",
        "    best_C_bayes = bayes_search.best_params_['C']\n",
        "    print(f\" ‚úì Best C (Bayes): {best_C_bayes:.4f}\")\n",
        "    print(f\" ‚úì CV Score: {bayes_search.best_score_:.4f}\")\n",
        "\n",
        "    # Test\n",
        "    y_pred = bayes_search.best_estimator_.predict(X_test)\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred, zero_division=0)\n",
        "\n",
        "    results['bayesian'] = {\n",
        "        'best_C': best_C_bayes,\n",
        "        'cv_score': bayes_search.best_score_,\n",
        "        'test_acc': acc,\n",
        "        'test_f1': f1,\n",
        "        'model': bayes_search.best_estimator_\n",
        "    }\n",
        "\n",
        "    print(f\" ‚úì Test Acc: {acc:.4f} | F1: {f1:.4f}\")\n",
        "\n",
        "    return results\n",
        "\n",
        "# ============================================================================\n",
        "# √áALI≈ûTIR\n",
        "# ============================================================================\n",
        "\n",
        "all_results = {}\n",
        "\n",
        "for name in ['KOSPI']:  # √ñnce sadece KOSPI test\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\" {name}\")\n",
        "    print(f\"{'='*80}\")\n",
        "\n",
        "    data = prepared_data[name]\n",
        "\n",
        "    try:\n",
        "        results = advanced_search_linear_svm(\n",
        "            data['X_train'],\n",
        "            data['y_train'],\n",
        "            data['X_test'],\n",
        "            data['y_test'],\n",
        "            name\n",
        "        )\n",
        "        all_results[name] = results\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n ‚ùå Error: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n",
        "# ============================================================================\n",
        "# FINAL COMPARISON\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\" \"*20 + \"üìä STRATEGY COMPARISON\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "for name, results in all_results.items():\n",
        "    print(f\"\\n {name}\")\n",
        "    print(\" \" + \"-\"*75)\n",
        "    print(f\" {'Strategy':<20} {'Best C':<15} {'CV Score':<12} {'Test Acc':<12} {'F1':<12}\")\n",
        "    print(\" \" + \"-\"*75)\n",
        "\n",
        "    for strategy in ['two_stage', 'randomized', 'bayesian']:\n",
        "        r = results[strategy]\n",
        "        print(f\" {strategy.upper():<20} {r['best_C']:<15.4f} {r['cv_score']:<12.4f} {r['test_acc']:<12.4f} {r['test_f1']:<12.4f}\")\n",
        "\n",
        "    # Find best\n",
        "    best_strategy = max(results.items(), key=lambda x: x[1]['test_acc'])\n",
        "    print(f\"\\n ‚≠ê WINNER: {best_strategy[0].upper()} (Acc: {best_strategy[1]['test_acc']:.4f})\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"‚úÖ ADVANCED SEARCH TAMAMLANDI\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vq-CFX_j-WLK",
        "outputId": "5f84896f-a4f4-442d-ca30-e2815cf73a6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üì¶ VERSƒ∞YON 4: Returns-Based Stationary Approach\n",
            "‚úÖ Kurulum tamamlandƒ±!\n",
            "\n",
            "================================================================================\n",
            "LEVEL 1: VERƒ∞ √áEKME (2011-01-01 to 2020-09-27)\n",
            "================================================================================\n",
            "\n",
            "üìä KSE100 (^KSE)... ‚úÖ 2346 g√ºn\n",
            "\n",
            "üìä KOSPI (^KS11)... ‚úÖ 2397 g√ºn\n",
            "\n",
            "üìä Nikkei225 (^N225)... ‚úÖ 2382 g√ºn\n",
            "\n",
            "üìä SZSE (000001.SS)... ‚úÖ 2366 g√ºn\n",
            "\n",
            "================================================================================\n",
            "‚úÖ 4 borsa √ßekildi\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "LEVEL 2: RETURNS-BASED STATIONARY INDICATORS\n",
            "================================================================================\n",
            "\n",
            "KSE100... ‚úÖ 2346 satƒ±r\n",
            "\n",
            "KOSPI... ‚úÖ 2397 satƒ±r\n",
            "\n",
            "Nikkei225... ‚úÖ 2382 satƒ±r\n",
            "\n",
            "SZSE... ‚úÖ 2366 satƒ±r\n",
            "\n",
            "================================================================================\n",
            "‚úÖ Stationary indicators hesaplandƒ±\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "LEVEL 3: VERƒ∞ HAZIRLAMA (Returns-based features)\n",
            "================================================================================\n",
            "\n",
            "KSE100:\n",
            " Veri: 2305 satƒ±r | Up: 53.6%\n",
            " Train: 1844 | Test: 461\n",
            "\n",
            "KOSPI:\n",
            " Veri: 2356 satƒ±r | Up: 52.5%\n",
            " Train: 1884 | Test: 472\n",
            "\n",
            "Nikkei225:\n",
            " Veri: 2341 satƒ±r | Up: 53.0%\n",
            " Train: 1872 | Test: 469\n",
            "\n",
            "SZSE:\n",
            " Veri: 2325 satƒ±r | Up: 52.7%\n",
            " Train: 1860 | Test: 465\n",
            "\n",
            "================================================================================\n",
            "‚úÖ 4 borsa hazƒ±r (Returns-based)\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "LEVEL 4: SVM LINEAR KERNEL (Returns-based Test)\n",
            "================================================================================\n",
            "\n",
            " KSE100\n",
            " ----------------------------------------------------------------------\n",
            " Best C: 0.001\n",
            " CV Score: 0.5401 (54.01%)\n",
            " Test Acc: 0.5184 (51.84%)\n",
            " Precision: 0.5184\n",
            " Recall: 1.0000\n",
            " F1-Score: 0.6829\n",
            "\n",
            " KOSPI\n",
            " ----------------------------------------------------------------------\n",
            " Best C: 0.001\n",
            " CV Score: 0.5154 (51.54%)\n",
            " Test Acc: 0.5636 (56.36%)\n",
            " Precision: 0.5636\n",
            " Recall: 1.0000\n",
            " F1-Score: 0.7209\n",
            "\n",
            " Nikkei225\n",
            " ----------------------------------------------------------------------\n",
            " Best C: 0.001\n",
            " CV Score: 0.5310 (53.10%)\n",
            " Test Acc: 0.5245 (52.45%)\n",
            " Precision: 0.5245\n",
            " Recall: 1.0000\n",
            " F1-Score: 0.6881\n",
            "\n",
            " SZSE\n",
            " ----------------------------------------------------------------------\n",
            " Best C: 900\n",
            " CV Score: 0.5247 (52.47%)\n",
            " Test Acc: 0.5226 (52.26%)\n",
            " Precision: 0.5312\n",
            " Recall: 0.9237\n",
            " F1-Score: 0.6745\n",
            "\n",
            "================================================================================\n",
            "                    üìä RETURNS-BASED SONU√áLAR\n",
            "================================================================================\n",
            "\n",
            " Index           Best C     CV Score     Test Acc     F1-Score    \n",
            " ----------------------------------------------------------------------\n",
            " KSE100          0.001      0.5401       0.5184       0.6829      \n",
            " KOSPI           0.001      0.5154       0.5636       0.7209      \n",
            " Nikkei225       0.001      0.5310       0.5245       0.6881      \n",
            " SZSE            900        0.5247       0.5226       0.6745      \n",
            " ----------------------------------------------------------------------\n",
            " AVERAGE         -          0.5278       0.5323       0.6916      \n",
            "\n",
            " ================================================================================\n",
            " üéØ MAKALE SONU√áLARI (Table 11)\n",
            " ================================================================================\n",
            "\n",
            " Index       Linear SVM (Paper)\n",
            " -----------------------------------\n",
            " KSE-100     0.8519\n",
            " KOSPI       0.8022\n",
            " Nikkei 225  0.8022\n",
            " SZSE        0.8998\n",
            "\n",
            "================================================================================\n",
            "‚úÖ RETURNS-BASED ANALƒ∞Z TAMAMLANDI\n",
            "================================================================================\n",
            "\n",
            "üí° KRƒ∞Tƒ∞K FARK:\n",
            " ‚úÖ Returns-based stationary features kullanƒ±ldƒ±\n",
            " ‚úÖ Log returns ‚Üí Non-stationary problem √ß√∂z√ºld√º\n",
            " ‚úÖ Volatility adjustment eklendi\n",
            " ‚úÖ Financial time series best practices uygulandƒ±\n",
            "\n",
            "üî¨ Eƒüer sonu√ßlar hala d√º≈ü√ºkse:\n",
            " ‚Üí Veri kalitesi problemi (Yahoo Finance vs Professional data)\n",
            " ‚Üí Makale metodolojisinde gizli adƒ±mlar olabilir\n",
            " ‚Üí Farklƒ± model (Random Forest, Neural Net) denenebilir\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "============================================================================\n",
        "VERSƒ∞YON 4: RETURNS-BASED STATIONARY APPROACH\n",
        "============================================================================\n",
        "Hipotez: Financial time series non-stationary!\n",
        "         Price-based deƒüil RETURNS-BASED indicator'lar kullanmalƒ±yƒ±z!\n",
        "\n",
        "Deƒüi≈üiklikler:\n",
        "- Close price ‚Üí Log Returns\n",
        "- Technical indicators returns bazlƒ±\n",
        "- Volatility normalization\n",
        "- Stationary features\n",
        "============================================================================\n",
        "\"\"\"\n",
        "\n",
        "import sys\n",
        "import subprocess\n",
        "print(\"üì¶ VERSƒ∞YON 4: Returns-Based Stationary Approach\")\n",
        "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\",\n",
        "                      \"yfinance\", \"ta\", \"scikit-learn\", \"pandas\", \"numpy\"])\n",
        "\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import ta\n",
        "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"‚úÖ Kurulum tamamlandƒ±!\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# LEVEL 1: VERƒ∞ √áEKME\n",
        "# ============================================================================\n",
        "print(\"=\"*80)\n",
        "print(\"LEVEL 1: VERƒ∞ √áEKME (2011-01-01 to 2020-09-27)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "tickers = {\n",
        "    'KSE100': '^KSE',\n",
        "    'KOSPI': '^KS11',\n",
        "    'Nikkei225': '^N225',\n",
        "    'SZSE': '000001.SS'\n",
        "}\n",
        "\n",
        "all_data = {}\n",
        "for name, ticker in tickers.items():\n",
        "    print(f\"\\nüìä {name} ({ticker})...\", end=\" \")\n",
        "    try:\n",
        "        data = yf.download(ticker, start=\"2011-01-01\", end=\"2020-09-27\",\n",
        "                          progress=False, auto_adjust=True)\n",
        "\n",
        "        if data.empty:\n",
        "            print(\"‚ùå VERƒ∞ YOK!\")\n",
        "            continue\n",
        "\n",
        "        if isinstance(data.columns, pd.MultiIndex):\n",
        "            data.columns = data.columns.get_level_values(0)\n",
        "\n",
        "        data = data[['Open', 'High', 'Low', 'Close', 'Volume']].copy()\n",
        "        data = data.dropna()\n",
        "\n",
        "        all_data[name] = data\n",
        "        print(f\"‚úÖ {len(data)} g√ºn\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå {e}\")\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(f\"‚úÖ {len(all_data)} borsa √ßekildi\")\n",
        "print(f\"{'='*80}\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# LEVEL 2: RETURNS-BASED STATIONARY INDICATORS\n",
        "# ============================================================================\n",
        "print(\"=\"*80)\n",
        "print(\"LEVEL 2: RETURNS-BASED STATIONARY INDICATORS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "def hesapla_stationary_indicators(df):\n",
        "    \"\"\"\n",
        "    üéØ Returns-based, stationary technical indicators\n",
        "\n",
        "    Financial time series preprocessing:\n",
        "    1. Log returns (stationary)\n",
        "    2. Volatility adjustment\n",
        "    3. Returns-based technical indicators\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "\n",
        "    # ========================================================================\n",
        "    # BASE: RETURNS & VOLATILITY\n",
        "    # ========================================================================\n",
        "\n",
        "    # 1. Log Returns (stationary!)\n",
        "    df['Returns'] = np.log(df['Close'] / df['Close'].shift(1))\n",
        "\n",
        "    # 2. Percentage Returns (alternative)\n",
        "    df['Pct_Returns'] = df['Close'].pct_change()\n",
        "\n",
        "    # 3. Volatility (20-day rolling std of returns)\n",
        "    df['Volatility'] = df['Returns'].rolling(20).std()\n",
        "\n",
        "    # 4. Volatility-adjusted returns (Sharpe-like signal)\n",
        "    df['Vol_Adj_Returns'] = df['Returns'] / (df['Volatility'] + 1e-8)\n",
        "\n",
        "    # ========================================================================\n",
        "    # MOMENTUM INDICATORS (Returns-based)\n",
        "    # ========================================================================\n",
        "\n",
        "    # 5. Returns Momentum (4-period diff)\n",
        "    df['Returns_Momentum'] = df['Returns'].diff(4)\n",
        "\n",
        "    # 6. Return Acceleration (2nd derivative)\n",
        "    df['Return_Accel'] = df['Returns'].diff()\n",
        "\n",
        "    # 7. Cumulative Returns (10-day)\n",
        "    df['Cum_Returns_10'] = df['Returns'].rolling(10).sum()\n",
        "\n",
        "    # ========================================================================\n",
        "    # MOVING AVERAGE INDICATORS (Returns-based)\n",
        "    # ========================================================================\n",
        "\n",
        "    # 8-9. EMA on Returns\n",
        "    ema_short = df['Returns'].ewm(span=5, adjust=False).mean()\n",
        "    ema_long = df['Returns'].ewm(span=14, adjust=False).mean()\n",
        "    df['MACD_Returns'] = ema_short - ema_long\n",
        "    df['MACD_Signal'] = df['MACD_Returns'].ewm(span=3, adjust=False).mean()\n",
        "\n",
        "    # 10. Simple MA difference (returns)\n",
        "    ma5_ret = df['Returns'].rolling(5).mean()\n",
        "    ma10_ret = df['Returns'].rolling(10).mean()\n",
        "    df['MA_Diff_Returns'] = ma5_ret - ma10_ret\n",
        "\n",
        "    # ========================================================================\n",
        "    # RSI & OSCILLATORS (Returns-based)\n",
        "    # ========================================================================\n",
        "\n",
        "    # 11. RSI on Returns (not price!)\n",
        "    # Returns zaten +/- olduƒüu i√ßin daha meaningful\n",
        "    returns_series = df['Returns'].fillna(0) * 100  # Scale for RSI\n",
        "    df['RSI_Returns'] = ta.momentum.RSIIndicator(\n",
        "        returns_series, window=14\n",
        "    ).rsi()\n",
        "\n",
        "    # 12-13. Stochastic on Returns\n",
        "    # Returns'√º min-max normalize et\n",
        "    returns_norm = (df['Returns'] - df['Returns'].rolling(14).min()) / \\\n",
        "                   (df['Returns'].rolling(14).max() - df['Returns'].rolling(14).min() + 1e-8)\n",
        "    df['Stoch_Returns'] = returns_norm * 100\n",
        "    df['Stoch_Returns_MA'] = df['Stoch_Returns'].rolling(3).mean()\n",
        "\n",
        "    # ========================================================================\n",
        "    # VOLATILITY INDICATORS\n",
        "    # ========================================================================\n",
        "\n",
        "    # 14. Volatility ratio (current vs historical)\n",
        "    vol_ma = df['Volatility'].rolling(20).mean()\n",
        "    df['Vol_Ratio'] = df['Volatility'] / (vol_ma + 1e-8)\n",
        "\n",
        "    # 15. High-Low range (normalized by close)\n",
        "    df['HL_Range'] = (df['High'] - df['Low']) / (df['Close'] + 1e-8)\n",
        "\n",
        "    # ========================================================================\n",
        "    # PRICE-BASED (but normalized) - Keep some original indicators\n",
        "    # ========================================================================\n",
        "\n",
        "    # 16. Williams %R (original but useful)\n",
        "    df['Williams_R'] = ta.momentum.WilliamsRIndicator(\n",
        "        df['High'], df['Low'], df['Close'], lbp=14\n",
        "    ).williams_r()\n",
        "\n",
        "    # 17. CCI (price-based but captures momentum)\n",
        "    df['CCI'] = ta.trend.CCIIndicator(\n",
        "        df['High'], df['Low'], df['Close'], window=20\n",
        "    ).cci()\n",
        "\n",
        "    # Inf/NaN temizleme\n",
        "    df = df.replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "    return df\n",
        "\n",
        "all_data_indicators = {}\n",
        "for name, data in all_data.items():\n",
        "    print(f\"\\n{name}...\", end=\" \")\n",
        "    try:\n",
        "        result = hesapla_stationary_indicators(data)\n",
        "        all_data_indicators[name] = result\n",
        "        print(f\"‚úÖ {len(result)} satƒ±r\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå {e}\")\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(f\"‚úÖ Stationary indicators hesaplandƒ±\")\n",
        "print(f\"{'='*80}\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# LEVEL 3: VERƒ∞ HAZIRLAMA (Returns-based features)\n",
        "# ============================================================================\n",
        "print(\"=\"*80)\n",
        "print(\"LEVEL 3: VERƒ∞ HAZIRLAMA (Returns-based features)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "def veri_hazirla_stationary(df, test_ratio=0.2):\n",
        "    \"\"\"\n",
        "    üéØ Returns-based feature preparation\n",
        "\n",
        "    Features: Stationary returns-based indicators\n",
        "    Target: Next day return direction\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "\n",
        "    # Returns-based features\n",
        "    features = [\n",
        "        'Returns', 'Pct_Returns', 'Volatility', 'Vol_Adj_Returns',\n",
        "        'Returns_Momentum', 'Return_Accel', 'Cum_Returns_10',\n",
        "        'MACD_Returns', 'MACD_Signal', 'MA_Diff_Returns',\n",
        "        'RSI_Returns', 'Stoch_Returns', 'Stoch_Returns_MA',\n",
        "        'Vol_Ratio', 'HL_Range', 'Williams_R', 'CCI'\n",
        "    ]\n",
        "\n",
        "    # 1Ô∏è‚É£ Target: Next day return direction (positive = 1, negative = 0)\n",
        "    df['Next_Return'] = df['Returns'].shift(-1)\n",
        "    df['Target'] = (df['Next_Return'] > 0).astype(int)\n",
        "    df = df.iloc[:-1].copy()  # Son satƒ±r NaN\n",
        "\n",
        "    # 2Ô∏è‚É£ NaN temizle\n",
        "    df = df.replace([np.inf, -np.inf], np.nan)\n",
        "    df = df.dropna(subset=features + ['Target'])\n",
        "\n",
        "    # 3Ô∏è‚É£ Normalization √ñNCE (data leakage ama makale ile kar≈üƒ±la≈ütƒ±rmak i√ßin)\n",
        "    scaler = MinMaxScaler()\n",
        "    df[features] = scaler.fit_transform(df[features])\n",
        "\n",
        "    # 4Ô∏è‚É£ Lag uygula (T-1 features ile T predict et)\n",
        "    lagged_features = []\n",
        "    for feat in features:\n",
        "        lagged_col = f'{feat}_lag1'\n",
        "        df[lagged_col] = df[feat].shift(1)\n",
        "        lagged_features.append(lagged_col)\n",
        "\n",
        "    # 5Ô∏è‚É£ Lag sonrasƒ± NaN temizle\n",
        "    df = df.dropna(subset=lagged_features)\n",
        "\n",
        "    X = df[lagged_features].copy()\n",
        "    y = df['Target'].copy()\n",
        "\n",
        "    print(f\" Veri: {len(X)} satƒ±r | Up: {y.mean()*100:.1f}%\")\n",
        "\n",
        "    # 6Ô∏è‚É£ Zaman bazlƒ± split\n",
        "    n_train = int(len(X) * (1 - test_ratio))\n",
        "    X_train = X.iloc[:n_train].copy()\n",
        "    X_test = X.iloc[n_train:].copy()\n",
        "    y_train = y.iloc[:n_train].values\n",
        "    y_test = y.iloc[n_train:].values\n",
        "\n",
        "    print(f\" Train: {len(X_train)} | Test: {len(X_test)}\")\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "prepared_data = {}\n",
        "for name, data in all_data_indicators.items():\n",
        "    print(f\"\\n{name}:\")\n",
        "    try:\n",
        "        X_train, X_test, y_train, y_test = veri_hazirla_stationary(data)\n",
        "        prepared_data[name] = {\n",
        "            'X_train': X_train, 'X_test': X_test,\n",
        "            'y_train': y_train, 'y_test': y_test\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\" ‚ùå {e}\")\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(f\"‚úÖ {len(prepared_data)} borsa hazƒ±r (Returns-based)\")\n",
        "print(f\"{'='*80}\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# LEVEL 4: SVM LINEAR KERNEL (Quick Test)\n",
        "# ============================================================================\n",
        "print(\"=\"*80)\n",
        "print(\"LEVEL 4: SVM LINEAR KERNEL (Returns-based Test)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "def test_svm_linear(X_train, y_train, X_test, y_test, name):\n",
        "    \"\"\"Quick SVM test\"\"\"\n",
        "\n",
        "    print(f\"\\n {name}\")\n",
        "    print(\" \" + \"-\"*70)\n",
        "\n",
        "    # Grid search\n",
        "    param_grid = {\n",
        "        'C': [0.001, 0.01, 0.1, 1, 4, 10, 50, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000]\n",
        "    }\n",
        "\n",
        "    cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "    svm = SVC(kernel='linear', max_iter=50000, random_state=42)\n",
        "\n",
        "    grid = GridSearchCV(svm, param_grid, cv=cv, scoring='accuracy', n_jobs=-1, verbose=0)\n",
        "    grid.fit(X_train, y_train)\n",
        "\n",
        "    # Test\n",
        "    best_model = grid.best_estimator_\n",
        "    y_pred = best_model.predict(X_test)\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    prec = precision_score(y_test, y_pred, zero_division=0)\n",
        "    rec = recall_score(y_test, y_pred, zero_division=0)\n",
        "    f1 = f1_score(y_test, y_pred, zero_division=0)\n",
        "\n",
        "    print(f\" Best C: {grid.best_params_['C']}\")\n",
        "    print(f\" CV Score: {grid.best_score_:.4f} ({grid.best_score_*100:.2f}%)\")\n",
        "    print(f\" Test Acc: {acc:.4f} ({acc*100:.2f}%)\")\n",
        "    print(f\" Precision: {prec:.4f}\")\n",
        "    print(f\" Recall: {rec:.4f}\")\n",
        "    print(f\" F1-Score: {f1:.4f}\")\n",
        "\n",
        "    return {\n",
        "        'best_C': grid.best_params_['C'],\n",
        "        'cv_score': grid.best_score_,\n",
        "        'test_acc': acc,\n",
        "        'precision': prec,\n",
        "        'recall': rec,\n",
        "        'f1': f1\n",
        "    }\n",
        "\n",
        "results = {}\n",
        "\n",
        "for name in prepared_data.keys():\n",
        "    data = prepared_data[name]\n",
        "    try:\n",
        "        result = test_svm_linear(\n",
        "            data['X_train'], data['y_train'],\n",
        "            data['X_test'], data['y_test'],\n",
        "            name\n",
        "        )\n",
        "        results[name] = result\n",
        "    except Exception as e:\n",
        "        print(f\" ‚ùå {name}: {e}\")\n",
        "\n",
        "# ============================================================================\n",
        "# SONU√áLAR\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\" \"*20 + \"üìä RETURNS-BASED SONU√áLAR\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(f\"\\n {'Index':<15} {'Best C':<10} {'CV Score':<12} {'Test Acc':<12} {'F1-Score':<12}\")\n",
        "print(\" \" + \"-\"*70)\n",
        "\n",
        "for name, result in results.items():\n",
        "    print(f\" {name:<15} {result['best_C']:<10} {result['cv_score']:<12.4f} {result['test_acc']:<12.4f} {result['f1']:<12.4f}\")\n",
        "\n",
        "# Ortalama\n",
        "if len(results) > 0:\n",
        "    avg_cv = np.mean([r['cv_score'] for r in results.values()])\n",
        "    avg_test = np.mean([r['test_acc'] for r in results.values()])\n",
        "    avg_f1 = np.mean([r['f1'] for r in results.values()])\n",
        "\n",
        "    print(\" \" + \"-\"*70)\n",
        "    print(f\" {'AVERAGE':<15} {'-':<10} {avg_cv:<12.4f} {avg_test:<12.4f} {avg_f1:<12.4f}\")\n",
        "\n",
        "# Makale kar≈üƒ±la≈ütƒ±rma\n",
        "print(f\"\\n {'='*80}\")\n",
        "print(\" üéØ MAKALE SONU√áLARI (Table 11)\")\n",
        "print(f\" {'='*80}\\n\")\n",
        "print(\" Index       Linear SVM (Paper)\")\n",
        "print(\" \" + \"-\"*35)\n",
        "print(\" KSE-100     0.8519\")\n",
        "print(\" KOSPI       0.8022\")\n",
        "print(\" Nikkei 225  0.8022\")\n",
        "print(\" SZSE        0.8998\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"‚úÖ RETURNS-BASED ANALƒ∞Z TAMAMLANDI\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\\nüí° KRƒ∞Tƒ∞K FARK:\")\n",
        "print(\" ‚úÖ Returns-based stationary features kullanƒ±ldƒ±\")\n",
        "print(\" ‚úÖ Log returns ‚Üí Non-stationary problem √ß√∂z√ºld√º\")\n",
        "print(\" ‚úÖ Volatility adjustment eklendi\")\n",
        "print(\" ‚úÖ Financial time series best practices uygulandƒ±\")\n",
        "print(\"\\nüî¨ Eƒüer sonu√ßlar hala d√º≈ü√ºkse:\")\n",
        "print(\" ‚Üí Veri kalitesi problemi (Yahoo Finance vs Professional data)\")\n",
        "print(\" ‚Üí Makale metodolojisinde gizli adƒ±mlar olabilir\")\n",
        "print(\" ‚Üí Farklƒ± model (Random Forest, Neural Net) denenebilir\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "qh0ng2xc-WPk",
        "outputId": "d5c38cfc-88d1-4f69-930a-f0739a2cad19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üì¶ VERSƒ∞YON 5: Multiple Lags (10 lags per indicator)\n",
            "‚úÖ Kurulum tamamlandƒ±!\n",
            "\n",
            "================================================================================\n",
            "LEVEL 1: VERƒ∞ √áEKME (2011-01-01 to 2020-09-27)\n",
            "================================================================================\n",
            "\n",
            "üìä KSE100 (^KSE)... ‚úÖ 2346 g√ºn\n",
            "\n",
            "üìä KOSPI (^KS11)... ‚úÖ 2397 g√ºn\n",
            "\n",
            "üìä Nikkei225 (^N225)... ‚úÖ 2382 g√ºn\n",
            "\n",
            "üìä SZSE (000001.SS)... ‚úÖ 2366 g√ºn\n",
            "\n",
            "================================================================================\n",
            "‚úÖ 4 borsa √ßekildi\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "LEVEL 2: 15 TEKNƒ∞K G√ñSTERGE (Table 1 - Original)\n",
            "================================================================================\n",
            "\n",
            "KSE100... ‚úÖ 2346 satƒ±r\n",
            "\n",
            "KOSPI... ‚úÖ 2397 satƒ±r\n",
            "\n",
            "Nikkei225... ‚úÖ 2382 satƒ±r\n",
            "\n",
            "SZSE... ‚úÖ 2366 satƒ±r\n",
            "\n",
            "================================================================================\n",
            "‚úÖ G√∂stergeler hesaplandƒ±\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "LEVEL 3: MULTIPLE LAGS FEATURE ENGINEERING\n",
            "================================================================================\n",
            "\n",
            "KSE100:\n",
            " Creating 10 lags for each of 15 indicators...\n",
            " Total lagged features created: 150\n",
            " Veri: 2316 satƒ±r | Features: 150 | Up: 53.6%\n",
            " Train: 1852 | Test: 464\n",
            "\n",
            "KOSPI:\n",
            " Creating 10 lags for each of 15 indicators...\n",
            " Total lagged features created: 150\n",
            " Veri: 2367 satƒ±r | Features: 150 | Up: 52.4%\n",
            " Train: 1893 | Test: 474\n",
            "\n",
            "Nikkei225:\n",
            " Creating 10 lags for each of 15 indicators...\n",
            " Total lagged features created: 150\n",
            " Veri: 2352 satƒ±r | Features: 150 | Up: 53.0%\n",
            " Train: 1881 | Test: 471\n",
            "\n",
            "SZSE:\n",
            " Creating 10 lags for each of 15 indicators...\n",
            " Total lagged features created: 150\n",
            " Veri: 2336 satƒ±r | Features: 150 | Up: 52.7%\n",
            " Train: 1868 | Test: 468\n",
            "\n",
            "================================================================================\n",
            "‚úÖ 4 borsa hazƒ±r (Multiple lags)\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "LEVEL 4: SVM LINEAR KERNEL (Multiple Lags Test)\n",
            "================================================================================\n",
            "\n",
            " KSE100\n",
            " ----------------------------------------------------------------------\n",
            " Best C: 0.001\n",
            " CV Score: 0.5405 (54.05%)\n",
            " Test Acc: 0.5172 (51.72%)\n",
            " Precision: 0.5172\n",
            " Recall: 1.0000\n",
            " F1-Score: 0.6818\n",
            "\n",
            " KOSPI\n",
            " ----------------------------------------------------------------------\n",
            " Best C: 0.001\n",
            " CV Score: 0.5140 (51.40%)\n",
            " Test Acc: 0.5654 (56.54%)\n",
            " Precision: 0.5654\n",
            " Recall: 1.0000\n",
            " F1-Score: 0.7224\n",
            "\n",
            " Nikkei225\n",
            " ----------------------------------------------------------------------\n",
            " Best C: 0.001\n",
            " CV Score: 0.5316 (53.16%)\n",
            " Test Acc: 0.5244 (52.44%)\n",
            " Precision: 0.5244\n",
            " Recall: 1.0000\n",
            " F1-Score: 0.6880\n",
            "\n",
            " SZSE\n",
            " ----------------------------------------------------------------------\n",
            " Best C: 4\n",
            " CV Score: 0.5519 (55.19%)\n",
            " Test Acc: 0.5363 (53.63%)\n",
            " Precision: 0.5521\n",
            " Recall: 0.7000\n",
            " F1-Score: 0.6173\n",
            "\n",
            "================================================================================\n",
            "                    üìä MULTIPLE LAGS SONU√áLAR\n",
            "================================================================================\n",
            "\n",
            " Index           Best C     CV Score     Test Acc     F1-Score    \n",
            " ----------------------------------------------------------------------\n",
            " KSE100          0.001      0.5405       0.5172       0.6818      \n",
            " KOSPI           0.001      0.5140       0.5654       0.7224      \n",
            " Nikkei225       0.001      0.5316       0.5244       0.6880      \n",
            " SZSE            4          0.5519       0.5363       0.6173      \n",
            " ----------------------------------------------------------------------\n",
            " AVERAGE         -          0.5345       0.5358       0.6774      \n",
            "\n",
            " ================================================================================\n",
            " üìà VERSƒ∞YON KAR≈ûILA≈ûTIRMASI\n",
            " ================================================================================\n",
            "\n",
            " Versiyon                        Avg Test Acc\n",
            " --------------------------------------------------\n",
            " V1: Norm LAG √∂ncesi (1 lag)    0.5630\n",
            " V2: Target same-day             0.5147\n",
            " V3: Pivot double-lag fix        0.5630\n",
            " V4: Returns-based               0.5323\n",
            " V5: Multiple lags (10)          0.5358\n",
            "\n",
            " ================================================================================\n",
            " üéØ MAKALE SONU√áLARI (Table 11)\n",
            " ================================================================================\n",
            "\n",
            " Index       Linear SVM (Paper)\n",
            " -----------------------------------\n",
            " KSE-100     0.8519\n",
            " KOSPI       0.8022\n",
            " Nikkei 225  0.8022\n",
            " SZSE        0.8998\n",
            "\n",
            "================================================================================\n",
            "‚úÖ MULTIPLE LAGS ANALƒ∞Z TAMAMLANDI\n",
            "================================================================================\n",
            "\n",
            "üí° KRƒ∞Tƒ∞K FARK:\n",
            " ‚úÖ Her indicator i√ßin 10 lag kullanƒ±ldƒ± (150 features)\n",
            " ‚úÖ Temporal pattern'leri yakalamak i√ßin SVM'e 'ge√ßmi≈ü' verildi\n",
            " ‚úÖ Medium makalesindeki 'lag features' yakla≈üƒ±mƒ± uygulandƒ±\n",
            "\n",
            "üî¨ Sonu√ßlarƒ±n yorumu:\n",
            " ‚Üí Eƒüer accuracy ARTTI: Multiple lags i≈üe yarƒ±yor! ‚úÖ\n",
            " ‚Üí Eƒüer accuracy AYNI: Problem ba≈üka yerde (veri kalitesi)\n",
            " ‚Üí Eƒüer accuracy D√ú≈ûT√ú: Overfitting (150 feature √ßok fazla)\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "============================================================================\n",
        "VERSƒ∞YON 5: MULTIPLE LAGS APPROACH\n",
        "============================================================================\n",
        "Hipotez: Her indicator i√ßin SADECE 1 lag deƒüil, MULTIPLE LAGS kullanmalƒ±yƒ±z!\n",
        "         SVM zaman serisini anlamƒ±yor, temporal pattern'i lag'lerle √∂ƒüretmeliyiz!\n",
        "\n",
        "Medium'dan √∂ƒürendiƒüimiz:\n",
        "\"SVMs do not inherently understand time series data\"\n",
        "‚Üí Solution: Create multiple lag features (lag_1, lag_2, ..., lag_N)\n",
        "\n",
        "Deƒüi≈üiklik:\n",
        "- ESKƒ∞: 15 indicators √ó 1 lag = 15 features\n",
        "- YENƒ∞: 15 indicators √ó 10 lags = 150 features!\n",
        "============================================================================\n",
        "\"\"\"\n",
        "\n",
        "import sys\n",
        "import subprocess\n",
        "print(\"üì¶ VERSƒ∞YON 5: Multiple Lags (10 lags per indicator)\")\n",
        "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\",\n",
        "                      \"yfinance\", \"ta\", \"scikit-learn\", \"pandas\", \"numpy\"])\n",
        "\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import ta\n",
        "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"‚úÖ Kurulum tamamlandƒ±!\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# LEVEL 1: VERƒ∞ √áEKME\n",
        "# ============================================================================\n",
        "print(\"=\"*80)\n",
        "print(\"LEVEL 1: VERƒ∞ √áEKME (2011-01-01 to 2020-09-27)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "tickers = {\n",
        "    'KSE100': '^KSE',\n",
        "    'KOSPI': '^KS11',\n",
        "    'Nikkei225': '^N225',\n",
        "    'SZSE': '000001.SS'\n",
        "}\n",
        "\n",
        "all_data = {}\n",
        "for name, ticker in tickers.items():\n",
        "    print(f\"\\nüìä {name} ({ticker})...\", end=\" \")\n",
        "    try:\n",
        "        data = yf.download(ticker, start=\"2011-01-01\", end=\"2020-09-27\",\n",
        "                          progress=False, auto_adjust=True)\n",
        "\n",
        "        if data.empty:\n",
        "            print(\"‚ùå VERƒ∞ YOK!\")\n",
        "            continue\n",
        "\n",
        "        if isinstance(data.columns, pd.MultiIndex):\n",
        "            data.columns = data.columns.get_level_values(0)\n",
        "\n",
        "        data = data[['Open', 'High', 'Low', 'Close', 'Volume']].copy()\n",
        "        data = data.dropna()\n",
        "\n",
        "        all_data[name] = data\n",
        "        print(f\"‚úÖ {len(data)} g√ºn\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå {e}\")\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(f\"‚úÖ {len(all_data)} borsa √ßekildi\")\n",
        "print(f\"{'='*80}\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# LEVEL 2: TEKNƒ∞K G√ñSTERGELER (Table 1 - Original)\n",
        "# ============================================================================\n",
        "print(\"=\"*80)\n",
        "print(\"LEVEL 2: 15 TEKNƒ∞K G√ñSTERGE (Table 1 - Original)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "def hesapla_teknik_gostergeler(df):\n",
        "    \"\"\"Makalenin Table 1 form√ºllerine g√∂re (original price-based)\"\"\"\n",
        "    df = df.copy()\n",
        "\n",
        "    high = df['High'].squeeze()\n",
        "    low = df['Low'].squeeze()\n",
        "    close = df['Close'].squeeze()\n",
        "\n",
        "    # 1-2. Stochastic Oscillator\n",
        "    stoch = ta.momentum.StochasticOscillator(high, low, close,\n",
        "                                             window=14, smooth_window=3)\n",
        "    df['Stochastic_K'] = stoch.stoch()\n",
        "    df['Stochastic_D'] = stoch.stoch_signal()\n",
        "\n",
        "    # 3. ROC (10 period)\n",
        "    df['ROC'] = ta.momentum.ROCIndicator(close, window=10).roc()\n",
        "\n",
        "    # 4. Williams %R (14 period)\n",
        "    df['Williams_R'] = ta.momentum.WilliamsRIndicator(high, low, close,\n",
        "                                                       lbp=14).williams_r()\n",
        "\n",
        "    # 5. Momentum (4 period: C_t - C_{t-4})\n",
        "    df['Momentum'] = close.diff(4)\n",
        "\n",
        "    # 6. Disparity 5\n",
        "    ma5 = close.rolling(5).mean()\n",
        "    df['Disparity_5'] = np.where(ma5 != 0, (close / ma5) * 100, 100)\n",
        "\n",
        "    # 7. Disparity 14\n",
        "    ma14 = close.rolling(14).mean()\n",
        "    df['Disparity_14'] = np.where(ma14 != 0, (close / ma14) * 100, 100)\n",
        "\n",
        "    # 8. OSCP (Price Oscillator)\n",
        "    ma10 = close.rolling(10).mean()\n",
        "    df['OSCP'] = np.where(ma5 != 0, ((ma5 - ma10) / ma5), 0)\n",
        "\n",
        "    # 9. CCI (20 period)\n",
        "    df['CCI'] = ta.trend.CCIIndicator(high, low, close, window=20).cci()\n",
        "\n",
        "    # 10. RSI (14 period)\n",
        "    df['RSI'] = ta.momentum.RSIIndicator(close, window=14).rsi()\n",
        "\n",
        "    # 11-15. Pivot Points\n",
        "    prev_high = high.shift(1)\n",
        "    prev_low = low.shift(1)\n",
        "    prev_close = close.shift(1)\n",
        "\n",
        "    df['Pivot_Point'] = (prev_high + prev_low + prev_close) / 3\n",
        "    df['S1'] = (df['Pivot_Point'] * 2) - prev_high\n",
        "    df['S2'] = df['Pivot_Point'] - (prev_high - prev_low)\n",
        "    df['R1'] = (df['Pivot_Point'] * 2) - prev_low\n",
        "    df['R2'] = df['Pivot_Point'] + (prev_high - prev_low)\n",
        "\n",
        "    df = df.replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "    return df\n",
        "\n",
        "all_data_indicators = {}\n",
        "for name, data in all_data.items():\n",
        "    print(f\"\\n{name}...\", end=\" \")\n",
        "    try:\n",
        "        result = hesapla_teknik_gostergeler(data)\n",
        "        all_data_indicators[name] = result\n",
        "        print(f\"‚úÖ {len(result)} satƒ±r\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå {e}\")\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(f\"‚úÖ G√∂stergeler hesaplandƒ±\")\n",
        "print(f\"{'='*80}\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# LEVEL 3: MULTIPLE LAGS FEATURE ENGINEERING\n",
        "# ============================================================================\n",
        "print(\"=\"*80)\n",
        "print(\"LEVEL 3: MULTIPLE LAGS FEATURE ENGINEERING\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "def veri_hazirla_multiple_lags(df, test_ratio=0.2, n_lags=10):\n",
        "    \"\"\"\n",
        "    üéØ MULTIPLE LAGS: Her indicator i√ßin N lag olu≈ütur\n",
        "\n",
        "    √ñrnek:\n",
        "    - RSI ‚Üí RSI_lag1, RSI_lag2, ..., RSI_lag10\n",
        "    - CCI ‚Üí CCI_lag1, CCI_lag2, ..., CCI_lag10\n",
        "\n",
        "    Total features: 15 indicators √ó 10 lags = 150 features!\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "\n",
        "    # Base indicators\n",
        "    base_features = [\n",
        "        'Stochastic_K', 'Stochastic_D', 'ROC', 'Williams_R',\n",
        "        'Momentum', 'Disparity_5', 'Disparity_14', 'OSCP',\n",
        "        'CCI', 'RSI', 'Pivot_Point', 'S1', 'S2', 'R1', 'R2'\n",
        "    ]\n",
        "\n",
        "    # 1Ô∏è‚É£ Target: Next day direction\n",
        "    df['Next_Close'] = df['Close'].shift(-1)\n",
        "    df['Target'] = (df['Next_Close'] > df['Close']).astype(int)\n",
        "    df = df.iloc[:-1].copy()\n",
        "\n",
        "    # 2Ô∏è‚É£ NaN temizle\n",
        "    df = df.replace([np.inf, -np.inf], np.nan)\n",
        "    df = df.dropna(subset=base_features + ['Target'])\n",
        "\n",
        "    # 3Ô∏è‚É£ ‚ö†Ô∏è NORMALIZATION √ñNCE (data leakage var ama makale ile kar≈üƒ±la≈ütƒ±rmak i√ßin)\n",
        "    scaler = MinMaxScaler()\n",
        "    df[base_features] = scaler.fit_transform(df[base_features])\n",
        "\n",
        "    # 4Ô∏è‚É£ üéØ MULTIPLE LAGS OLU≈ûTUR\n",
        "    print(f\" Creating {n_lags} lags for each of {len(base_features)} indicators...\")\n",
        "\n",
        "    lagged_features = []\n",
        "    for indicator in base_features:\n",
        "        for lag in range(1, n_lags + 1):\n",
        "            lagged_col = f'{indicator}_lag{lag}'\n",
        "            df[lagged_col] = df[indicator].shift(lag)\n",
        "            lagged_features.append(lagged_col)\n",
        "\n",
        "    print(f\" Total lagged features created: {len(lagged_features)}\")\n",
        "\n",
        "    # 5Ô∏è‚É£ Lag sonrasƒ± NaN temizle (en b√ºy√ºk lag kadar satƒ±r kaybedilir)\n",
        "    df = df.dropna(subset=lagged_features)\n",
        "\n",
        "    X = df[lagged_features].copy()\n",
        "    y = df['Target'].copy()\n",
        "\n",
        "    print(f\" Veri: {len(X)} satƒ±r | Features: {X.shape[1]} | Up: {y.mean()*100:.1f}%\")\n",
        "\n",
        "    # 6Ô∏è‚É£ Zaman bazlƒ± split\n",
        "    n_train = int(len(X) * (1 - test_ratio))\n",
        "    X_train = X.iloc[:n_train].copy()\n",
        "    X_test = X.iloc[n_train:].copy()\n",
        "    y_train = y.iloc[:n_train].values\n",
        "    y_test = y.iloc[n_train:].values\n",
        "\n",
        "    print(f\" Train: {len(X_train)} | Test: {len(X_test)}\")\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "prepared_data = {}\n",
        "for name, data in all_data_indicators.items():\n",
        "    print(f\"\\n{name}:\")\n",
        "    try:\n",
        "        X_train, X_test, y_train, y_test = veri_hazirla_multiple_lags(data, n_lags=10)\n",
        "        prepared_data[name] = {\n",
        "            'X_train': X_train, 'X_test': X_test,\n",
        "            'y_train': y_train, 'y_test': y_test\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\" ‚ùå {e}\")\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(f\"‚úÖ {len(prepared_data)} borsa hazƒ±r (Multiple lags)\")\n",
        "print(f\"{'='*80}\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# LEVEL 4: SVM LINEAR KERNEL\n",
        "# ============================================================================\n",
        "print(\"=\"*80)\n",
        "print(\"LEVEL 4: SVM LINEAR KERNEL (Multiple Lags Test)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "def test_svm_linear(X_train, y_train, X_test, y_test, name):\n",
        "    \"\"\"SVM Linear kernel test\"\"\"\n",
        "\n",
        "    print(f\"\\n {name}\")\n",
        "    print(\" \" + \"-\"*70)\n",
        "\n",
        "    # Grid search\n",
        "    param_grid = {\n",
        "        'C': [0.001, 0.01, 0.1, 1, 4, 10, 50, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000]\n",
        "    }\n",
        "\n",
        "    cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "    svm = SVC(kernel='linear', max_iter=50000, random_state=42)\n",
        "\n",
        "    grid = GridSearchCV(svm, param_grid, cv=cv, scoring='accuracy', n_jobs=-1, verbose=0)\n",
        "    grid.fit(X_train, y_train)\n",
        "\n",
        "    # Test\n",
        "    best_model = grid.best_estimator_\n",
        "    y_pred = best_model.predict(X_test)\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    prec = precision_score(y_test, y_pred, zero_division=0)\n",
        "    rec = recall_score(y_test, y_pred, zero_division=0)\n",
        "    f1 = f1_score(y_test, y_pred, zero_division=0)\n",
        "\n",
        "    print(f\" Best C: {grid.best_params_['C']}\")\n",
        "    print(f\" CV Score: {grid.best_score_:.4f} ({grid.best_score_*100:.2f}%)\")\n",
        "    print(f\" Test Acc: {acc:.4f} ({acc*100:.2f}%)\")\n",
        "    print(f\" Precision: {prec:.4f}\")\n",
        "    print(f\" Recall: {rec:.4f}\")\n",
        "    print(f\" F1-Score: {f1:.4f}\")\n",
        "\n",
        "    return {\n",
        "        'best_C': grid.best_params_['C'],\n",
        "        'cv_score': grid.best_score_,\n",
        "        'test_acc': acc,\n",
        "        'precision': prec,\n",
        "        'recall': rec,\n",
        "        'f1': f1\n",
        "    }\n",
        "\n",
        "results = {}\n",
        "\n",
        "for name in prepared_data.keys():\n",
        "    data = prepared_data[name]\n",
        "    try:\n",
        "        result = test_svm_linear(\n",
        "            data['X_train'], data['y_train'],\n",
        "            data['X_test'], data['y_test'],\n",
        "            name\n",
        "        )\n",
        "        results[name] = result\n",
        "    except Exception as e:\n",
        "        print(f\" ‚ùå {name}: {e}\")\n",
        "\n",
        "# ============================================================================\n",
        "# SONU√áLAR\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\" \"*20 + \"üìä MULTIPLE LAGS SONU√áLAR\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(f\"\\n {'Index':<15} {'Best C':<10} {'CV Score':<12} {'Test Acc':<12} {'F1-Score':<12}\")\n",
        "print(\" \" + \"-\"*70)\n",
        "\n",
        "for name, result in results.items():\n",
        "    print(f\" {name:<15} {result['best_C']:<10} {result['cv_score']:<12.4f} {result['test_acc']:<12.4f} {result['f1']:<12.4f}\")\n",
        "\n",
        "# Ortalama\n",
        "if len(results) > 0:\n",
        "    avg_cv = np.mean([r['cv_score'] for r in results.values()])\n",
        "    avg_test = np.mean([r['test_acc'] for r in results.values()])\n",
        "    avg_f1 = np.mean([r['f1'] for r in results.values()])\n",
        "\n",
        "    print(\" \" + \"-\"*70)\n",
        "    print(f\" {'AVERAGE':<15} {'-':<10} {avg_cv:<12.4f} {avg_test:<12.4f} {avg_f1:<12.4f}\")\n",
        "\n",
        "# √ñnceki versiyonlarla kar≈üƒ±la≈ütƒ±rma\n",
        "print(f\"\\n {'='*80}\")\n",
        "print(\" üìà VERSƒ∞YON KAR≈ûILA≈ûTIRMASI\")\n",
        "print(f\" {'='*80}\\n\")\n",
        "\n",
        "print(\" Versiyon                        Avg Test Acc\")\n",
        "print(\" \" + \"-\"*50)\n",
        "print(\" V1: Norm LAG √∂ncesi (1 lag)    0.5630\")\n",
        "print(\" V2: Target same-day             0.5147\")\n",
        "print(\" V3: Pivot double-lag fix        0.5630\")\n",
        "print(\" V4: Returns-based               0.5323\")\n",
        "if len(results) > 0:\n",
        "    print(f\" V5: Multiple lags (10)          {avg_test:.4f}\")\n",
        "\n",
        "# Makale kar≈üƒ±la≈ütƒ±rma\n",
        "print(f\"\\n {'='*80}\")\n",
        "print(\" üéØ MAKALE SONU√áLARI (Table 11)\")\n",
        "print(f\" {'='*80}\\n\")\n",
        "print(\" Index       Linear SVM (Paper)\")\n",
        "print(\" \" + \"-\"*35)\n",
        "print(\" KSE-100     0.8519\")\n",
        "print(\" KOSPI       0.8022\")\n",
        "print(\" Nikkei 225  0.8022\")\n",
        "print(\" SZSE        0.8998\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"‚úÖ MULTIPLE LAGS ANALƒ∞Z TAMAMLANDI\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\\nüí° KRƒ∞Tƒ∞K FARK:\")\n",
        "print(\" ‚úÖ Her indicator i√ßin 10 lag kullanƒ±ldƒ± (150 features)\")\n",
        "print(\" ‚úÖ Temporal pattern'leri yakalamak i√ßin SVM'e 'ge√ßmi≈ü' verildi\")\n",
        "print(\" ‚úÖ Medium makalesindeki 'lag features' yakla≈üƒ±mƒ± uygulandƒ±\")\n",
        "print(\"\\nüî¨ Sonu√ßlarƒ±n yorumu:\")\n",
        "print(\" ‚Üí Eƒüer accuracy ARTTI: Multiple lags i≈üe yarƒ±yor! ‚úÖ\")\n",
        "print(\" ‚Üí Eƒüer accuracy AYNI: Problem ba≈üka yerde (veri kalitesi)\")\n",
        "print(\" ‚Üí Eƒüer accuracy D√ú≈ûT√ú: Overfitting (150 feature √ßok fazla)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XJ4gDvqx-WSs"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}