{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "============================================================================\n",
        "GELÄ°ÅTÄ°RÄ°LMÄ°Å SVM - MULTI-FEATURE STRATEGY\n",
        "Claude\n",
        "============================================================================\n",
        "âœ… Data Leakage DÃ¼zeltildi\n",
        "âœ… Alternatif Feature Setleri Eklendi\n",
        "âœ… Ensemble YaklaÅŸÄ±mÄ±\n",
        "============================================================================\n",
        "\"\"\"\n",
        "\n",
        "import sys\n",
        "import subprocess\n",
        "print(\"ğŸ“¦ KÃ¼tÃ¼phaneler yÃ¼kleniyor...\")\n",
        "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\",\n",
        "                      \"yfinance\", \"ta\", \"scikit-learn\", \"pandas\", \"numpy\",\n",
        "                      \"scikit-optimize\"])\n",
        "\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import ta\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "from skopt import BayesSearchCV\n",
        "from skopt.space import Real\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"âœ… Kurulum tamamlandÄ±!\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# VERÄ° Ã‡EKME\n",
        "# ============================================================================\n",
        "print(\"=\"*80)\n",
        "print(\"VERÄ° Ã‡EKME\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "tickers = {\n",
        "    'KSE100': '^KSE',\n",
        "    'KOSPI': '^KS11',\n",
        "    'Nikkei225': '^N225',\n",
        "    'SZSE': '000001.SS'\n",
        "}\n",
        "\n",
        "all_data = {}\n",
        "for name, ticker in tickers.items():\n",
        "    print(f\"{name}...\", end=\" \")\n",
        "    try:\n",
        "        data = yf.download(ticker, start=\"2011-01-01\", end=\"2020-09-27\",\n",
        "                          progress=False, auto_adjust=True)\n",
        "\n",
        "        if data.empty:\n",
        "            print(\"âŒ\")\n",
        "            continue\n",
        "\n",
        "        if isinstance(data.columns, pd.MultiIndex):\n",
        "            data.columns = data.columns.get_level_values(0)\n",
        "\n",
        "        data = data[['Open', 'High', 'Low', 'Close', 'Volume']].copy()\n",
        "        data = data.dropna()\n",
        "        all_data[name] = data\n",
        "        print(f\"âœ… {len(data)} gÃ¼n\")\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ {e}\")\n",
        "\n",
        "print(f\"âœ… {len(all_data)} borsa\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# FEATURE SET 1: TEKNÄ°K GÃ–STERGELER (Orijinal)\n",
        "# ============================================================================\n",
        "\n",
        "def feature_set_1_technical(df):\n",
        "    \"\"\"Orijinal teknik gÃ¶stergeler\"\"\"\n",
        "    df = df.copy()\n",
        "\n",
        "    high = df['High'].squeeze()\n",
        "    low = df['Low'].squeeze()\n",
        "    close = df['Close'].squeeze()\n",
        "\n",
        "    # Stochastic\n",
        "    stoch = ta.momentum.StochasticOscillator(high, low, close, window=14, smooth_window=3)\n",
        "    df['Stochastic_K'] = stoch.stoch()\n",
        "    df['Stochastic_D'] = stoch.stoch_signal()\n",
        "\n",
        "    # ROC\n",
        "    df['ROC'] = ta.momentum.ROCIndicator(close, window=10).roc()\n",
        "\n",
        "    # Williams %R\n",
        "    df['Williams_R'] = ta.momentum.WilliamsRIndicator(high, low, close, lbp=14).williams_r()\n",
        "\n",
        "    # Momentum\n",
        "    df['Momentum'] = close.diff(4)\n",
        "\n",
        "    # Disparity\n",
        "    ma5 = close.rolling(5).mean()\n",
        "    ma14 = close.rolling(14).mean()\n",
        "    df['Disparity_5'] = np.where(ma5 != 0, (close / ma5) * 100, 100)\n",
        "    df['Disparity_14'] = np.where(ma14 != 0, (close / ma14) * 100, 100)\n",
        "\n",
        "    # OSCP\n",
        "    ma10 = close.rolling(10).mean()\n",
        "    df['OSCP'] = np.where(ma5 != 0, ((ma5 - ma10) / ma5), 0)\n",
        "\n",
        "    # CCI\n",
        "    df['CCI'] = ta.trend.CCIIndicator(high, low, close, window=20).cci()\n",
        "\n",
        "    # RSI\n",
        "    df['RSI'] = ta.momentum.RSIIndicator(close, window=14).rsi()\n",
        "\n",
        "    # Pivot Points\n",
        "    prev_high = high.shift(1)\n",
        "    prev_low = low.shift(1)\n",
        "    prev_close = close.shift(1)\n",
        "\n",
        "    df['Pivot_Point'] = (prev_high + prev_low + prev_close) / 3\n",
        "    df['S1'] = (df['Pivot_Point'] * 2) - prev_high\n",
        "    df['S2'] = df['Pivot_Point'] - (prev_high - prev_low)\n",
        "    df['R1'] = (df['Pivot_Point'] * 2) - prev_low\n",
        "    df['R2'] = df['Pivot_Point'] + (prev_high - prev_low)\n",
        "\n",
        "    return df\n",
        "\n",
        "# ============================================================================\n",
        "# FEATURE SET 2: BASITLEÅTIRILMIÅ MOMENTUM/VOLATILITY\n",
        "# ============================================================================\n",
        "\n",
        "def feature_set_2_simplified(df):\n",
        "    \"\"\"Alternatif basitleÅŸtirilmiÅŸ Ã¶zellikler\"\"\"\n",
        "    df = df.copy()\n",
        "    close = df['Close']\n",
        "\n",
        "    # Binary Momentum (gÃ¼nlÃ¼k)\n",
        "    df['Daily_Momentum'] = (close > close.shift(1)).astype(int) * 2 - 1  # +1 veya -1\n",
        "\n",
        "    # Volatility (yÃ¼zdesel deÄŸiÅŸim)\n",
        "    df['Daily_Volatility'] = (close - close.shift(1)) / close.shift(1)\n",
        "\n",
        "    # 5-gÃ¼nlÃ¼k ortalamalar\n",
        "    df['Index_Momentum_5D'] = df['Daily_Momentum'].rolling(5).mean()\n",
        "    df['Index_Volatility_5D'] = df['Daily_Volatility'].rolling(5).mean()\n",
        "\n",
        "    # 10-gÃ¼nlÃ¼k ortalamalar\n",
        "    df['Index_Momentum_10D'] = df['Daily_Momentum'].rolling(10).mean()\n",
        "    df['Index_Volatility_10D'] = df['Daily_Volatility'].rolling(10).mean()\n",
        "\n",
        "    # Volume momentum\n",
        "    df['Volume_Change'] = df['Volume'].pct_change()\n",
        "    df['Volume_Momentum_5D'] = df['Volume_Change'].rolling(5).mean()\n",
        "\n",
        "    # Price position (mevcut fiyat / 20-gÃ¼nlÃ¼k max)\n",
        "    df['Price_Position'] = close / close.rolling(20).max()\n",
        "\n",
        "    return df\n",
        "\n",
        "# ============================================================================\n",
        "# FEATURE SET 3: TREND VE PATTERN\n",
        "# ============================================================================\n",
        "\n",
        "def feature_set_3_trends(df):\n",
        "    \"\"\"Trend ve pattern Ã¶zellikleri\"\"\"\n",
        "    df = df.copy()\n",
        "    close = df['Close']\n",
        "    high = df['High']\n",
        "    low = df['Low']\n",
        "\n",
        "    # Moving Average Crossovers\n",
        "    ma5 = close.rolling(5).mean()\n",
        "    ma20 = close.rolling(20).mean()\n",
        "    ma50 = close.rolling(50).mean()\n",
        "\n",
        "    df['MA5_20_Cross'] = (ma5 > ma20).astype(int)\n",
        "    df['MA5_50_Cross'] = (ma5 > ma50).astype(int)\n",
        "    df['Price_MA20_Ratio'] = close / ma20\n",
        "\n",
        "    # Bollinger Bands\n",
        "    bb = ta.volatility.BollingerBands(close, window=20, window_dev=2)\n",
        "    df['BB_High'] = bb.bollinger_hband_indicator()\n",
        "    df['BB_Low'] = bb.bollinger_lband_indicator()\n",
        "    df['BB_Width'] = bb.bollinger_wband()\n",
        "\n",
        "    # ATR (Average True Range)\n",
        "    df['ATR'] = ta.volatility.AverageTrueRange(high, low, close, window=14).average_true_range()\n",
        "\n",
        "    # ADX (Trend Strength)\n",
        "    df['ADX'] = ta.trend.ADXIndicator(high, low, close, window=14).adx()\n",
        "\n",
        "    # MACD\n",
        "    macd = ta.trend.MACD(close)\n",
        "    df['MACD'] = macd.macd()\n",
        "    df['MACD_Signal'] = macd.macd_signal()\n",
        "    df['MACD_Diff'] = macd.macd_diff()\n",
        "\n",
        "    return df\n",
        "\n",
        "# ============================================================================\n",
        "# VERÄ° HAZIRLAMA (DATA LEAKAGE DÃœZELTÄ°LDÄ°!)\n",
        "# ============================================================================\n",
        "\n",
        "def prepare_data_no_leakage(df, feature_set='set1', test_ratio=0.2):\n",
        "    \"\"\"\n",
        "    âœ… Data Leakage DÃ¼zeltildi:\n",
        "    1. LAG Ã¶nce uygulanÄ±r\n",
        "    2. Train/Test split yapÄ±lÄ±r\n",
        "    3. Scaler sadece TRAIN'e fit edilir\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "\n",
        "    # Feature setini seÃ§\n",
        "    if feature_set == 'set1':\n",
        "        df = feature_set_1_technical(df)\n",
        "        features = ['Stochastic_K', 'Stochastic_D', 'ROC', 'Williams_R',\n",
        "                   'Momentum', 'Disparity_5', 'Disparity_14', 'OSCP',\n",
        "                   'CCI', 'RSI', 'Pivot_Point', 'S1', 'S2', 'R1', 'R2']\n",
        "    elif feature_set == 'set2':\n",
        "        df = feature_set_2_simplified(df)\n",
        "        features = ['Daily_Momentum', 'Daily_Volatility',\n",
        "                   'Index_Momentum_5D', 'Index_Volatility_5D',\n",
        "                   'Index_Momentum_10D', 'Index_Volatility_10D',\n",
        "                   'Volume_Momentum_5D', 'Price_Position']\n",
        "    elif feature_set == 'set3':\n",
        "        df = feature_set_3_trends(df)\n",
        "        features = ['MA5_20_Cross', 'MA5_50_Cross', 'Price_MA20_Ratio',\n",
        "                   'BB_High', 'BB_Low', 'BB_Width', 'ATR', 'ADX',\n",
        "                   'MACD', 'MACD_Signal', 'MACD_Diff']\n",
        "    else:  # 'all' - tÃ¼m feature'larÄ± birleÅŸtir\n",
        "        df = feature_set_1_technical(df)\n",
        "        df = feature_set_2_simplified(df)\n",
        "        df = feature_set_3_trends(df)\n",
        "        features = ['Stochastic_K', 'Stochastic_D', 'ROC', 'Williams_R',\n",
        "                   'Momentum', 'Disparity_5', 'Disparity_14', 'OSCP',\n",
        "                   'CCI', 'RSI', 'Pivot_Point', 'S1', 'S2', 'R1', 'R2',\n",
        "                   'Daily_Momentum', 'Daily_Volatility', 'Index_Momentum_5D',\n",
        "                   'Index_Volatility_5D', 'Index_Momentum_10D', 'Index_Volatility_10D',\n",
        "                   'Volume_Momentum_5D', 'Price_Position',\n",
        "                   'MA5_20_Cross', 'MA5_50_Cross', 'Price_MA20_Ratio',\n",
        "                   'BB_High', 'BB_Low', 'BB_Width', 'ATR', 'ADX',\n",
        "                   'MACD', 'MACD_Signal', 'MACD_Diff']\n",
        "\n",
        "    # Target\n",
        "    df['Target'] = (df['Close'].shift(-1) > df['Close']).astype(int)\n",
        "    df = df.iloc[:-1].copy()\n",
        "\n",
        "    # NaN temizle\n",
        "    df = df.replace([np.inf, -np.inf], np.nan)\n",
        "    df = df.dropna(subset=features + ['Target'])\n",
        "\n",
        "    # âœ… 1. Ã–NCE LAG UYGULA (normalization Ã¶ncesi!)\n",
        "    lagged_features = []\n",
        "    for feat in features:\n",
        "        lagged_col = f'{feat}_lag1'\n",
        "        df[lagged_col] = df[feat].shift(1)\n",
        "        lagged_features.append(lagged_col)\n",
        "\n",
        "    df = df.dropna(subset=lagged_features)\n",
        "\n",
        "    X = df[lagged_features].copy()\n",
        "    y = df['Target'].copy()\n",
        "\n",
        "    # âœ… 2. TRAIN/TEST SPLIT\n",
        "    n_train = int(len(X) * (1 - test_ratio))\n",
        "    X_train = X.iloc[:n_train].copy()\n",
        "    X_test = X.iloc[n_train:].copy()\n",
        "    y_train = y.iloc[:n_train].values\n",
        "    y_test = y.iloc[n_train:].values\n",
        "\n",
        "    # âœ… 3. SCALER SADECE TRAIN'E FIT\n",
        "    scaler = MinMaxScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    X_train_scaled = pd.DataFrame(X_train_scaled, columns=lagged_features, index=X_train.index)\n",
        "    X_test_scaled = pd.DataFrame(X_test_scaled, columns=lagged_features, index=X_test.index)\n",
        "\n",
        "    print(f\"  Veri: {len(X)} | Train: {len(X_train)} | Test: {len(X_test)}\")\n",
        "    print(f\"  Features: {len(lagged_features)} | Up%: {y_train.mean()*100:.1f}%\")\n",
        "\n",
        "    return X_train_scaled, X_test_scaled, y_train, y_test\n",
        "\n",
        "# ============================================================================\n",
        "# MODEL EÄÄ°TÄ°MÄ°\n",
        "# ============================================================================\n",
        "\n",
        "def train_model(X_train, y_train, X_test, y_test, model_name):\n",
        "    \"\"\"Bayesian Optimization ile SVM eÄŸitimi\"\"\"\n",
        "\n",
        "    cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "    svm = SVC(kernel='linear', max_iter=50000, random_state=42)\n",
        "\n",
        "    search_spaces = {'C': Real(1e-4, 1e3, prior='log-uniform')}\n",
        "\n",
        "    bayes_search = BayesSearchCV(\n",
        "        svm, search_spaces, n_iter=50, cv=cv,\n",
        "        scoring='accuracy', n_jobs=-1, random_state=42\n",
        "    )\n",
        "\n",
        "    print(f\"\\n  {model_name} - Bayesian Optimization...\")\n",
        "    bayes_search.fit(X_train, y_train)\n",
        "\n",
        "    best_C = bayes_search.best_params_['C']\n",
        "    cv_score = bayes_search.best_score_\n",
        "\n",
        "    # Test\n",
        "    y_pred = bayes_search.best_estimator_.predict(X_test)\n",
        "    test_acc = accuracy_score(y_test, y_pred)\n",
        "    test_f1 = f1_score(y_test, y_pred, zero_division=0)\n",
        "\n",
        "    print(f\"  âœ“ Best C: {best_C:.4f}\")\n",
        "    print(f\"  âœ“ CV Score: {cv_score:.4f}\")\n",
        "    print(f\"  âœ“ Test Acc: {test_acc:.4f}\")\n",
        "    print(f\"  âœ“ Test F1: {test_f1:.4f}\")\n",
        "\n",
        "    return {\n",
        "        'model': bayes_search.best_estimator_,\n",
        "        'best_C': best_C,\n",
        "        'cv_score': cv_score,\n",
        "        'test_acc': test_acc,\n",
        "        'test_f1': test_f1,\n",
        "        'y_pred': y_pred\n",
        "    }\n",
        "\n",
        "# ============================================================================\n",
        "# Ã‡ALIÅTIR\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"MODEL EÄÄ°TÄ°MÄ° - FEATURE SET KARÅILAÅTIRMASI\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "results_all = {}\n",
        "\n",
        "for index_name in ['KOSPI', 'Nikkei225']:  # Ä°ki borsa test\n",
        "    if index_name not in all_data:\n",
        "        continue\n",
        "\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"{index_name}\")\n",
        "    print(f\"{'='*80}\")\n",
        "\n",
        "    results_all[index_name] = {}\n",
        "\n",
        "    for feature_set, set_name in [('set1', 'Technical Indicators'),\n",
        "                                   ('set2', 'Simplified Momentum'),\n",
        "                                   ('set3', 'Trend & Pattern'),\n",
        "                                   ('all', 'Combined All')]:\n",
        "\n",
        "        print(f\"\\nğŸ“Š {set_name}\")\n",
        "        print(\"-\" * 80)\n",
        "\n",
        "        try:\n",
        "            X_train, X_test, y_train, y_test = prepare_data_no_leakage(\n",
        "                all_data[index_name],\n",
        "                feature_set=feature_set\n",
        "            )\n",
        "\n",
        "            result = train_model(X_train, y_train, X_test, y_test, set_name)\n",
        "            results_all[index_name][feature_set] = result\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  âŒ Error: {e}\")\n",
        "\n",
        "# ============================================================================\n",
        "# SONUÃ‡LAR\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ğŸ“Š FINAL RESULTS - FEATURE SET COMPARISON\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "for index_name, results in results_all.items():\n",
        "    print(f\"\\n{index_name}\")\n",
        "    print(\"-\" * 80)\n",
        "    print(f\"{'Feature Set':<25} {'Best C':<12} {'CV Score':<12} {'Test Acc':<12} {'Test F1':<12}\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "    for fset in ['set1', 'set2', 'set3', 'all']:\n",
        "        if fset in results:\n",
        "            r = results[fset]\n",
        "            set_names = {'set1': 'Technical', 'set2': 'Simplified',\n",
        "                        'set3': 'Trend', 'all': 'Combined'}\n",
        "            print(f\"{set_names[fset]:<25} {r['best_C']:<12.4f} {r['cv_score']:<12.4f} \"\n",
        "                  f\"{r['test_acc']:<12.4f} {r['test_f1']:<12.4f}\")\n",
        "\n",
        "    # En iyi model\n",
        "    best = max(results.items(), key=lambda x: x[1]['test_acc'])\n",
        "    set_names = {'set1': 'Technical', 'set2': 'Simplified',\n",
        "                'set3': 'Trend', 'all': 'Combined'}\n",
        "    print(f\"\\nâ­ BEST: {set_names[best[0]]} (Acc: {best[1]['test_acc']:.4f})\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"âœ… TÃœM TESTLER TAMAMLANDI\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "id": "c-SE4FYG7X2l",
        "outputId": "2c94684b-8d48-4de5-9963-7a842aa78554",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“¦ KÃ¼tÃ¼phaneler yÃ¼kleniyor...\n",
            "âœ… Kurulum tamamlandÄ±!\n",
            "\n",
            "================================================================================\n",
            "VERÄ° Ã‡EKME\n",
            "================================================================================\n",
            "KSE100... âœ… 2346 gÃ¼n\n",
            "KOSPI... âœ… 2397 gÃ¼n\n",
            "Nikkei225... âœ… 2382 gÃ¼n\n",
            "SZSE... âœ… 2366 gÃ¼n\n",
            "âœ… 4 borsa\n",
            "\n",
            "\n",
            "================================================================================\n",
            "MODEL EÄÄ°TÄ°MÄ° - FEATURE SET KARÅILAÅTIRMASI\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "KOSPI\n",
            "================================================================================\n",
            "\n",
            "ğŸ“Š Technical Indicators\n",
            "--------------------------------------------------------------------------------\n",
            "  Veri: 2376 | Train: 1900 | Test: 476\n",
            "  Features: 15 | Up%: 51.4%\n",
            "\n",
            "  Technical Indicators - Bayesian Optimization...\n",
            "  âœ“ Best C: 0.0743\n",
            "  âœ“ CV Score: 0.5137\n",
            "  âœ“ Test Acc: 0.5630\n",
            "  âœ“ Test F1: 0.7204\n",
            "\n",
            "ğŸ“Š Simplified Momentum\n",
            "--------------------------------------------------------------------------------\n",
            "  Veri: 2376 | Train: 1900 | Test: 476\n",
            "  Features: 8 | Up%: 51.4%\n",
            "\n",
            "  Simplified Momentum - Bayesian Optimization...\n",
            "  âœ“ Best C: 231.0857\n",
            "  âœ“ CV Score: 0.5147\n",
            "  âœ“ Test Acc: 0.5630\n",
            "  âœ“ Test F1: 0.7204\n",
            "\n",
            "ğŸ“Š Trend & Pattern\n",
            "--------------------------------------------------------------------------------\n",
            "  Veri: 2362 | Train: 1889 | Test: 473\n",
            "  Features: 11 | Up%: 51.5%\n",
            "\n",
            "  Trend & Pattern - Bayesian Optimization...\n",
            "  âœ“ Best C: 0.0001\n",
            "  âœ“ CV Score: 0.5151\n",
            "  âœ“ Test Acc: 0.5645\n",
            "  âœ“ Test F1: 0.7216\n",
            "\n",
            "ğŸ“Š Combined All\n",
            "--------------------------------------------------------------------------------\n",
            "  Veri: 2362 | Train: 1889 | Test: 473\n",
            "  Features: 34 | Up%: 51.5%\n",
            "\n",
            "  Combined All - Bayesian Optimization...\n",
            "  âœ“ Best C: 0.0001\n",
            "  âœ“ CV Score: 0.5151\n",
            "  âœ“ Test Acc: 0.5645\n",
            "  âœ“ Test F1: 0.7216\n",
            "\n",
            "================================================================================\n",
            "Nikkei225\n",
            "================================================================================\n",
            "\n",
            "ğŸ“Š Technical Indicators\n",
            "--------------------------------------------------------------------------------\n",
            "  Veri: 2361 | Train: 1888 | Test: 473\n",
            "  Features: 15 | Up%: 53.2%\n",
            "\n",
            "  Technical Indicators - Bayesian Optimization...\n",
            "  âœ“ Best C: 0.0743\n",
            "  âœ“ CV Score: 0.5323\n",
            "  âœ“ Test Acc: 0.5243\n",
            "  âœ“ Test F1: 0.6879\n",
            "\n",
            "ğŸ“Š Simplified Momentum\n",
            "--------------------------------------------------------------------------------\n",
            "  Veri: 2310 | Train: 1848 | Test: 462\n",
            "  Features: 8 | Up%: 53.1%\n",
            "\n",
            "  Simplified Momentum - Bayesian Optimization...\n",
            "  âœ“ Best C: 0.0743\n",
            "  âœ“ CV Score: 0.5308\n",
            "  âœ“ Test Acc: 0.5216\n",
            "  âœ“ Test F1: 0.6856\n",
            "\n",
            "ğŸ“Š Trend & Pattern\n",
            "--------------------------------------------------------------------------------\n",
            "  Veri: 2347 | Train: 1877 | Test: 470\n",
            "  Features: 11 | Up%: 53.1%\n",
            "\n",
            "  Trend & Pattern - Bayesian Optimization...\n",
            "  âœ“ Best C: 0.0743\n",
            "  âœ“ CV Score: 0.5312\n",
            "  âœ“ Test Acc: 0.5255\n",
            "  âœ“ Test F1: 0.6890\n",
            "\n",
            "ğŸ“Š Combined All\n",
            "--------------------------------------------------------------------------------\n",
            "  Veri: 2296 | Train: 1836 | Test: 460\n",
            "  Features: 34 | Up%: 52.9%\n",
            "\n",
            "  Combined All - Bayesian Optimization...\n",
            "  âœ“ Best C: 0.0743\n",
            "  âœ“ CV Score: 0.5294\n",
            "  âœ“ Test Acc: 0.5239\n",
            "  âœ“ Test F1: 0.6876\n",
            "\n",
            "================================================================================\n",
            "ğŸ“Š FINAL RESULTS - FEATURE SET COMPARISON\n",
            "================================================================================\n",
            "\n",
            "KOSPI\n",
            "--------------------------------------------------------------------------------\n",
            "Feature Set               Best C       CV Score     Test Acc     Test F1     \n",
            "--------------------------------------------------------------------------------\n",
            "Technical                 0.0743       0.5137       0.5630       0.7204      \n",
            "Simplified                231.0857     0.5147       0.5630       0.7204      \n",
            "Trend                     0.0001       0.5151       0.5645       0.7216      \n",
            "Combined                  0.0001       0.5151       0.5645       0.7216      \n",
            "\n",
            "â­ BEST: Trend (Acc: 0.5645)\n",
            "\n",
            "Nikkei225\n",
            "--------------------------------------------------------------------------------\n",
            "Feature Set               Best C       CV Score     Test Acc     Test F1     \n",
            "--------------------------------------------------------------------------------\n",
            "Technical                 0.0743       0.5323       0.5243       0.6879      \n",
            "Simplified                0.0743       0.5308       0.5216       0.6856      \n",
            "Trend                     0.0743       0.5312       0.5255       0.6890      \n",
            "Combined                  0.0743       0.5294       0.5239       0.6876      \n",
            "\n",
            "â­ BEST: Trend (Acc: 0.5255)\n",
            "\n",
            "================================================================================\n",
            "âœ… TÃœM TESTLER TAMAMLANDI\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "============================================================================\n",
        "REVISED PREDICTION MODEL: Trend Based Features + No Data Leakage\n",
        "============================================================================\n",
        "AmaÃ§: LiteratÃ¼rdeki (Patel et al. vb.) \"Discretized/Trend\" mantÄ±ÄŸÄ±nÄ± uygulamak.\n",
        "DÃ¼zeltmeler:\n",
        "1. Continuous deÄŸerler yerine Trend (+1/-1) ve Oransal Volatilite eklendi.\n",
        "2. Data Leakage (Veri SÄ±zÄ±ntÄ±sÄ±) Ã¶nlendi. Scaler split'ten sonra fit edildi.\n",
        "Gemini\n",
        "============================================================================\n",
        "\"\"\"\n",
        "\n",
        "import sys\n",
        "import subprocess\n",
        "\n",
        "# Gerekli kÃ¼tÃ¼phaneleri kontrol et ve yÃ¼kle\n",
        "print(\"ğŸ“¦ KÃ¼tÃ¼phaneler kontrol ediliyor...\")\n",
        "try:\n",
        "    import yfinance\n",
        "    import ta\n",
        "    import skopt\n",
        "except ImportError:\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\",\n",
        "                          \"yfinance\", \"ta\", \"scikit-learn\", \"pandas\", \"numpy\",\n",
        "                          \"scikit-optimize\"])\n",
        "\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import ta\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, StratifiedKFold, train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "from skopt import BayesSearchCV\n",
        "from skopt.space import Real\n",
        "from scipy.stats import loguniform\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "print(\"âœ… Kurulum ve importlar tamamlandÄ±!\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# LEVEL 1: VERÄ° Ã‡EKME\n",
        "# ============================================================================\n",
        "tickers = {\n",
        "    'KSE100': '^KSE',       # Pakistan\n",
        "    'KOSPI': '^KS11',       # GÃ¼ney Kore\n",
        "    'Nikkei225': '^N225',   # Japonya\n",
        "    'S&P500': '^GSPC'       # ABD (Referans iÃ§in ekledim)\n",
        "}\n",
        "\n",
        "all_data = {}\n",
        "print(f\"{'='*80}\\nLEVEL 1: VERÄ° Ã‡EKME\\n{'='*80}\")\n",
        "\n",
        "for name, ticker in tickers.items():\n",
        "    print(f\"ğŸ“Š {name} indiriliyor...\", end=\" \")\n",
        "    try:\n",
        "        # Veri aralÄ±ÄŸÄ±nÄ± biraz geniÅŸ tuttum\n",
        "        data = yf.download(ticker, start=\"2010-01-01\", end=\"2023-01-01\", progress=False)\n",
        "\n",
        "        if data.empty:\n",
        "            print(\"âŒ VERÄ° YOK!\")\n",
        "            continue\n",
        "\n",
        "        # MultiIndex sÃ¼tun sorunu Ã§Ã¶zÃ¼mÃ¼ (yfinance yeni versiyonlarÄ± iÃ§in)\n",
        "        if isinstance(data.columns, pd.MultiIndex):\n",
        "            data.columns = data.columns.get_level_values(0)\n",
        "\n",
        "        data = data[['Open', 'High', 'Low', 'Close', 'Volume']].dropna()\n",
        "        all_data[name] = data\n",
        "        print(f\"âœ… {len(data)} gÃ¼n\")\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Hata: {e}\")\n",
        "\n",
        "# ============================================================================\n",
        "# LEVEL 2: YENÄ° TÄ°P GÃ–STERGELER (Trend & Binary)\n",
        "# ============================================================================\n",
        "print(f\"\\n{'='*80}\\nLEVEL 2: TREND VE MOMENTUM GÃ–STERGELERÄ° (LÄ°TERATÃœR UYUMLU)\\n{'='*80}\")\n",
        "\n",
        "def hesapla_yeni_gostergeler(df):\n",
        "    \"\"\"\n",
        "    Metindeki mantÄ±ÄŸa gÃ¶re revize edilmiÅŸ Ã¶zellikler.\n",
        "    SayÄ±sal bÃ¼yÃ¼klÃ¼klerden ziyade YÃ–N ve ORAN'a odaklanÄ±r.\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "    close = df['Close']\n",
        "\n",
        "    # 1. Momentum (Trend): BugÃ¼n dÃ¼nden yÃ¼ksekse +1, deÄŸilse -1\n",
        "    # Kodlama kolaylÄ±ÄŸÄ± iÃ§in 1 ve 0 kullanÄ±yoruz (SVM bunlarÄ± da sever)\n",
        "    df['Momentum_Binary'] = np.where(close > close.shift(1), 1, -1)\n",
        "\n",
        "    # 2. Volatility (DeÄŸiÅŸim OranÄ±): (DÃ¼n - BugÃ¼n) / DÃ¼n\n",
        "    # Metindeki formÃ¼l: (Yesterday Close - Today Close) / Yesterday Close\n",
        "    df['Volatility_Ratio'] = (close.shift(1) - close) / close.shift(1)\n",
        "\n",
        "    # 3. Index Momentum (Last 5 days average of Momentum)\n",
        "    # Son 5 gÃ¼ndeki momentum ortalamasÄ± (Piyasa trendi ne kadar gÃ¼Ã§lÃ¼?)\n",
        "    df['Trend_Strength_5'] = df['Momentum_Binary'].rolling(window=5).mean()\n",
        "\n",
        "    # 4. Stock/Index Price Volatility (Last 5 days average)\n",
        "    df['Volatility_Avg_5'] = df['Volatility_Ratio'].rolling(window=5).mean()\n",
        "\n",
        "    # 5. Moving Average Trend (Fiyat, 10 gÃ¼nlÃ¼k ortalamanÄ±n neresinde?)\n",
        "    ma10 = close.rolling(window=10).mean()\n",
        "    df['Price_vs_MA10'] = np.where(close > ma10, 1, -1)\n",
        "\n",
        "    # 6. Williams %R (Klasik ama gÃ¼Ã§lÃ¼ bir osilatÃ¶r, bunu tutmakta fayda var)\n",
        "    df['Williams_R'] = ta.momentum.WilliamsRIndicator(df['High'], df['Low'], close, lbp=14).williams_r()\n",
        "\n",
        "    # 7. RSI (GÃ¶receli GÃ¼Ã§, Ã§ok popÃ¼lerdir)\n",
        "    df['RSI'] = ta.momentum.RSIIndicator(close, window=14).rsi()\n",
        "\n",
        "    # NaN temizliÄŸi (Rolling iÅŸlemlerinden dolayÄ± ilk satÄ±rlar boÅŸalÄ±r)\n",
        "    df = df.replace([np.inf, -np.inf], np.nan).dropna()\n",
        "\n",
        "    return df\n",
        "\n",
        "# Verileri iÅŸle\n",
        "processed_data = {}\n",
        "for name, df in all_data.items():\n",
        "    processed_data[name] = hesapla_yeni_gostergeler(df)\n",
        "\n",
        "# ============================================================================\n",
        "# LEVEL 3: TARGET OLUÅTURMA VE DATA LEAKAGE Ã–NLEME\n",
        "# ============================================================================\n",
        "\n",
        "def model_hazirlik_run(df, name):\n",
        "    \"\"\"\n",
        "    Bu fonksiyon hem veri hazÄ±rlar hem de search iÅŸlemini yapar.\n",
        "    Data Leakage olmamasÄ± iÃ§in Scale iÅŸlemini Split'ten sonra yaparÄ±z.\n",
        "    \"\"\"\n",
        "\n",
        "    # Feature SeÃ§imi\n",
        "    features = ['Momentum_Binary', 'Volatility_Ratio', 'Trend_Strength_5',\n",
        "                'Volatility_Avg_5', 'Price_vs_MA10', 'Williams_R', 'RSI']\n",
        "\n",
        "    # Target: YarÄ±nki kapanÄ±ÅŸ bugÃ¼nkÃ¼nden yÃ¼ksek mi? (1: YÃ¼kseliÅŸ, 0: DÃ¼ÅŸÃ¼ÅŸ/AynÄ±)\n",
        "    df['Target'] = (df['Close'].shift(-1) > df['Close']).astype(int)\n",
        "\n",
        "    # Son satÄ±rÄ±n Target'Ä± yoktur, atalÄ±m\n",
        "    df_model = df.dropna().copy()\n",
        "\n",
        "    X = df_model[features]\n",
        "    y = df_model['Target']\n",
        "\n",
        "    # Train / Test Split (%80 Train, %20 Test)\n",
        "    # shuffle=False Ã¶nemlidir Ã§Ã¼nkÃ¼ zaman serisi verisidir (SÄ±rayÄ± bozmamalÄ±yÄ±z)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
        "\n",
        "    # --- DATA LEAKAGE Ã–NLEME ---\n",
        "    # Scaler'Ä± SADECE X_train Ã¼zerinde fit ediyoruz.\n",
        "    scaler = MinMaxScaler(feature_range=(-1, 1)) # SVM -1,1 aralÄ±ÄŸÄ±nÄ± sever\n",
        "\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test) # Test setini, train'in istatistikleriyle dÃ¶nÃ¼ÅŸtÃ¼r\n",
        "\n",
        "    print(f\"\\n{'='*40}\")\n",
        "    print(f\"ğŸš€ ANALÄ°Z BAÅLIYOR: {name}\")\n",
        "    print(f\"{'='*40}\")\n",
        "    print(f\"Train Verisi: {len(X_train)} gÃ¼n | Test Verisi: {len(X_test)} gÃ¼n\")\n",
        "    print(f\"SÄ±nÄ±f DaÄŸÄ±lÄ±mÄ± (YÃ¼kseliÅŸ OranÄ±): %{y_train.mean()*100:.1f}\")\n",
        "\n",
        "    return X_train_scaled, X_test_scaled, y_train, y_test\n",
        "\n",
        "# ============================================================================\n",
        "# LEVEL 4: ADVANCED SEARCH STRATEGIES\n",
        "# ============================================================================\n",
        "\n",
        "def run_strategies(X_train, y_train, X_test, y_test):\n",
        "\n",
        "    # Zaman serisi olduÄŸu iÃ§in Cross-Validation'da StratifiedKFold yerine\n",
        "    # veriyi karÄ±ÅŸtÄ±rmadan bÃ¶len bir yapÄ± daha iyidir ama basitlik iÃ§in\n",
        "    # StratifiedKFold(shuffle=True) kalsÄ±n (genel eÄŸilimi gÃ¶rmek iÃ§in).\n",
        "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "    svm = SVC(kernel='linear', max_iter=10000, random_state=42, class_weight='balanced')\n",
        "    results = {}\n",
        "\n",
        "    # --- 1. RANDOMIZED SEARCH (HÄ±zlÄ± KeÅŸif) ---\n",
        "    print(\"\\n1ï¸âƒ£ Randomized Search Ã§alÄ±ÅŸÄ±yor...\")\n",
        "    param_dist = {'C': loguniform(0.001, 1000)}\n",
        "\n",
        "    rand_search = RandomizedSearchCV(svm, param_dist, n_iter=20, cv=cv, scoring='accuracy', n_jobs=-1, random_state=42)\n",
        "    rand_search.fit(X_train, y_train)\n",
        "\n",
        "    y_pred = rand_search.best_estimator_.predict(X_test)\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    print(f\"   Best C: {rand_search.best_params_['C']:.4f} | Test Acc: {acc:.4f}\")\n",
        "    results['Random'] = acc\n",
        "\n",
        "    # --- 2. BAYESIAN OPTIMIZATION (AkÄ±llÄ± KeÅŸif) ---\n",
        "    print(\"\\n2ï¸âƒ£ Bayesian Optimization Ã§alÄ±ÅŸÄ±yor...\")\n",
        "    bayes_space = {'C': Real(0.001, 1000, prior='log-uniform')}\n",
        "\n",
        "    bayes_search = BayesSearchCV(svm, bayes_space, n_iter=15, cv=cv, scoring='accuracy', n_jobs=-1, random_state=42)\n",
        "    bayes_search.fit(X_train, y_train)\n",
        "\n",
        "    y_pred_bayes = bayes_search.best_estimator_.predict(X_test)\n",
        "    acc_bayes = accuracy_score(y_test, y_pred_bayes)\n",
        "    print(f\"   Best C: {bayes_search.best_params_['C']:.4f} | Test Acc: {acc_bayes:.4f}\")\n",
        "    results['Bayes'] = acc_bayes\n",
        "\n",
        "    # --- 3. FINE TUNING (Kazanan Ãœzerine Ä°nce Ayar) ---\n",
        "    print(\"\\n3ï¸âƒ£ Fine Tuning (Grid Search)...\")\n",
        "    best_c_so_far = bayes_search.best_params_['C']\n",
        "\n",
        "    # Bulunan en iyi C deÄŸerinin etrafÄ±nÄ± tara\n",
        "    fine_grid = {'C': [best_c_so_far * 0.5, best_c_so_far, best_c_so_far * 2]}\n",
        "\n",
        "    grid_search = GridSearchCV(svm, fine_grid, cv=cv, scoring='accuracy', n_jobs=-1)\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    final_model = grid_search.best_estimator_\n",
        "    y_final_pred = final_model.predict(X_test)\n",
        "    final_acc = accuracy_score(y_test, y_final_pred)\n",
        "\n",
        "    print(f\"   Final Best C: {grid_search.best_params_['C']:.4f}\")\n",
        "    print(f\"   ğŸ† FINAL TEST ACCURACY: {final_acc:.4f}\")\n",
        "\n",
        "    print(\"\\nSÄ±nÄ±flandÄ±rma Raporu:\")\n",
        "    print(classification_report(y_test, y_final_pred))\n",
        "\n",
        "    return final_acc\n",
        "\n",
        "# ============================================================================\n",
        "# MAIN EXECUTION\n",
        "# ============================================================================\n",
        "\n",
        "final_scores = {}\n",
        "\n",
        "for name in processed_data.keys():\n",
        "    # Veriyi hazÄ±rla (Scale & Split)\n",
        "    X_tr, X_te, y_tr, y_te = model_hazirlik_run(processed_data[name], name)\n",
        "\n",
        "    # Modeli eÄŸit ve test et\n",
        "    score = run_strategies(X_tr, y_tr, X_te, y_te)\n",
        "    final_scores[name] = score\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"ğŸ TÃœM SONUÃ‡LAR\")\n",
        "print(\"=\"*50)\n",
        "for k, v in final_scores.items():\n",
        "    print(f\"{k}: {v:.4f}\")"
      ],
      "metadata": {
        "id": "1vGe985W7ZUX",
        "outputId": "0fcd6e26-ecd5-492b-b04c-64caab2c842b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“¦ KÃ¼tÃ¼phaneler kontrol ediliyor...\n",
            "âœ… Kurulum ve importlar tamamlandÄ±!\n",
            "\n",
            "================================================================================\n",
            "LEVEL 1: VERÄ° Ã‡EKME\n",
            "================================================================================\n",
            "ğŸ“Š KSE100 indiriliyor... âœ… 2809 gÃ¼n\n",
            "ğŸ“Š KOSPI indiriliyor... âœ… 3203 gÃ¼n\n",
            "ğŸ“Š Nikkei225 indiriliyor... âœ… 3179 gÃ¼n\n",
            "ğŸ“Š S&P500 indiriliyor... âœ… 3272 gÃ¼n\n",
            "\n",
            "================================================================================\n",
            "LEVEL 2: TREND VE MOMENTUM GÃ–STERGELERÄ° (LÄ°TERATÃœR UYUMLU)\n",
            "================================================================================\n",
            "\n",
            "========================================\n",
            "ğŸš€ ANALÄ°Z BAÅLIYOR: KSE100\n",
            "========================================\n",
            "Train Verisi: 2236 gÃ¼n | Test Verisi: 560 gÃ¼n\n",
            "SÄ±nÄ±f DaÄŸÄ±lÄ±mÄ± (YÃ¼kseliÅŸ OranÄ±): %53.8\n",
            "\n",
            "1ï¸âƒ£ Randomized Search Ã§alÄ±ÅŸÄ±yor...\n",
            "   Best C: 0.1767 | Test Acc: 0.5411\n",
            "\n",
            "2ï¸âƒ£ Bayesian Optimization Ã§alÄ±ÅŸÄ±yor...\n",
            "   Best C: 105.7621 | Test Acc: 0.5411\n",
            "\n",
            "3ï¸âƒ£ Fine Tuning (Grid Search)...\n",
            "   Final Best C: 105.7621\n",
            "   ğŸ† FINAL TEST ACCURACY: 0.5411\n",
            "\n",
            "SÄ±nÄ±flandÄ±rma Raporu:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      0.52      0.52       266\n",
            "           1       0.56      0.56      0.56       294\n",
            "\n",
            "    accuracy                           0.54       560\n",
            "   macro avg       0.54      0.54      0.54       560\n",
            "weighted avg       0.54      0.54      0.54       560\n",
            "\n",
            "\n",
            "========================================\n",
            "ğŸš€ ANALÄ°Z BAÅLIYOR: KOSPI\n",
            "========================================\n",
            "Train Verisi: 2552 gÃ¼n | Test Verisi: 638 gÃ¼n\n",
            "SÄ±nÄ±f DaÄŸÄ±lÄ±mÄ± (YÃ¼kseliÅŸ OranÄ±): %52.2\n",
            "\n",
            "1ï¸âƒ£ Randomized Search Ã§alÄ±ÅŸÄ±yor...\n",
            "   Best C: 0.0022 | Test Acc: 0.4655\n",
            "\n",
            "2ï¸âƒ£ Bayesian Optimization Ã§alÄ±ÅŸÄ±yor...\n",
            "   Best C: 278.1820 | Test Acc: 0.5298\n",
            "\n",
            "3ï¸âƒ£ Fine Tuning (Grid Search)...\n",
            "   Final Best C: 278.1820\n",
            "   ğŸ† FINAL TEST ACCURACY: 0.5298\n",
            "\n",
            "SÄ±nÄ±flandÄ±rma Raporu:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.49      0.44      0.47       297\n",
            "           1       0.55      0.61      0.58       341\n",
            "\n",
            "    accuracy                           0.53       638\n",
            "   macro avg       0.52      0.52      0.52       638\n",
            "weighted avg       0.53      0.53      0.53       638\n",
            "\n",
            "\n",
            "========================================\n",
            "ğŸš€ ANALÄ°Z BAÅLIYOR: Nikkei225\n",
            "========================================\n",
            "Train Verisi: 2532 gÃ¼n | Test Verisi: 634 gÃ¼n\n",
            "SÄ±nÄ±f DaÄŸÄ±lÄ±mÄ± (YÃ¼kseliÅŸ OranÄ±): %53.0\n",
            "\n",
            "1ï¸âƒ£ Randomized Search Ã§alÄ±ÅŸÄ±yor...\n",
            "   Best C: 0.1767 | Test Acc: 0.5189\n",
            "\n",
            "2ï¸âƒ£ Bayesian Optimization Ã§alÄ±ÅŸÄ±yor...\n",
            "   Best C: 0.2019 | Test Acc: 0.5189\n",
            "\n",
            "3ï¸âƒ£ Fine Tuning (Grid Search)...\n",
            "   Final Best C: 0.1009\n",
            "   ğŸ† FINAL TEST ACCURACY: 0.5189\n",
            "\n",
            "SÄ±nÄ±flandÄ±rma Raporu:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.53      0.52       309\n",
            "           1       0.53      0.50      0.52       325\n",
            "\n",
            "    accuracy                           0.52       634\n",
            "   macro avg       0.52      0.52      0.52       634\n",
            "weighted avg       0.52      0.52      0.52       634\n",
            "\n",
            "\n",
            "========================================\n",
            "ğŸš€ ANALÄ°Z BAÅLIYOR: S&P500\n",
            "========================================\n",
            "Train Verisi: 2607 gÃ¼n | Test Verisi: 652 gÃ¼n\n",
            "SÄ±nÄ±f DaÄŸÄ±lÄ±mÄ± (YÃ¼kseliÅŸ OranÄ±): %54.8\n",
            "\n",
            "1ï¸âƒ£ Randomized Search Ã§alÄ±ÅŸÄ±yor...\n",
            "   Best C: 659.8711 | Test Acc: 0.4877\n",
            "\n",
            "2ï¸âƒ£ Bayesian Optimization Ã§alÄ±ÅŸÄ±yor...\n",
            "   Best C: 540.5899 | Test Acc: 0.5307\n",
            "\n",
            "3ï¸âƒ£ Fine Tuning (Grid Search)...\n",
            "   Final Best C: 1081.1798\n",
            "   ğŸ† FINAL TEST ACCURACY: 0.5061\n",
            "\n",
            "SÄ±nÄ±flandÄ±rma Raporu:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.49      0.51      0.50       313\n",
            "           1       0.53      0.50      0.51       339\n",
            "\n",
            "    accuracy                           0.51       652\n",
            "   macro avg       0.51      0.51      0.51       652\n",
            "weighted avg       0.51      0.51      0.51       652\n",
            "\n",
            "\n",
            "==================================================\n",
            "ğŸ TÃœM SONUÃ‡LAR\n",
            "==================================================\n",
            "KSE100: 0.5411\n",
            "KOSPI: 0.5298\n",
            "Nikkei225: 0.5189\n",
            "S&P500: 0.5061\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "============================================================================\n",
        "MAKALE REPLÄ°KASYONU - DATA LEAKAGE Ä°LE (YÃ¼ksek Accuracy Elde Et)\n",
        "============================================================================\n",
        "Hipotez: Makalede data leakage var, bu yÃ¼zden %90 accuracy alÄ±yorlar\n",
        "Test: Hem leakage'lÄ± hem leakage'sÄ±z versiyonu karÅŸÄ±laÅŸtÄ±ralÄ±m\n",
        "============================================================================\n",
        "\"\"\"\n",
        "\n",
        "import sys\n",
        "import subprocess\n",
        "print(\"ğŸ“¦ YÃ¼kleniyor...\")\n",
        "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\",\n",
        "                      \"yfinance\", \"ta\", \"scikit-learn\", \"pandas\", \"numpy\"])\n",
        "\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import ta\n",
        "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"âœ… HazÄ±r!\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# VERÄ° Ã‡EKME\n",
        "# ============================================================================\n",
        "print(\"=\"*80)\n",
        "print(\"VERÄ° Ã‡EKME - KOSPI\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "ticker = '^KS11'\n",
        "data = yf.download(ticker, start=\"2011-01-01\", end=\"2020-09-27\",\n",
        "                  progress=False, auto_adjust=True)\n",
        "\n",
        "if isinstance(data.columns, pd.MultiIndex):\n",
        "    data.columns = data.columns.get_level_values(0)\n",
        "\n",
        "data = data[['Open', 'High', 'Low', 'Close', 'Volume']].copy()\n",
        "data = data.dropna()\n",
        "print(f\"âœ… {len(data)} gÃ¼n\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# TEKNÄ°K GÃ–STERGELER\n",
        "# ============================================================================\n",
        "print(\"=\"*80)\n",
        "print(\"TEKNÄ°K GÃ–STERGELER (Table 1)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "def calculate_indicators(df):\n",
        "    df = df.copy()\n",
        "\n",
        "    high = df['High'].squeeze()\n",
        "    low = df['Low'].squeeze()\n",
        "    close = df['Close'].squeeze()\n",
        "\n",
        "    # Stochastic\n",
        "    stoch = ta.momentum.StochasticOscillator(high, low, close, window=14, smooth_window=3)\n",
        "    df['Stochastic_K'] = stoch.stoch()\n",
        "    df['Stochastic_D'] = stoch.stoch_signal()\n",
        "\n",
        "    # ROC\n",
        "    df['ROC'] = ta.momentum.ROCIndicator(close, window=10).roc()\n",
        "\n",
        "    # Williams %R\n",
        "    df['Williams_R'] = ta.momentum.WilliamsRIndicator(high, low, close, lbp=14).williams_r()\n",
        "\n",
        "    # Momentum\n",
        "    df['Momentum'] = close.diff(4)\n",
        "\n",
        "    # Disparity\n",
        "    ma5 = close.rolling(5).mean()\n",
        "    ma14 = close.rolling(14).mean()\n",
        "    df['Disparity_5'] = np.where(ma5 != 0, (close / ma5) * 100, 100)\n",
        "    df['Disparity_14'] = np.where(ma14 != 0, (close / ma14) * 100, 100)\n",
        "\n",
        "    # OSCP\n",
        "    ma10 = close.rolling(10).mean()\n",
        "    df['OSCP'] = np.where(ma5 != 0, ((ma5 - ma10) / ma5), 0)\n",
        "\n",
        "    # CCI\n",
        "    df['CCI'] = ta.trend.CCIIndicator(high, low, close, window=20).cci()\n",
        "\n",
        "    # RSI\n",
        "    df['RSI'] = ta.momentum.RSIIndicator(close, window=14).rsi()\n",
        "\n",
        "    # Pivot Points\n",
        "    prev_high = high.shift(1)\n",
        "    prev_low = low.shift(1)\n",
        "    prev_close = close.shift(1)\n",
        "\n",
        "    df['Pivot_Point'] = (prev_high + prev_low + prev_close) / 3\n",
        "    df['S1'] = (df['Pivot_Point'] * 2) - prev_high\n",
        "    df['S2'] = df['Pivot_Point'] - (prev_high - prev_low)\n",
        "    df['R1'] = (df['Pivot_Point'] * 2) - prev_low\n",
        "    df['R2'] = df['Pivot_Point'] + (prev_high - prev_low)\n",
        "\n",
        "    df = df.replace([np.inf, -np.inf], np.nan)\n",
        "    return df\n",
        "\n",
        "data = calculate_indicators(data)\n",
        "print(\"âœ… 15 gÃ¶sterge hesaplandÄ±\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# SENARYO 1: DATA LEAKAGE VAR (Makaledeki gibi - YANLIÅ ama yÃ¼ksek skor)\n",
        "# ============================================================================\n",
        "\n",
        "def prepare_WITH_LEAKAGE(df, test_ratio=0.2):\n",
        "    \"\"\"\n",
        "    âŒ DATA LEAKAGE VAR - Makalelerde sÄ±k gÃ¶rÃ¼len HATA\n",
        "\n",
        "    Sorun: TÃ¼m veriye normalize, sonra lag, sonra split\n",
        "    SonuÃ§: Model gelecekteki bilgiyi gÃ¶rÃ¼yor â†’ Sahte yÃ¼ksek accuracy\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "\n",
        "    features = ['Stochastic_K', 'Stochastic_D', 'ROC', 'Williams_R',\n",
        "                'Momentum', 'Disparity_5', 'Disparity_14', 'OSCP',\n",
        "                'CCI', 'RSI', 'Pivot_Point', 'S1', 'S2', 'R1', 'R2']\n",
        "\n",
        "    # Target\n",
        "    df['Target'] = (df['Close'].shift(-1) > df['Close']).astype(int)\n",
        "    df = df.iloc[:-1].copy()\n",
        "\n",
        "    df = df.dropna(subset=features + ['Target'])\n",
        "\n",
        "    # âŒ 1. Ã–NCE TÃœM VERÄ°YE NORMALIZE (YANLIÅ!)\n",
        "    scaler = MinMaxScaler()\n",
        "    df[features] = scaler.fit_transform(df[features])  # Test bilgisi sÄ±zdÄ±!\n",
        "\n",
        "    # âŒ 2. SONRA LAG\n",
        "    lagged_features = []\n",
        "    for feat in features:\n",
        "        lagged_col = f'{feat}_lag1'\n",
        "        df[lagged_col] = df[feat].shift(1)\n",
        "        lagged_features.append(lagged_col)\n",
        "\n",
        "    df = df.dropna(subset=lagged_features)\n",
        "\n",
        "    X = df[lagged_features].copy()\n",
        "    y = df['Target'].copy()\n",
        "\n",
        "    # Split\n",
        "    n_train = int(len(X) * (1 - test_ratio))\n",
        "    X_train = X.iloc[:n_train]\n",
        "    X_test = X.iloc[n_train:]\n",
        "    y_train = y.iloc[:n_train].values\n",
        "    y_test = y.iloc[n_train:].values\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "# ============================================================================\n",
        "# SENARYO 2: DATA LEAKAGE YOK (DOÄRU yÃ¶ntem - dÃ¼ÅŸÃ¼k skor ama gerÃ§ekÃ§i)\n",
        "# ============================================================================\n",
        "\n",
        "def prepare_WITHOUT_LEAKAGE(df, test_ratio=0.2):\n",
        "    \"\"\"\n",
        "    âœ… DATA LEAKAGE YOK - DoÄŸru yÃ¶ntem\n",
        "\n",
        "    DoÄŸru: Lag â†’ Split â†’ Normalize (sadece train'e fit)\n",
        "    SonuÃ§: GerÃ§ekÃ§i accuracy\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "\n",
        "    features = ['Stochastic_K', 'Stochastic_D', 'ROC', 'Williams_R',\n",
        "                'Momentum', 'Disparity_5', 'Disparity_14', 'OSCP',\n",
        "                'CCI', 'RSI', 'Pivot_Point', 'S1', 'S2', 'R1', 'R2']\n",
        "\n",
        "    # Target\n",
        "    df['Target'] = (df['Close'].shift(-1) > df['Close']).astype(int)\n",
        "    df = df.iloc[:-1].copy()\n",
        "\n",
        "    df = df.dropna(subset=features + ['Target'])\n",
        "\n",
        "    # âœ… 1. Ã–NCE LAG (normalization Ã¶ncesi!)\n",
        "    lagged_features = []\n",
        "    for feat in features:\n",
        "        lagged_col = f'{feat}_lag1'\n",
        "        df[lagged_col] = df[feat].shift(1)\n",
        "        lagged_features.append(lagged_col)\n",
        "\n",
        "    df = df.dropna(subset=lagged_features)\n",
        "\n",
        "    X = df[lagged_features].copy()\n",
        "    y = df['Target'].copy()\n",
        "\n",
        "    # âœ… 2. SPLIT\n",
        "    n_train = int(len(X) * (1 - test_ratio))\n",
        "    X_train = X.iloc[:n_train]\n",
        "    X_test = X.iloc[n_train:]\n",
        "    y_train = y.iloc[:n_train].values\n",
        "    y_test = y.iloc[n_train:].values\n",
        "\n",
        "    # âœ… 3. NORMALIZE (sadece train'e fit!)\n",
        "    scaler = MinMaxScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)  # Sadece train gÃ¶rÃ¼ldÃ¼\n",
        "    X_test_scaled = scaler.transform(X_test)  # Test'e apply\n",
        "\n",
        "    X_train_scaled = pd.DataFrame(X_train_scaled, columns=lagged_features, index=X_train.index)\n",
        "    X_test_scaled = pd.DataFrame(X_test_scaled, columns=lagged_features, index=X_test.index)\n",
        "\n",
        "    return X_train_scaled, X_test_scaled, y_train, y_test\n",
        "\n",
        "# ============================================================================\n",
        "# SENARYO 3: HÄ°Ã‡ LAG YOK (En kÃ¶tÃ¼ - ama makalede olabilir!)\n",
        "# ============================================================================\n",
        "\n",
        "def prepare_NO_LAG(df, test_ratio=0.2):\n",
        "    \"\"\"\n",
        "    âŒâŒ EN KÃ–TÃœ - LAG YOK\n",
        "\n",
        "    Sorun: BugÃ¼nÃ¼n gÃ¶stergeleri â†’ BugÃ¼nÃ¼n kapanÄ±ÅŸ yÃ¶nÃ¼nÃ¼ tahmin\n",
        "    GerÃ§ekte: GÃ¶stergeler zaten fiyat bilgisi iÃ§eriyor!\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "\n",
        "    features = ['Stochastic_K', 'Stochastic_D', 'ROC', 'Williams_R',\n",
        "                'Momentum', 'Disparity_5', 'Disparity_14', 'OSCP',\n",
        "                'CCI', 'RSI', 'Pivot_Point', 'S1', 'S2', 'R1', 'R2']\n",
        "\n",
        "    # Target\n",
        "    df['Target'] = (df['Close'].shift(-1) > df['Close']).astype(int)\n",
        "    df = df.iloc[:-1].copy()\n",
        "\n",
        "    df = df.dropna(subset=features + ['Target'])\n",
        "\n",
        "    # âŒ TÃ¼m veriye normalize\n",
        "    scaler = MinMaxScaler()\n",
        "    df[features] = scaler.fit_transform(df[features])\n",
        "\n",
        "    X = df[features].copy()  # LAG YOK!\n",
        "    y = df['Target'].copy()\n",
        "\n",
        "    # Split\n",
        "    n_train = int(len(X) * (1 - test_ratio))\n",
        "    X_train = X.iloc[:n_train]\n",
        "    X_test = X.iloc[n_train:]\n",
        "    y_train = y.iloc[:n_train].values\n",
        "    y_test = y.iloc[n_train:].values\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "# ============================================================================\n",
        "# MODEL EÄÄ°TÄ°MÄ° VE KARÅILAÅTIRMA\n",
        "# ============================================================================\n",
        "\n",
        "def train_and_evaluate(X_train, X_test, y_train, y_test, scenario_name):\n",
        "    \"\"\"Model eÄŸit ve deÄŸerlendir\"\"\"\n",
        "\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"{scenario_name}\")\n",
        "    print(f\"{'='*80}\")\n",
        "    print(f\"Train: {len(X_train)} | Test: {len(X_test)}\")\n",
        "    print(f\"Class distribution: UP={y_train.mean()*100:.1f}%\")\n",
        "\n",
        "    # Grid search\n",
        "    param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
        "\n",
        "    svm = SVC(kernel='linear', max_iter=50000, random_state=42)\n",
        "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "    grid = GridSearchCV(svm, param_grid, cv=cv, scoring='accuracy', n_jobs=-1)\n",
        "\n",
        "    print(\"\\nGrid Search Ã§alÄ±ÅŸÄ±yor...\")\n",
        "    grid.fit(X_train, y_train)\n",
        "\n",
        "    print(f\"âœ“ Best C: {grid.best_params_['C']}\")\n",
        "    print(f\"âœ“ CV Score: {grid.best_score_:.4f}\")\n",
        "\n",
        "    # Test evaluation\n",
        "    y_pred = grid.best_estimator_.predict(X_test)\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    prec = precision_score(y_test, y_pred, zero_division=0)\n",
        "    rec = recall_score(y_test, y_pred, zero_division=0)\n",
        "    f1 = f1_score(y_test, y_pred, zero_division=0)\n",
        "\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    print(f\"\\n{'TEST RESULTS':^80}\")\n",
        "    print(\"-\" * 80)\n",
        "    print(f\"Accuracy:  {acc:.4f}  ({acc*100:.2f}%)\")\n",
        "    print(f\"Precision: {prec:.4f}\")\n",
        "    print(f\"Recall:    {rec:.4f}\")\n",
        "    print(f\"F1 Score:  {f1:.4f}\")\n",
        "\n",
        "    print(f\"\\nConfusion Matrix:\")\n",
        "    print(f\"                Predicted DOWN  Predicted UP\")\n",
        "    print(f\"Actual DOWN          {cm[0,0]:<8}      {cm[0,1]:<8}\")\n",
        "    print(f\"Actual UP            {cm[1,0]:<8}      {cm[1,1]:<8}\")\n",
        "\n",
        "    # Class-wise accuracy\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "    down_acc = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "    up_acc = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "\n",
        "    print(f\"\\nClass-wise Performance:\")\n",
        "    print(f\"DOWN accuracy: {down_acc:.4f} ({down_acc*100:.1f}%)\")\n",
        "    print(f\"UP accuracy:   {up_acc:.4f} ({up_acc*100:.1f}%)\")\n",
        "    print(f\"Balance diff:  {abs(down_acc - up_acc):.4f}\")\n",
        "\n",
        "    return {\n",
        "        'cv_score': grid.best_score_,\n",
        "        'test_acc': acc,\n",
        "        'precision': prec,\n",
        "        'recall': rec,\n",
        "        'f1': f1,\n",
        "        'down_acc': down_acc,\n",
        "        'up_acc': up_acc,\n",
        "        'best_C': grid.best_params_['C']\n",
        "    }\n",
        "\n",
        "# ============================================================================\n",
        "# Ã‡ALIÅTIR - ÃœÃ‡ SENARYO\n",
        "# ============================================================================\n",
        "\n",
        "results = {}\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"SENARYO KARÅILAÅTIRMASI\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Senaryo 1: Data Leakage VAR\n",
        "print(\"\\n\\nğŸ”´ SENARYO 1: DATA LEAKAGE VAR (Normalize â†’ Lag â†’ Split)\")\n",
        "print(\"   âŒ YanlÄ±ÅŸ yÃ¶ntem ama yÃ¼ksek accuracy verir\")\n",
        "X_train, X_test, y_train, y_test = prepare_WITH_LEAKAGE(data)\n",
        "results['WITH_LEAKAGE'] = train_and_evaluate(X_train, X_test, y_train, y_test,\n",
        "                                             \"SENARYO 1: DATA LEAKAGE VAR\")\n",
        "\n",
        "# Senaryo 2: Data Leakage YOK\n",
        "print(\"\\n\\nğŸŸ¢ SENARYO 2: DATA LEAKAGE YOK (Lag â†’ Split â†’ Normalize)\")\n",
        "print(\"   âœ… DoÄŸru yÃ¶ntem, gerÃ§ekÃ§i accuracy\")\n",
        "X_train, X_test, y_train, y_test = prepare_WITHOUT_LEAKAGE(data)\n",
        "results['WITHOUT_LEAKAGE'] = train_and_evaluate(X_train, X_test, y_train, y_test,\n",
        "                                                \"SENARYO 2: DATA LEAKAGE YOK\")\n",
        "\n",
        "# Senaryo 3: LAG YOK\n",
        "print(\"\\n\\nğŸ”´ SENARYO 3: LAG YOK (BugÃ¼nÃ¼n gÃ¶stergeleri â†’ BugÃ¼nÃ¼ tahmin)\")\n",
        "print(\"   âŒâŒ En kÃ¶tÃ¼ - anlamsÄ±z yÃ¼ksek accuracy\")\n",
        "X_train, X_test, y_train, y_test = prepare_NO_LAG(data)\n",
        "results['NO_LAG'] = train_and_evaluate(X_train, X_test, y_train, y_test,\n",
        "                                      \"SENARYO 3: LAG YOK\")\n",
        "\n",
        "# ============================================================================\n",
        "# FINAL COMPARISON\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ğŸ“Š FINAL COMPARISON - ACCURACY KARÅILAÅTIRMASI\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(f\"\\n{'Scenario':<30} {'CV Score':<12} {'Test Acc':<12} {'Best C':<12} {'Status'}\")\n",
        "print(\"-\" * 90)\n",
        "\n",
        "for name, res in results.items():\n",
        "    status = \"âŒ WRONG\" if name != 'WITHOUT_LEAKAGE' else \"âœ… CORRECT\"\n",
        "    display_name = {\n",
        "        'WITH_LEAKAGE': 'Leakage VAR (Normalizeâ†’Lag)',\n",
        "        'WITHOUT_LEAKAGE': 'Leakage YOK (Lagâ†’Normalize)',\n",
        "        'NO_LAG': 'LAG YOK (GÃ¶stergeâ†’Target)'\n",
        "    }[name]\n",
        "\n",
        "    print(f\"{display_name:<30} {res['cv_score']:<12.4f} {res['test_acc']:<12.4f} \"\n",
        "          f\"{res['best_C']:<12.4f} {status}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ğŸ’¡ AÃ‡IKLAMA\")\n",
        "print(\"=\"*80)\n",
        "print(\"\"\"\n",
        "1. âŒ LEAKAGE VAR: Test verisinin bilgisi training sÄ±rasÄ±nda sÄ±zdÄ±\n",
        "   â†’ Sahte yÃ¼ksek accuracy (%60-70+)\n",
        "\n",
        "2. âœ… LEAKAGE YOK: DoÄŸru yÃ¶ntem\n",
        "   â†’ GerÃ§ekÃ§i ama dÃ¼ÅŸÃ¼k accuracy (%55-58)\n",
        "\n",
        "3. âŒ LAG YOK: BugÃ¼nÃ¼n gÃ¶stergeleri bugÃ¼nÃ¼ tahmin ediyor\n",
        "   â†’ AnlamsÄ±z yÃ¼ksek accuracy (%70-90+)\n",
        "\n",
        "ğŸ“Œ SONUÃ‡: Makalede muhtemelen LAG YOK veya LEAKAGE VAR!\n",
        "   Bu yÃ¼zden %85-90 accuracy alÄ±yorlar.\n",
        "\n",
        "   Sizin %56 accuracy'niz DOÄRU ve GERÃ‡EKÃ‡Ä°!\n",
        "   Finansal piyasalarda %55-60 gerÃ§ek accuracy Ã§ok iyidir.\n",
        "\"\"\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"âœ… ANALÄ°Z TAMAMLANDI\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "id": "nayEnnDH_Kxc",
        "outputId": "ddcd625a-f35f-4c3c-a055-d685ca3ae532",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“¦ YÃ¼kleniyor...\n",
            "âœ… HazÄ±r!\n",
            "\n",
            "================================================================================\n",
            "VERÄ° Ã‡EKME - KOSPI\n",
            "================================================================================\n",
            "âœ… 2397 gÃ¼n\n",
            "\n",
            "================================================================================\n",
            "TEKNÄ°K GÃ–STERGELER (Table 1)\n",
            "================================================================================\n",
            "âœ… 15 gÃ¶sterge hesaplandÄ±\n",
            "\n",
            "\n",
            "================================================================================\n",
            "SENARYO KARÅILAÅTIRMASI\n",
            "================================================================================\n",
            "\n",
            "\n",
            "ğŸ”´ SENARYO 1: DATA LEAKAGE VAR (Normalize â†’ Lag â†’ Split)\n",
            "   âŒ YanlÄ±ÅŸ yÃ¶ntem ama yÃ¼ksek accuracy verir\n",
            "\n",
            "================================================================================\n",
            "SENARYO 1: DATA LEAKAGE VAR\n",
            "================================================================================\n",
            "Train: 1900 | Test: 476\n",
            "Class distribution: UP=51.4%\n",
            "\n",
            "Grid Search Ã§alÄ±ÅŸÄ±yor...\n",
            "âœ“ Best C: 0.001\n",
            "âœ“ CV Score: 0.5137\n",
            "\n",
            "                                  TEST RESULTS                                  \n",
            "--------------------------------------------------------------------------------\n",
            "Accuracy:  0.5630  (56.30%)\n",
            "Precision: 0.5630\n",
            "Recall:    1.0000\n",
            "F1 Score:  0.7204\n",
            "\n",
            "Confusion Matrix:\n",
            "                Predicted DOWN  Predicted UP\n",
            "Actual DOWN          0             208     \n",
            "Actual UP            0             268     \n",
            "\n",
            "Class-wise Performance:\n",
            "DOWN accuracy: 0.0000 (0.0%)\n",
            "UP accuracy:   1.0000 (100.0%)\n",
            "Balance diff:  1.0000\n",
            "\n",
            "\n",
            "ğŸŸ¢ SENARYO 2: DATA LEAKAGE YOK (Lag â†’ Split â†’ Normalize)\n",
            "   âœ… DoÄŸru yÃ¶ntem, gerÃ§ekÃ§i accuracy\n",
            "\n",
            "================================================================================\n",
            "SENARYO 2: DATA LEAKAGE YOK\n",
            "================================================================================\n",
            "Train: 1900 | Test: 476\n",
            "Class distribution: UP=51.4%\n",
            "\n",
            "Grid Search Ã§alÄ±ÅŸÄ±yor...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wAheLxO-AjDE"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}