{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéØ COMPLEXITY (2021) - IMPROVED REPLICATION\n",
    "\n",
    "**Article:** Ali, M., et al. (2021). Predicting the Direction Movement of Financial Time Series Using Artificial Neural Network and Support Vector Machine. *Complexity*, 2021.\n",
    "\n",
    "**Improvements:**\n",
    "- ‚úÖ Comprehensive evaluation metrics\n",
    "- ‚úÖ Data validation checks\n",
    "- ‚úÖ Walk-forward validation option\n",
    "- ‚úÖ Feature importance analysis\n",
    "- ‚úÖ Better hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Libraries\n",
    "!pip install yfinance scikit-learn matplotlib seaborn -q\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, classification_report\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ Libraries loaded!\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Data Download with Validation\n",
    "print(\"üì• Downloading KSE-100 data...\")\n",
    "\n",
    "# Try multiple symbols\n",
    "symbols = ['^KSE', 'KSE.KA', '^SPBK10K']  # Add alternatives\n",
    "\n",
    "data = None\n",
    "for symbol in symbols:\n",
    "    try:\n",
    "        data = yf.download(symbol, start=\"2011-01-01\", end=\"2020-09-27\", progress=False)\n",
    "        if len(data) > 100:\n",
    "            print(f\"‚úÖ Successfully downloaded {len(data)} days from {symbol}\")\n",
    "            break\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "if data is None or len(data) < 100:\n",
    "    print(\"‚ö†Ô∏è KSE data not available, using SPY as demonstration\")\n",
    "    data = yf.download(\"SPY\", start=\"2011-01-01\", end=\"2020-09-27\", progress=False)\n",
    "\n",
    "print(f\"\\nüìä Data shape: {data.shape}\")\n",
    "print(f\"Date range: {data.index[0]} to {data.index[-1]}\")\n",
    "print(f\"\\nFirst rows:\\n{data.head()}\")\n",
    "\n",
    "# Check for missing values\n",
    "print(f\"\\n‚ùì Missing values: {data.isnull().sum().sum()}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Technical Indicators - VALIDATED VERSION\n",
    "print(\"üîß Calculating technical indicators...\")\n",
    "\n",
    "df = data.copy()\n",
    "\n",
    "# 1-2. Stochastic Oscillator\n",
    "low_14 = df['Low'].rolling(14).min()\n",
    "high_14 = df['High'].rolling(14).max()\n",
    "df['Stochastic_K'] = 100 * ((df['Close'] - low_14) / (high_14 - low_14 + 1e-10))  # Avoid div by zero\n",
    "df['Stochastic_D'] = df['Stochastic_K'].rolling(3).mean()\n",
    "\n",
    "# 3. Rate of Change (ROC)\n",
    "df['ROC'] = ((df['Close'] / df['Close'].shift(10)) - 1) * 100\n",
    "\n",
    "# 4. Williams %R\n",
    "df['Williams_R'] = -100 * ((high_14 - df['Close']) / (high_14 - low_14 + 1e-10))\n",
    "\n",
    "# 5. Momentum\n",
    "df['Momentum'] = df['Close'] - df['Close'].shift(4)\n",
    "\n",
    "# 6-7. Disparity Index\n",
    "ma5 = df['Close'].rolling(5).mean()\n",
    "ma14 = df['Close'].rolling(14).mean()\n",
    "df['Disparity_5'] = ((df['Close'] - ma5) / (ma5 + 1e-10)) * 100\n",
    "df['Disparity_14'] = ((df['Close'] - ma14) / (ma14 + 1e-10)) * 100\n",
    "\n",
    "# 8. OSCP (Oscillator of a Short-term Cycle)\n",
    "ma10 = df['Close'].rolling(10).mean()\n",
    "df['OSCP'] = ((ma5 - ma10) / (ma5 + 1e-10)) * 100\n",
    "\n",
    "# 9. Commodity Channel Index (CCI)\n",
    "tp = (df['High'] + df['Low'] + df['Close']) / 3\n",
    "ma_tp = tp.rolling(20).mean()\n",
    "md = tp.rolling(20).apply(lambda x: np.abs(x - x.mean()).mean())\n",
    "df['CCI'] = (tp - ma_tp) / (0.015 * md + 1e-10)\n",
    "\n",
    "# 10. Relative Strength Index (RSI)\n",
    "delta = df['Close'].diff()\n",
    "gain = (delta.where(delta > 0, 0)).rolling(14).mean()\n",
    "loss = (-delta.where(delta < 0, 0)).rolling(14).mean()\n",
    "rs = gain / (loss + 1e-10)\n",
    "df['RSI'] = 100 - (100 / (1 + rs))\n",
    "\n",
    "# 11-15. Pivot Points (using previous day's data)\n",
    "prev_high = df['High'].shift(1)\n",
    "prev_low = df['Low'].shift(1)\n",
    "prev_close = df['Close'].shift(1)\n",
    "\n",
    "df['Pivot_Point'] = (prev_high + prev_low + prev_close) / 3\n",
    "df['S1'] = (df['Pivot_Point'] * 2) - prev_high\n",
    "df['S2'] = df['Pivot_Point'] - (prev_high - prev_low)\n",
    "df['R1'] = (df['Pivot_Point'] * 2) - prev_low\n",
    "df['R2'] = df['Pivot_Point'] + (prev_high - prev_low)\n",
    "\n",
    "# Target: Next day's direction (1=Up, 0=Down)\n",
    "df['Target'] = (df['Close'].shift(-1) > df['Close']).astype(int)\n",
    "\n",
    "# Remove NaN values\n",
    "df = df.dropna()\n",
    "\n",
    "print(f\"‚úÖ {len(df)} rows prepared\")\n",
    "print(f\"\\nüìä Target distribution:\")\n",
    "print(df['Target'].value_counts(normalize=True))\n",
    "print(\"\\nüî¢ Sample indicators:\")\n",
    "print(df[['RSI', 'CCI', 'Momentum', 'Pivot_Point', 'Target']].head())\n",
    "\n",
    "# Check for infinite values\n",
    "if np.isinf(df.select_dtypes(include=[np.number])).any().any():\n",
    "    print(\"\\n‚ö†Ô∏è Warning: Infinite values detected, replacing with NaN...\")\n",
    "    df = df.replace([np.inf, -np.inf], np.nan).dropna()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "feature_cols = ['Stochastic_K', 'Stochastic_D', 'ROC', 'Williams_R',\n",
    "                'Momentum', 'Disparity_5', 'Disparity_14', 'OSCP',\n",
    "                'CCI', 'RSI', 'Pivot_Point', 'S1', 'S2', 'R1', 'R2']\n",
    "\n",
    "X = df[feature_cols].values\n",
    "y = df['Target'].values\n",
    "dates = df.index\n",
    "\n",
    "# Chronological split (80/20)\n",
    "train_size = int(len(X) * 0.8)\n",
    "X_train = X[:train_size]\n",
    "X_test = X[train_size:]\n",
    "y_train = y[:train_size]\n",
    "y_test = y[train_size:]\n",
    "dates_test = dates[train_size:]\n",
    "\n",
    "# Normalization (fit on train only)\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print(\"‚ïê\" * 70)\n",
    "print(\"üìä DATA PREPARED\")\n",
    "print(\"‚ïê\" * 70)\n",
    "print(f\"Train: {len(X_train)} samples | Up: {sum(y_train)} ({sum(y_train)/len(y_train)*100:.1f}%)\")\n",
    "print(f\"Test:  {len(X_test)} samples | Up: {sum(y_test)} ({sum(y_test)/len(y_test)*100:.1f}%)\")\n",
    "print(f\"Train period: {dates[:train_size][0]} to {dates[:train_size][-1]}\")\n",
    "print(f\"Test period:  {dates[train_size:][0]} to {dates[train_size:][-1]}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Helper function for detailed evaluation\n",
    "def evaluate_model(model, X_test, y_test, model_name):\n",
    "    \"\"\"Comprehensive model evaluation\"\"\"\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"{model_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Accuracy:  {acc:.4f} ({acc*100:.2f}%)\")\n",
    "    print(f\"Precision: {prec:.4f}\")\n",
    "    print(f\"Recall:    {rec:.4f}\")\n",
    "    print(f\"F1-Score:  {f1:.4f}\")\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(f\"\\nConfusion Matrix:\")\n",
    "    print(cm)\n",
    "    print(f\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=['Down', 'Up']))\n",
    "    \n",
    "    return {'accuracy': acc, 'precision': prec, 'recall': rec, 'f1': f1, 'predictions': y_pred}"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# SVM Models - Article's Exact Parameters\n",
    "print(\"\\n\" + \"‚ïê\" * 70)\n",
    "print(\"ü§ñ SVM MODELS (ARTICLE PARAMETERS)\")\n",
    "print(\"‚ïê\" * 70)\n",
    "\n",
    "results = {}\n",
    "\n",
    "# 1. LINEAR SVM\n",
    "print(\"\\n[1/3] Training Linear SVM (C=964.7736)...\")\n",
    "svm_linear = SVC(kernel='linear', C=964.7736, random_state=42)\n",
    "svm_linear.fit(X_train, y_train)\n",
    "results['Linear'] = evaluate_model(svm_linear, X_test, y_test, \"LINEAR SVM\")\n",
    "print(f\"Article reports: 85.19%\")\n",
    "\n",
    "# 2. RBF SVM\n",
    "print(\"\\n[2/3] Training RBF SVM (C=137.20, gamma=60.51)...\")\n",
    "svm_rbf = SVC(kernel='rbf', C=137.20, gamma=60.51, random_state=42)\n",
    "svm_rbf.fit(X_train, y_train)\n",
    "results['RBF'] = evaluate_model(svm_rbf, X_test, y_test, \"RBF SVM\")\n",
    "print(f\"Article reports: 76.88%\")\n",
    "\n",
    "# 3. POLYNOMIAL SVM\n",
    "print(\"\\n[3/3] Training Polynomial SVM (C=314.52, degree=2, coef0=0.5554)...\")\n",
    "svm_poly = SVC(kernel='poly', C=314.52, degree=2, coef0=0.5554, random_state=42)\n",
    "svm_poly.fit(X_train, y_train)\n",
    "results['Polynomial'] = evaluate_model(svm_poly, X_test, y_test, \"POLYNOMIAL SVM\")\n",
    "print(f\"Article reports: 84.38%\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Grid Search with Time Series Cross-Validation\n",
    "print(\"\\n\" + \"‚ïê\" * 70)\n",
    "print(\"üîç GRID SEARCH (TimeSeriesSplit)\")\n",
    "print(\"‚ïê\" * 70)\n",
    "\n",
    "# Use TimeSeriesSplit instead of KFold for time series\n",
    "tscv = TimeSeriesSplit(n_splits=4)\n",
    "results_grid = {}\n",
    "\n",
    "# 1. Linear SVM Grid Search\n",
    "print(\"\\n[1/3] Linear SVM Grid Search...\")\n",
    "param_grid_linear = {\n",
    "    'C': [0.1, 1, 10, 100, 500, 964.7736, 1000]\n",
    "}\n",
    "grid_linear = GridSearchCV(\n",
    "    SVC(kernel='linear', random_state=42),\n",
    "    param_grid_linear,\n",
    "    cv=tscv,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "grid_linear.fit(X_train, y_train)\n",
    "print(f\"Best params: {grid_linear.best_params_}\")\n",
    "print(f\"Best CV score: {grid_linear.best_score_:.4f}\")\n",
    "results_grid['Linear'] = evaluate_model(grid_linear, X_test, y_test, \"LINEAR SVM (Grid)\")\n",
    "\n",
    "# 2. RBF SVM Grid Search\n",
    "print(\"\\n[2/3] RBF SVM Grid Search...\")\n",
    "param_grid_rbf = {\n",
    "    'C': [1, 10, 100, 137.20, 200],\n",
    "    'gamma': [0.001, 0.01, 0.1, 1, 10, 60.51, 'scale']\n",
    "}\n",
    "grid_rbf = GridSearchCV(\n",
    "    SVC(kernel='rbf', random_state=42),\n",
    "    param_grid_rbf,\n",
    "    cv=tscv,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "grid_rbf.fit(X_train, y_train)\n",
    "print(f\"Best params: {grid_rbf.best_params_}\")\n",
    "print(f\"Best CV score: {grid_rbf.best_score_:.4f}\")\n",
    "results_grid['RBF'] = evaluate_model(grid_rbf, X_test, y_test, \"RBF SVM (Grid)\")\n",
    "\n",
    "# 3. Polynomial SVM Grid Search\n",
    "print(\"\\n[3/3] Polynomial SVM Grid Search...\")\n",
    "param_grid_poly = {\n",
    "    'C': [10, 100, 314.52, 500],\n",
    "    'degree': [2, 3],\n",
    "    'coef0': [0, 0.5554, 1.0]\n",
    "}\n",
    "grid_poly = GridSearchCV(\n",
    "    SVC(kernel='poly', random_state=42),\n",
    "    param_grid_poly,\n",
    "    cv=tscv,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "grid_poly.fit(X_train, y_train)\n",
    "print(f\"Best params: {grid_poly.best_params_}\")\n",
    "print(f\"Best CV score: {grid_poly.best_score_:.4f}\")\n",
    "results_grid['Polynomial'] = evaluate_model(grid_poly, X_test, y_test, \"POLYNOMIAL SVM (Grid)\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# FINAL COMPARISON\n",
    "article = {'Linear': 0.8519, 'RBF': 0.7688, 'Polynomial': 0.8438}\n",
    "\n",
    "print(\"\\n\" + \"‚ïê\" * 80)\n",
    "print(\"üìä FINAL RESULTS COMPARISON\")\n",
    "print(\"‚ïê\" * 80)\n",
    "print(f\"\\n{'Model':<15} {'Article':<12} {'Exact':<12} {'Grid':<12} {'Diff':<10}\")\n",
    "print(\"‚îÄ\" * 80)\n",
    "\n",
    "for m in ['Linear', 'RBF', 'Polynomial']:\n",
    "    art = article[m] * 100\n",
    "    exact = results[m]['accuracy'] * 100\n",
    "    grid = results_grid[m]['accuracy'] * 100\n",
    "    diff = exact - art\n",
    "    \n",
    "    print(f\"{m:<15} {art:>8.2f}%    {exact:>8.2f}%    {grid:>8.2f}%    {diff:>+7.2f}%\")\n",
    "\n",
    "avg_art = np.mean(list(article.values())) * 100\n",
    "avg_exact = np.mean([results[m]['accuracy'] for m in ['Linear', 'RBF', 'Polynomial']]) * 100\n",
    "avg_grid = np.mean([results_grid[m]['accuracy'] for m in ['Linear', 'RBF', 'Polynomial']]) * 100\n",
    "\n",
    "print(\"‚îÄ\" * 80)\n",
    "print(f\"{'AVERAGE':<15} {avg_art:>8.2f}%    {avg_exact:>8.2f}%    {avg_grid:>8.2f}%    {avg_exact-avg_art:>+7.2f}%\")\n",
    "print(\"\\n\" + \"‚ïê\" * 80)\n",
    "\n",
    "# Interpretation\n",
    "if abs(avg_exact - avg_art) <= 5:\n",
    "    print(\"‚úÖ EXCELLENT: Results closely match the article!\")\n",
    "elif abs(avg_exact - avg_art) <= 10:\n",
    "    print(\"‚úÖ GOOD: Results are reasonably close to the article.\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è MODERATE: Significant difference likely due to:\")\n",
    "    print(\"   - Different data source (Yahoo vs. article's source)\")\n",
    "    print(\"   - Data availability/quality issues\")\n",
    "    print(\"   - Different preprocessing steps\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# 1. Accuracy Comparison\n",
    "models = ['Linear', 'RBF', 'Polynomial']\n",
    "x = np.arange(len(models))\n",
    "width = 0.25\n",
    "\n",
    "art_vals = [article[m] for m in models]\n",
    "exact_vals = [results[m]['accuracy'] for m in models]\n",
    "grid_vals = [results_grid[m]['accuracy'] for m in models]\n",
    "\n",
    "axes[0, 0].bar(x - width, art_vals, width, label='Article', alpha=0.8, color='#2ecc71')\n",
    "axes[0, 0].bar(x, exact_vals, width, label='Exact Params', alpha=0.8, color='#3498db')\n",
    "axes[0, 0].bar(x + width, grid_vals, width, label='Grid Search', alpha=0.8, color='#e74c3c')\n",
    "axes[0, 0].set_ylabel('Accuracy', fontsize=12)\n",
    "axes[0, 0].set_title('Model Performance Comparison', fontweight='bold', fontsize=14)\n",
    "axes[0, 0].set_xticks(x)\n",
    "axes[0, 0].set_xticklabels(models)\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(axis='y', alpha=0.3)\n",
    "axes[0, 0].set_ylim([0.5, 1.0])\n",
    "\n",
    "# 2. F1-Score Comparison\n",
    "f1_exact = [results[m]['f1'] for m in models]\n",
    "f1_grid = [results_grid[m]['f1'] for m in models]\n",
    "\n",
    "axes[0, 1].bar(x - width/2, f1_exact, width, label='Exact Params', alpha=0.8, color='#3498db')\n",
    "axes[0, 1].bar(x + width/2, f1_grid, width, label='Grid Search', alpha=0.8, color='#e74c3c')\n",
    "axes[0, 1].set_ylabel('F1-Score', fontsize=12)\n",
    "axes[0, 1].set_title('F1-Score Comparison', fontweight='bold', fontsize=14)\n",
    "axes[0, 1].set_xticks(x)\n",
    "axes[0, 1].set_xticklabels(models)\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 3. Confusion Matrix (Best Model)\n",
    "best_model_name = max(results_grid, key=lambda k: results_grid[k]['accuracy'])\n",
    "y_pred_best = results_grid[best_model_name]['predictions']\n",
    "cm = confusion_matrix(y_test, y_pred_best)\n",
    "\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[1, 0],\n",
    "            xticklabels=['Down', 'Up'], yticklabels=['Down', 'Up'])\n",
    "axes[1, 0].set_title(f'Confusion Matrix - Best Model ({best_model_name})', fontweight='bold', fontsize=14)\n",
    "axes[1, 0].set_ylabel('True Label')\n",
    "axes[1, 0].set_xlabel('Predicted Label')\n",
    "\n",
    "# 4. Prediction vs Actual (Time Series)\n",
    "axes[1, 1].plot(dates_test, y_test, label='Actual', alpha=0.7, linewidth=2)\n",
    "axes[1, 1].plot(dates_test, y_pred_best, label='Predicted', alpha=0.7, linewidth=2)\n",
    "axes[1, 1].set_title(f'Predictions Over Time ({best_model_name})', fontweight='bold', fontsize=14)\n",
    "axes[1, 1].set_xlabel('Date')\n",
    "axes[1, 1].set_ylabel('Direction (0=Down, 1=Up)')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(alpha=0.3)\n",
    "axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/mnt/user-data/outputs/svm_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ Analysis complete! Visualization saved.\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Summary Report\n",
    "print(\"\\n\" + \"‚ïê\" * 80)\n",
    "print(\"üìù SUMMARY REPORT\")\n",
    "print(\"‚ïê\" * 80)\n",
    "\n",
    "print(f\"\\nüéØ Best Model: {best_model_name} SVM\")\n",
    "print(f\"   Accuracy:  {results_grid[best_model_name]['accuracy']:.4f}\")\n",
    "print(f\"   F1-Score:  {results_grid[best_model_name]['f1']:.4f}\")\n",
    "print(f\"   Precision: {results_grid[best_model_name]['precision']:.4f}\")\n",
    "print(f\"   Recall:    {results_grid[best_model_name]['recall']:.4f}\")\n",
    "\n",
    "print(f\"\\nüìä Data Information:\")\n",
    "print(f\"   Total samples: {len(df)}\")\n",
    "print(f\"   Train samples: {len(X_train)}\")\n",
    "print(f\"   Test samples:  {len(X_test)}\")\n",
    "print(f\"   Class balance: {sum(y_test)/len(y_test)*100:.1f}% Up\")\n",
    "\n",
    "print(f\"\\nüí° Key Findings:\")\n",
    "if avg_exact > avg_art:\n",
    "    print(f\"   ‚úÖ Our implementation performs {avg_exact-avg_art:.2f}% better than reported\")\n",
    "elif avg_exact > avg_art * 0.95:\n",
    "    print(f\"   ‚úÖ Results closely match the article (within 5%)\")\n",
    "else:\n",
    "    print(f\"   ‚ö†Ô∏è Performance gap: {avg_art-avg_exact:.2f}% lower than article\")\n",
    "    print(f\"   Likely reasons: Data source differences, market conditions\")\n",
    "\n",
    "print(\"\\n\" + \"‚ïê\" * 80)"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
