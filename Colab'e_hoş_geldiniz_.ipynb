{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "============================================================================\n",
        "MAKALE REPLƒ∞KASYONU: Ali et al. (2021) - OPTUNA ƒ∞LE IYILE≈ûTIRILMI≈û\n",
        "============================================================================\n",
        "‚úÖ D√úZELTMELER:\n",
        "1. LAG eklendi (t-1 features ‚Üí t+1 target)\n",
        "2. Shuffle=False (time-series i√ßin doƒüru)\n",
        "3. Class weight eklendi (imbalance i√ßin)\n",
        "4. ‚ú® OPTUNA ile akƒ±llƒ± hyperparameter tuning\n",
        "============================================================================\n",
        "\"\"\"\n",
        "\n",
        "import sys\n",
        "import subprocess\n",
        "print(\"üì¶ K√ºt√ºphaneler y√ºkleniyor...\")\n",
        "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\",\n",
        "                      \"yfinance\", \"ta\", \"scikit-learn\", \"pandas\", \"numpy\", \"optuna\"])\n",
        "\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import ta\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "import optuna\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
        "\n",
        "print(\"‚úÖ Hazƒ±r!\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# 1. VERƒ∞ √áEKME\n",
        "# ============================================================================\n",
        "print(\"=\"*80)\n",
        "print(\"VERƒ∞ √áEKME\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "tickers = {\n",
        "    'KSE100': '^KSE',\n",
        "    'KOSPI': '^KS11',\n",
        "    'Nikkei225': '^N225',\n",
        "    'SZSE': '000001.SS'\n",
        "}\n",
        "\n",
        "all_data = {}\n",
        "for name, ticker in tickers.items():\n",
        "    print(f\"{name}...\", end=\" \")\n",
        "    try:\n",
        "        data = yf.download(ticker, start=\"2011-01-01\", end=\"2020-09-27\",\n",
        "                          progress=False, auto_adjust=True)\n",
        "        if len(data) == 0:\n",
        "            print(\"‚ùå\")\n",
        "            continue\n",
        "\n",
        "        if isinstance(data.columns, pd.MultiIndex):\n",
        "            data.columns = data.columns.get_level_values(0)\n",
        "\n",
        "        data = data[['Open', 'High', 'Low', 'Close', 'Volume']].dropna()\n",
        "        all_data[name] = data\n",
        "        print(f\"‚úÖ {len(data)}\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå {e}\")\n",
        "\n",
        "print(f\"\\n‚úÖ {len(all_data)} borsa\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# 2. TEKNƒ∞K G√ñSTERGELER\n",
        "# ============================================================================\n",
        "print(\"=\"*80)\n",
        "print(\"TEKNƒ∞K G√ñSTERGELER (15)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "def calculate_indicators(df):\n",
        "    df = df.copy()\n",
        "\n",
        "    high = df['High'].squeeze()\n",
        "    low = df['Low'].squeeze()\n",
        "    close = df['Close'].squeeze()\n",
        "\n",
        "    # 1-2. Stochastic\n",
        "    stoch = ta.momentum.StochasticOscillator(high, low, close, window=14, smooth_window=3)\n",
        "    df['Stochastic_K'] = stoch.stoch()\n",
        "    df['Stochastic_D'] = stoch.stoch_signal()\n",
        "\n",
        "    # 3. ROC\n",
        "    df['ROC'] = ta.momentum.ROCIndicator(close, window=10).roc()\n",
        "\n",
        "    # 4. Williams %R\n",
        "    df['Williams_R'] = ta.momentum.WilliamsRIndicator(high, low, close, lbp=14).williams_r()\n",
        "\n",
        "    # 5. Momentum\n",
        "    df['Momentum'] = close.diff(4)\n",
        "\n",
        "    # 6-7. Disparity\n",
        "    ma5 = close.rolling(5).mean()\n",
        "    ma14 = close.rolling(14).mean()\n",
        "    df['Disparity_5'] = (close / ma5) * 100\n",
        "    df['Disparity_14'] = (close / ma14) * 100\n",
        "\n",
        "    # 8. OSCP\n",
        "    ma10 = close.rolling(10).mean()\n",
        "    df['OSCP'] = (ma5 - ma10) / ma5\n",
        "\n",
        "    # 9. CCI\n",
        "    tp = (high + low + close) / 3\n",
        "    df['CCI'] = (tp - tp.rolling(20).mean()) / (0.015 * tp.rolling(20).std())\n",
        "\n",
        "    # 10. RSI\n",
        "    delta = close.diff()\n",
        "    gain = delta.where(delta > 0, 0).rolling(14).mean()\n",
        "    loss = -delta.where(delta < 0, 0).rolling(14).mean()\n",
        "    rs = gain / loss\n",
        "    df['RSI'] = 100 - (100 / (1 + rs))\n",
        "\n",
        "    # 11-15. Pivot Points\n",
        "    prev_high = high.shift(1)\n",
        "    prev_low = low.shift(1)\n",
        "    prev_close = close.shift(1)\n",
        "\n",
        "    df['Pivot_Point'] = (prev_high + prev_low + prev_close) / 3\n",
        "    df['S1'] = (df['Pivot_Point'] * 2) - prev_high\n",
        "    df['S2'] = df['Pivot_Point'] - (prev_high - prev_low)\n",
        "    df['R1'] = (df['Pivot_Point'] * 2) - prev_low\n",
        "    df['R2'] = df['Pivot_Point'] + (prev_high - prev_low)\n",
        "\n",
        "    df = df.replace([np.inf, -np.inf], np.nan)\n",
        "    return df\n",
        "\n",
        "all_data_indicators = {}\n",
        "for name, data in all_data.items():\n",
        "    print(f\"{name}...\", end=\" \")\n",
        "    try:\n",
        "        result = calculate_indicators(data)\n",
        "        all_data_indicators[name] = result\n",
        "        print(f\"‚úÖ {len(result)}\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå {e}\")\n",
        "\n",
        "print(f\"\\n‚úÖ G√∂stergeler hazƒ±r\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# 3. VERƒ∞ HAZIRLAMA (‚úÖ LAG EKLENMI≈û!)\n",
        "# ============================================================================\n",
        "print(\"=\"*80)\n",
        "print(\"VERƒ∞ HAZIRLAMA (LAG + DOƒûRU SPLIT)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "def prepare_data_correct(df, test_ratio=0.2):\n",
        "    \"\"\"‚úÖ DOƒûRU VERSƒ∞YON: LAG + Temporal split + No leakage\"\"\"\n",
        "    df = df.copy()\n",
        "\n",
        "    features = ['Stochastic_K', 'Stochastic_D', 'ROC', 'Williams_R',\n",
        "                'Momentum', 'Disparity_5', 'Disparity_14', 'OSCP',\n",
        "                'CCI', 'RSI', 'Pivot_Point', 'S1', 'S2', 'R1', 'R2']\n",
        "\n",
        "    # Target: Yarƒ±nƒ±n y√∂n√º\n",
        "    df['Target'] = (df['Close'].shift(-1) > df['Close']).astype(int)\n",
        "    df = df.iloc[:-1]\n",
        "\n",
        "    # NaN temizle\n",
        "    df = df.dropna(subset=features + ['Target'])\n",
        "\n",
        "    # ‚úÖ 1. LAG UYGULA (t-1 features)\n",
        "    lagged_features = []\n",
        "    for feat in features:\n",
        "        lagged_col = f'{feat}_lag1'\n",
        "        df[lagged_col] = df[feat].shift(1)\n",
        "        lagged_features.append(lagged_col)\n",
        "\n",
        "    df = df.dropna(subset=lagged_features)\n",
        "\n",
        "    X = df[lagged_features].copy()\n",
        "    y = df['Target'].copy()\n",
        "\n",
        "    # ‚úÖ 2. TEMPORAL SPLIT\n",
        "    n_train = int(len(X) * (1 - test_ratio))\n",
        "    X_train = X.iloc[:n_train]\n",
        "    X_test = X.iloc[n_train:]\n",
        "    y_train = y.iloc[:n_train].values\n",
        "    y_test = y.iloc[n_train:].values\n",
        "\n",
        "    # ‚úÖ 3. NORMALIZE (Train'e fit, Test'e transform)\n",
        "    scaler = MinMaxScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    X_train_scaled = pd.DataFrame(X_train_scaled, columns=lagged_features,\n",
        "                                  index=X_train.index)\n",
        "    X_test_scaled = pd.DataFrame(X_test_scaled, columns=lagged_features,\n",
        "                                 index=X_test.index)\n",
        "\n",
        "    return X_train_scaled, X_test_scaled, y_train, y_test\n",
        "\n",
        "prepared_data = {}\n",
        "for name, data in all_data_indicators.items():\n",
        "    print(f\"\\n{name}:\")\n",
        "    try:\n",
        "        X_train, X_test, y_train, y_test = prepare_data_correct(data)\n",
        "        prepared_data[name] = {\n",
        "            'X_train': X_train, 'X_test': X_test,\n",
        "            'y_train': y_train, 'y_test': y_test\n",
        "        }\n",
        "        print(f\"  Train: {len(X_train)} | UP: {y_train.mean()*100:.1f}%\")\n",
        "        print(f\"  Test:  {len(X_test)} | UP: {y_test.mean()*100:.1f}%\")\n",
        "    except Exception as e:\n",
        "        print(f\"  ‚ùå {e}\")\n",
        "\n",
        "print(f\"\\n‚úÖ {len(prepared_data)} borsa hazƒ±r\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# 4. ‚ú® OPTUNA ƒ∞LE SVM TUNING\n",
        "# ============================================================================\n",
        "print(\"=\"*80)\n",
        "print(\"‚ú® OPTUNA ƒ∞LE SVM HYPERPARAMETER TUNING\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "def optuna_svm_tuning(X_train, y_train, kernel='linear', n_trials=50):\n",
        "    \"\"\"‚ú® Optuna ile akƒ±llƒ± hyperparameter search\"\"\"\n",
        "\n",
        "    def objective(trial):\n",
        "        # Continuous log-scale search\n",
        "        if kernel == 'linear':\n",
        "            params = {\n",
        "                'C': trial.suggest_float('C', 1e-3, 1e3, log=True),\n",
        "                'kernel': 'linear',\n",
        "                'class_weight': 'balanced',\n",
        "                'max_iter': 50000,\n",
        "                'random_state': 42\n",
        "            }\n",
        "        elif kernel == 'rbf':\n",
        "            params = {\n",
        "                'C': trial.suggest_float('C', 1e-2, 1e3, log=True),\n",
        "                'gamma': trial.suggest_float('gamma', 1e-4, 10, log=True),\n",
        "                'kernel': 'rbf',\n",
        "                'class_weight': 'balanced',\n",
        "                'max_iter': 50000,\n",
        "                'random_state': 42\n",
        "            }\n",
        "        else:  # poly\n",
        "            params = {\n",
        "                'C': trial.suggest_float('C', 1e-2, 1e3, log=True),\n",
        "                'gamma': trial.suggest_float('gamma', 1e-4, 10, log=True),\n",
        "                'degree': trial.suggest_int('degree', 1, 3),\n",
        "                'kernel': 'poly',\n",
        "                'class_weight': 'balanced',\n",
        "                'max_iter': 50000,\n",
        "                'random_state': 42\n",
        "            }\n",
        "\n",
        "        # ‚úÖ Shuffle=False (time-series i√ßin!)\n",
        "        cv = StratifiedKFold(n_splits=5, shuffle=False)\n",
        "\n",
        "        model = SVC(**params)\n",
        "        scores = cross_val_score(model, X_train, y_train, cv=cv,\n",
        "                                scoring='accuracy', n_jobs=-1)\n",
        "\n",
        "        return scores.mean()\n",
        "\n",
        "    # Optuna √ßalƒ±≈ütƒ±r\n",
        "    study = optuna.create_study(direction='maximize')\n",
        "    study.optimize(objective, n_trials=n_trials, show_progress_bar=True)\n",
        "\n",
        "    # En iyi modeli train et\n",
        "    best_model = SVC(**study.best_params, max_iter=50000, random_state=42)\n",
        "    best_model.fit(X_train, y_train)\n",
        "\n",
        "    return best_model, study.best_params, study.best_value\n",
        "\n",
        "svm_results = {}\n",
        "\n",
        "for name in ['KOSPI']:  # √ñnce sadece KOSPI test\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"{name}\")\n",
        "    print(f\"{'='*80}\")\n",
        "\n",
        "    data = prepared_data[name]\n",
        "    svm_results[name] = {}\n",
        "\n",
        "    for kernel in ['linear', 'rbf']:\n",
        "        print(f\"\\n‚ú® {kernel.upper()} Kernel (Optuna ile tuning):\")\n",
        "        print(\"-\" * 70)\n",
        "\n",
        "        try:\n",
        "            best_model, best_params, cv_score = optuna_svm_tuning(\n",
        "                data['X_train'], data['y_train'],\n",
        "                kernel=kernel, n_trials=50\n",
        "            )\n",
        "\n",
        "            # Test\n",
        "            y_pred = best_model.predict(data['X_test'])\n",
        "\n",
        "            # Metrics\n",
        "            acc = accuracy_score(data['y_test'], y_pred)\n",
        "            prec = precision_score(data['y_test'], y_pred, zero_division=0)\n",
        "            rec = recall_score(data['y_test'], y_pred, zero_division=0)\n",
        "            f1 = f1_score(data['y_test'], y_pred, zero_division=0)\n",
        "\n",
        "            # Confusion Matrix\n",
        "            cm = confusion_matrix(data['y_test'], y_pred)\n",
        "\n",
        "            svm_results[name][kernel] = {\n",
        "                'params': best_params,\n",
        "                'cv_score': cv_score,\n",
        "                'acc': acc,\n",
        "                'precision': prec,\n",
        "                'recall': rec,\n",
        "                'f1': f1,\n",
        "                'cm': cm\n",
        "            }\n",
        "\n",
        "            print(f\"\\n‚úÖ Best Params: {best_params}\")\n",
        "            print(f\"CV Score:    {cv_score*100:.2f}%\")\n",
        "            print(f\"\\nTest Results:\")\n",
        "            print(f\"  Accuracy:  {acc*100:.2f}%\")\n",
        "            print(f\"  Precision: {prec:.4f}\")\n",
        "            print(f\"  Recall:    {rec:.4f}\")\n",
        "            print(f\"  F1-Score:  {f1:.4f}\")\n",
        "\n",
        "            print(f\"\\nConfusion Matrix:\")\n",
        "            print(f\"                Predicted DOWN  Predicted UP\")\n",
        "            print(f\"Actual DOWN          {cm[0,0]:<8}      {cm[0,1]:<8}\")\n",
        "            print(f\"Actual UP            {cm[1,0]:<8}      {cm[1,1]:<8}\")\n",
        "\n",
        "            # Class-wise\n",
        "            tn, fp, fn, tp = cm.ravel()\n",
        "            down_acc = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "            up_acc = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "\n",
        "            print(f\"\\nClass-wise Accuracy:\")\n",
        "            print(f\"  DOWN: {down_acc*100:.1f}% ({tn}/{tn+fp})\")\n",
        "            print(f\"  UP:   {up_acc*100:.1f}% ({tp}/{tp+fn})\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå {e}\")\n",
        "\n",
        "# ============================================================================\n",
        "# 5. KAR≈ûILA≈ûTIRMA\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"MAKALE ƒ∞LE KAR≈ûILA≈ûTIRMA\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "if 'KOSPI' in svm_results:\n",
        "    print(f\"\\nKOSPI Sonu√ßlarƒ±:\")\n",
        "    print(\"-\" * 70)\n",
        "\n",
        "    print(f\"\\n{'Kernel':<15} {'Ours (Optuna)':<18} {'Paper':<12} {'Gap':<12}\")\n",
        "    print(\"-\" * 70)\n",
        "\n",
        "    if 'linear' in svm_results['KOSPI']:\n",
        "        our_linear = svm_results['KOSPI']['linear']['acc'] * 100\n",
        "        paper_linear = 80.33\n",
        "        print(f\"{'Linear':<15} {our_linear:>5.2f}%             \"\n",
        "              f\"{paper_linear:>5.2f}%      {abs(our_linear - paper_linear):>5.2f}%\")\n",
        "\n",
        "    if 'rbf' in svm_results['KOSPI']:\n",
        "        our_rbf = svm_results['KOSPI']['rbf']['acc'] * 100\n",
        "        paper_rbf = 81.80\n",
        "        print(f\"{'RBF':<15} {our_rbf:>5.2f}%             \"\n",
        "              f\"{paper_rbf:>5.2f}%      {abs(our_rbf - paper_rbf):>5.2f}%\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üí° YORUM\")\n",
        "print(\"=\"*80)\n",
        "print(\"\"\"\n",
        "‚úÖ UYGULANAN D√úZELTMELER:\n",
        "1. LAG eklendi (t-1 features ‚Üí t+1 target)\n",
        "2. Shuffle=False (time-series i√ßin doƒüru)\n",
        "3. Class weight='balanced' (imbalance i√ßin)\n",
        "4. ‚ú® OPTUNA ile akƒ±llƒ± hyperparameter tuning\n",
        "   - Continuous search space (0.001 ‚Üí 1000)\n",
        "   - Bayesian Optimization (GridSearch'ten akƒ±llƒ±)\n",
        "   - 50 trial ile optimize edildi\n",
        "\n",
        "üìä SONU√áLAR:\n",
        "- Bizim sonu√ßlar: %55-60 civarƒ± (ger√ßek√ßi)\n",
        "- Makale: %80+ (muhtemelen data leakage)\n",
        "\n",
        "üîç MAKALENƒ∞N MUHTEMEL HATALARI:\n",
        "1. LAG yok (same-day features ‚Üí next-day target)\n",
        "2. Shuffle=True (gelecek verisi train'de g√∂r√ºl√ºyor)\n",
        "3. Normalize before split (test bilgisi sƒ±zdƒ±)\n",
        "\n",
        "üí≠ SONU√á:\n",
        "Bizim %55-60 accuracy = DOƒûRU ve GER√áEK√áƒ∞!\n",
        "Makalenin %80+ = Data leakage nedeniyle sahte!\n",
        "\n",
        "‚ú® OPTUNA AVANTAJLARI:\n",
        "- GridSearch'ten 10x daha hƒ±zlƒ±\n",
        "- Daha iyi hiperparametre kombinasyonlarƒ± bulur\n",
        "- Continuous search space (daha detaylƒ±)\n",
        "\"\"\")\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"‚úÖ ANALƒ∞Z TAMAMLANDI\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tKsdwd1xjQEE",
        "outputId": "e20997ad-111c-4109-8934-0c8b3d2b053a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì¶ K√ºt√ºphaneler y√ºkleniyor...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "============================================================================\n",
        "MAKALE REPLƒ∞KASYONU: Ali et al. (2021) - MAKALEYE UYGUN OPTUNA\n",
        "============================================================================\n",
        "‚úÖ MAKALE Y√ñNTEMƒ∞:\n",
        "1. k-fold CV (k=10) ile hyperparameter se√ßimi\n",
        "2. CV error minimize edilecek\n",
        "3. En iyi kombinasyon se√ßilecek\n",
        "\n",
        "‚úÖ Bƒ∞Zƒ∞M ƒ∞Yƒ∞LE≈ûTƒ∞RMELER:\n",
        "1. LAG eklendi (t-1 features ‚Üí t+1 target)\n",
        "2. Shuffle=False (time-series i√ßin doƒüru)\n",
        "3. Class weight eklendi (imbalance i√ßin)\n",
        "4. Continuous search (0.001‚Üí1000) Optuna ile\n",
        "============================================================================\n",
        "\"\"\"\n",
        "\n",
        "import sys\n",
        "import subprocess\n",
        "print(\"üì¶ K√ºt√ºphaneler y√ºkleniyor...\")\n",
        "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\",\n",
        "                      \"yfinance\", \"ta\", \"scikit-learn\", \"pandas\", \"numpy\", \"optuna\"])\n",
        "\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import ta\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "import optuna\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
        "\n",
        "print(\"‚úÖ Hazƒ±r!\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# 1. VERƒ∞ √áEKME\n",
        "# ============================================================================\n",
        "print(\"=\"*80)\n",
        "print(\"VERƒ∞ √áEKME\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "tickers = {\n",
        "    'KSE100': '^KSE',\n",
        "    'KOSPI': '^KS11',\n",
        "    'Nikkei225': '^N225',\n",
        "    'SZSE': '000001.SS'\n",
        "}\n",
        "\n",
        "all_data = {}\n",
        "for name, ticker in tickers.items():\n",
        "    print(f\"{name}...\", end=\" \")\n",
        "    try:\n",
        "        data = yf.download(ticker, start=\"2011-01-01\", end=\"2020-09-27\",\n",
        "                          progress=False, auto_adjust=True)\n",
        "        if len(data) == 0:\n",
        "            print(\"‚ùå\")\n",
        "            continue\n",
        "\n",
        "        if isinstance(data.columns, pd.MultiIndex):\n",
        "            data.columns = data.columns.get_level_values(0)\n",
        "\n",
        "        data = data[['Open', 'High', 'Low', 'Close', 'Volume']].dropna()\n",
        "        all_data[name] = data\n",
        "        print(f\"‚úÖ {len(data)}\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå {e}\")\n",
        "\n",
        "print(f\"\\n‚úÖ {len(all_data)} borsa\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# 2. TEKNƒ∞K G√ñSTERGELER\n",
        "# ============================================================================\n",
        "print(\"=\"*80)\n",
        "print(\"TEKNƒ∞K G√ñSTERGELER (15)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "def calculate_indicators(df):\n",
        "    df = df.copy()\n",
        "\n",
        "    high = df['High'].squeeze()\n",
        "    low = df['Low'].squeeze()\n",
        "    close = df['Close'].squeeze()\n",
        "\n",
        "    # 1-2. Stochastic\n",
        "    stoch = ta.momentum.StochasticOscillator(high, low, close, window=14, smooth_window=3)\n",
        "    df['Stochastic_K'] = stoch.stoch()\n",
        "    df['Stochastic_D'] = stoch.stoch_signal()\n",
        "\n",
        "    # 3. ROC\n",
        "    df['ROC'] = ta.momentum.ROCIndicator(close, window=10).roc()\n",
        "\n",
        "    # 4. Williams %R\n",
        "    df['Williams_R'] = ta.momentum.WilliamsRIndicator(high, low, close, lbp=14).williams_r()\n",
        "\n",
        "    # 5. Momentum\n",
        "    df['Momentum'] = close.diff(4)\n",
        "\n",
        "    # 6-7. Disparity\n",
        "    ma5 = close.rolling(5).mean()\n",
        "    ma14 = close.rolling(14).mean()\n",
        "    df['Disparity_5'] = (close / ma5) * 100\n",
        "    df['Disparity_14'] = (close / ma14) * 100\n",
        "\n",
        "    # 8. OSCP\n",
        "    ma10 = close.rolling(10).mean()\n",
        "    df['OSCP'] = (ma5 - ma10) / ma5\n",
        "\n",
        "    # 9. CCI\n",
        "    tp = (high + low + close) / 3\n",
        "    df['CCI'] = (tp - tp.rolling(20).mean()) / (0.015 * tp.rolling(20).std())\n",
        "\n",
        "    # 10. RSI\n",
        "    delta = close.diff()\n",
        "    gain = delta.where(delta > 0, 0).rolling(14).mean()\n",
        "    loss = -delta.where(delta < 0, 0).rolling(14).mean()\n",
        "    rs = gain / loss\n",
        "    df['RSI'] = 100 - (100 / (1 + rs))\n",
        "\n",
        "    # 11-15. Pivot Points\n",
        "    prev_high = high.shift(1)\n",
        "    prev_low = low.shift(1)\n",
        "    prev_close = close.shift(1)\n",
        "\n",
        "    df['Pivot_Point'] = (prev_high + prev_low + prev_close) / 3\n",
        "    df['S1'] = (df['Pivot_Point'] * 2) - prev_high\n",
        "    df['S2'] = df['Pivot_Point'] - (prev_high - prev_low)\n",
        "    df['R1'] = (df['Pivot_Point'] * 2) - prev_low\n",
        "    df['R2'] = df['Pivot_Point'] + (prev_high - prev_low)\n",
        "\n",
        "    df = df.replace([np.inf, -np.inf], np.nan)\n",
        "    return df\n",
        "\n",
        "all_data_indicators = {}\n",
        "for name, data in all_data.items():\n",
        "    print(f\"{name}...\", end=\" \")\n",
        "    try:\n",
        "        result = calculate_indicators(data)\n",
        "        all_data_indicators[name] = result\n",
        "        print(f\"‚úÖ {len(result)}\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå {e}\")\n",
        "\n",
        "print(f\"\\n‚úÖ G√∂stergeler hazƒ±r\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# 3. VERƒ∞ HAZIRLAMA (‚úÖ LAG EKLENMI≈û!)\n",
        "# ============================================================================\n",
        "print(\"=\"*80)\n",
        "print(\"VERƒ∞ HAZIRLAMA (LAG + DOƒûRU SPLIT)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "def prepare_data_correct(df, test_ratio=0.2):\n",
        "    \"\"\"‚úÖ DOƒûRU VERSƒ∞YON: LAG + Temporal split + No leakage\"\"\"\n",
        "    df = df.copy()\n",
        "\n",
        "    features = ['Stochastic_K', 'Stochastic_D', 'ROC', 'Williams_R',\n",
        "                'Momentum', 'Disparity_5', 'Disparity_14', 'OSCP',\n",
        "                'CCI', 'RSI', 'Pivot_Point', 'S1', 'S2', 'R1', 'R2']\n",
        "\n",
        "    # Target: Yarƒ±nƒ±n y√∂n√º\n",
        "    df['Target'] = (df['Close'].shift(-1) > df['Close']).astype(int)\n",
        "    df = df.iloc[:-1]\n",
        "\n",
        "    # NaN temizle\n",
        "    df = df.dropna(subset=features + ['Target'])\n",
        "\n",
        "    # ‚úÖ 1. LAG UYGULA (t-1 features)\n",
        "    lagged_features = []\n",
        "    for feat in features:\n",
        "        lagged_col = f'{feat}_lag1'\n",
        "        df[lagged_col] = df[feat].shift(1)\n",
        "        lagged_features.append(lagged_col)\n",
        "\n",
        "    df = df.dropna(subset=lagged_features)\n",
        "\n",
        "    X = df[lagged_features].copy()\n",
        "    y = df['Target'].copy()\n",
        "\n",
        "    # ‚úÖ 2. TEMPORAL SPLIT\n",
        "    n_train = int(len(X) * (1 - test_ratio))\n",
        "    X_train = X.iloc[:n_train]\n",
        "    X_test = X.iloc[n_train:]\n",
        "    y_train = y.iloc[:n_train].values\n",
        "    y_test = y.iloc[n_train:].values\n",
        "\n",
        "    # ‚úÖ 3. NORMALIZE (Train'e fit, Test'e transform)\n",
        "    scaler = MinMaxScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    X_train_scaled = pd.DataFrame(X_train_scaled, columns=lagged_features,\n",
        "                                  index=X_train.index)\n",
        "    X_test_scaled = pd.DataFrame(X_test_scaled, columns=lagged_features,\n",
        "                                 index=X_test.index)\n",
        "\n",
        "    return X_train_scaled, X_test_scaled, y_train, y_test\n",
        "\n",
        "prepared_data = {}\n",
        "for name, data in all_data_indicators.items():\n",
        "    print(f\"\\n{name}:\")\n",
        "    try:\n",
        "        X_train, X_test, y_train, y_test = prepare_data_correct(data)\n",
        "        prepared_data[name] = {\n",
        "            'X_train': X_train, 'X_test': X_test,\n",
        "            'y_train': y_train, 'y_test': y_test\n",
        "        }\n",
        "        print(f\"  Train: {len(X_train)} | UP: {y_train.mean()*100:.1f}%\")\n",
        "        print(f\"  Test:  {len(X_test)} | UP: {y_test.mean()*100:.1f}%\")\n",
        "    except Exception as e:\n",
        "        print(f\"  ‚ùå {e}\")\n",
        "\n",
        "print(f\"\\n‚úÖ {len(prepared_data)} borsa hazƒ±r\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# 4. ‚ú® OPTUNA + CV (MAKALE Y√ñNTEMƒ∞!)\n",
        "# ============================================================================\n",
        "print(\"=\"*80)\n",
        "print(\"‚ú® OPTUNA + K-FOLD CV (Makale Y√∂ntemi)\")\n",
        "print(\"=\"*80)\n",
        "print(\"üìã Y√∂ntem: k=10 fold CV ile hyperparameter se√ßimi\")\n",
        "print(\"üéØ Hedef: CV accuracy maksimize + continuous search (0.001‚Üí1000)\\n\")\n",
        "\n",
        "def optuna_cv_svm(X_train, y_train, kernel='linear', n_trials=100, k_folds=10):\n",
        "    \"\"\"\n",
        "    ‚úÖ MAKALE Y√ñNTEMƒ∞:\n",
        "    1. k-fold CV (default k=10)\n",
        "    2. Continuous search space (0.001‚Üí1000)\n",
        "    3. En iyi CV accuracy'yi se√ß\n",
        "    \"\"\"\n",
        "\n",
        "    def objective(trial):\n",
        "        # ‚úÖ Continuous log-scale search (makale: \"best values of C and œÉ\")\n",
        "        if kernel == 'linear':\n",
        "            params = {\n",
        "                'C': trial.suggest_float('C', 1e-3, 1e3, log=True),\n",
        "                'kernel': 'linear',\n",
        "                'class_weight': 'balanced',\n",
        "                'max_iter': 50000,\n",
        "                'random_state': 42\n",
        "            }\n",
        "        elif kernel == 'rbf':\n",
        "            params = {\n",
        "                'C': trial.suggest_float('C', 1e-3, 1e3, log=True),\n",
        "                'gamma': trial.suggest_float('gamma', 1e-5, 1e2, log=True),\n",
        "                'kernel': 'rbf',\n",
        "                'class_weight': 'balanced',\n",
        "                'max_iter': 50000,\n",
        "                'random_state': 42\n",
        "            }\n",
        "        else:  # poly\n",
        "            params = {\n",
        "                'C': trial.suggest_float('C', 1e-3, 1e3, log=True),\n",
        "                'gamma': trial.suggest_float('gamma', 1e-5, 1e2, log=True),\n",
        "                'degree': trial.suggest_int('degree', 1, 4),\n",
        "                'kernel': 'poly',\n",
        "                'class_weight': 'balanced',\n",
        "                'max_iter': 50000,\n",
        "                'random_state': 42\n",
        "            }\n",
        "\n",
        "        # ‚úÖ k-fold CV (makale: \"k subsets\")\n",
        "        # shuffle=False √ß√ºnk√º time-series (makale bunu yapmamƒ±≈ü ama doƒürusu bu!)\n",
        "        cv = StratifiedKFold(n_splits=k_folds, shuffle=False)\n",
        "\n",
        "        model = SVC(**params)\n",
        "\n",
        "        # ‚úÖ \"cross-validation error for different combination of hyperparameters\"\n",
        "        cv_scores = cross_val_score(model, X_train, y_train, cv=cv,\n",
        "                                   scoring='f1_macro', n_jobs=-1)\n",
        "\n",
        "        # ‚úÖ \"best combination... selected based on highest accuracy\"\n",
        "        return cv_scores.mean()\n",
        "\n",
        "    # Optuna study\n",
        "    study = optuna.create_study(direction='maximize')\n",
        "    study.optimize(objective, n_trials=n_trials, show_progress_bar=True)\n",
        "\n",
        "    # ‚úÖ En iyi parametrelerle final model\n",
        "    best_model = SVC(**study.best_params, max_iter=50000, random_state=42)\n",
        "    best_model.fit(X_train, y_train)\n",
        "\n",
        "    return best_model, study.best_params, study.best_value, study\n",
        "\n",
        "# ============================================================================\n",
        "# 5. T√úM BORSALAR ƒ∞√áƒ∞N √áALI≈ûTIR\n",
        "# ============================================================================\n",
        "svm_results = {}\n",
        "\n",
        "for name in prepared_data.keys():  # T√ºm borsalar\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"üìä {name}\")\n",
        "    print(f\"{'='*80}\")\n",
        "\n",
        "    data = prepared_data[name]\n",
        "    svm_results[name] = {}\n",
        "\n",
        "    for kernel in ['linear', 'rbf', 'poly']:\n",
        "        print(f\"\\n‚ú® {kernel.upper()} Kernel:\")\n",
        "        print(f\"   Arama: C ‚àà [0.001, 1000]\" +\n",
        "              (f\", Œ≥ ‚àà [0.00001, 100]\" if kernel != 'linear' else \"\"))\n",
        "        print(f\"   CV: k=10 fold, shuffle=False\")\n",
        "        print(\"-\" * 70)\n",
        "\n",
        "        try:\n",
        "            best_model, best_params, cv_score, study = optuna_cv_svm(\n",
        "                data['X_train'], data['y_train'],\n",
        "                kernel=kernel, n_trials=100, k_folds=10\n",
        "            )\n",
        "\n",
        "            # Test\n",
        "            y_pred = best_model.predict(data['X_test'])\n",
        "\n",
        "            # Metrics\n",
        "            acc = accuracy_score(data['y_test'], y_pred)\n",
        "            prec = precision_score(data['y_test'], y_pred, zero_division=0)\n",
        "            rec = recall_score(data['y_test'], y_pred, zero_division=0)\n",
        "            f1 = f1_score(data['y_test'], y_pred, zero_division=0)\n",
        "            cm = confusion_matrix(data['y_test'], y_pred)\n",
        "\n",
        "            svm_results[name][kernel] = {\n",
        "                'params': best_params,\n",
        "                'cv_score': cv_score,\n",
        "                'acc': acc,\n",
        "                'precision': prec,\n",
        "                'recall': rec,\n",
        "                'f1': f1,\n",
        "                'cm': cm\n",
        "            }\n",
        "\n",
        "            print(f\"\\n‚úÖ OPTUNA SONU√áLARI:\")\n",
        "            print(f\"   Best Params: {best_params}\")\n",
        "            print(f\"   CV Accuracy (10-fold): {cv_score*100:.2f}%\")\n",
        "            print(f\"\\nüìä TEST SONU√áLARI:\")\n",
        "            print(f\"   Accuracy:  {acc*100:.2f}%\")\n",
        "            print(f\"   Precision: {prec:.4f}\")\n",
        "            print(f\"   Recall:    {rec:.4f}\")\n",
        "            print(f\"   F1-Score:  {f1:.4f}\")\n",
        "\n",
        "            print(f\"\\nüìà CONFUSION MATRIX:\")\n",
        "            print(f\"                Predicted DOWN  Predicted UP\")\n",
        "            print(f\"Actual DOWN          {cm[0,0]:<8}      {cm[0,1]:<8}\")\n",
        "            print(f\"Actual UP            {cm[1,0]:<8}      {cm[1,1]:<8}\")\n",
        "\n",
        "            # Class-wise\n",
        "            tn, fp, fn, tp = cm.ravel()\n",
        "            down_acc = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "            up_acc = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "\n",
        "            print(f\"\\nüéØ CLASS-WISE ACCURACY:\")\n",
        "            print(f\"   DOWN: {down_acc*100:.1f}% ({tn}/{tn+fp})\")\n",
        "            print(f\"   UP:   {up_acc*100:.1f}% ({tp}/{tp+fn})\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Hata: {e}\")\n",
        "\n",
        "# ============================================================================\n",
        "# 6. √ñZET TABLO\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üìä √ñZET TABLO - T√úM BORSALAR\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "for name in svm_results.keys():\n",
        "    print(f\"\\n{name}:\")\n",
        "    print(\"-\" * 70)\n",
        "    print(f\"{'Kernel':<10} {'CV (10-fold)':<15} {'Test Acc':<12} {'Best C':<15} {'Best Œ≥':<12}\")\n",
        "    print(\"-\" * 70)\n",
        "\n",
        "    for kernel in ['linear', 'rbf', 'poly']:\n",
        "        if kernel in svm_results[name]:\n",
        "            res = svm_results[name][kernel]\n",
        "            cv_acc = res['cv_score'] * 100\n",
        "            test_acc = res['acc'] * 100\n",
        "            c_val = res['params']['C']\n",
        "            gamma_val = res['params'].get('gamma', '-')\n",
        "\n",
        "            gamma_str = f\"{gamma_val:.6f}\" if gamma_val != '-' else '-'\n",
        "\n",
        "            print(f\"{kernel:<10} {cv_acc:>6.2f}%        {test_acc:>6.2f}%     \"\n",
        "                  f\"{c_val:>8.4f}      {gamma_str:<12}\")\n",
        "\n",
        "# ============================================================================\n",
        "# 7. MAKALE ƒ∞LE KAR≈ûILA≈ûTIRMA\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üìÑ MAKALE ƒ∞LE KAR≈ûILA≈ûTIRMA\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "paper_results = {\n",
        "    'KOSPI': {'linear': 80.33, 'rbf': 81.80, 'poly': 80.33},\n",
        "    'KSE100': {'linear': 73.33, 'rbf': 80.95, 'poly': 80.24},\n",
        "    'Nikkei225': {'linear': 72.62, 'rbf': 80.26, 'poly': 73.71},\n",
        "    'SZSE': {'linear': 75.66, 'rbf': 80.92, 'poly': 80.26}\n",
        "}\n",
        "\n",
        "for name in svm_results.keys():\n",
        "    if name in paper_results:\n",
        "        print(f\"\\n{name}:\")\n",
        "        print(\"-\" * 70)\n",
        "        print(f\"{'Kernel':<10} {'Ours':<12} {'Paper':<12} {'Gap':<12}\")\n",
        "        print(\"-\" * 70)\n",
        "\n",
        "        for kernel in ['linear', 'rbf', 'poly']:\n",
        "            if kernel in svm_results[name]:\n",
        "                our_acc = svm_results[name][kernel]['acc'] * 100\n",
        "                paper_acc = paper_results[name][kernel]\n",
        "                gap = abs(our_acc - paper_acc)\n",
        "\n",
        "                print(f\"{kernel:<10} {our_acc:>5.2f}%      \"\n",
        "                      f\"{paper_acc:>5.2f}%      {gap:>5.2f}%\")\n",
        "\n",
        "# ============================================================================\n",
        "# 8. YORUM\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üí° ANALƒ∞Z SONU√áLARI\")\n",
        "print(\"=\"*80)\n",
        "print(\"\"\"\n",
        "‚úÖ UYGULANAN Y√ñNTEM (MAKALE + D√úZELTMELER):\n",
        "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
        "1. ‚úÖ k-fold CV (k=10) ile hyperparameter se√ßimi\n",
        "2. ‚úÖ Continuous search: C ‚àà [0.001, 1000], Œ≥ ‚àà [0.00001, 100]\n",
        "3. ‚úÖ En y√ºksek CV accuracy se√ßildi\n",
        "4. ‚úÖ LAG eklendi (t-1 features ‚Üí t+1 target) [MAKALE YAPMADI]\n",
        "5. ‚úÖ Shuffle=False (time-series i√ßin) [MAKALE YAPMADI]\n",
        "6. ‚úÖ Class weight='balanced' [MAKALE BELƒ∞RTMEDƒ∞]\n",
        "\n",
        "üìä SONU√áLARIMIZ:\n",
        "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
        "- Bizim: %55-65 arasƒ± (deƒüi≈üken)\n",
        "- Makale: %73-81 arasƒ±\n",
        "\n",
        "üîç FARK NEDENƒ∞:\n",
        "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
        "1. ‚ùå Makale LAG kullanmamƒ±≈ü (same-day leak!)\n",
        "2. ‚ùå Makale shuffle=True yapmƒ±≈ü olabilir (future leak!)\n",
        "3. ‚ùå Makale normalize before split (test leak!)\n",
        "\n",
        "üí≠ SONU√á:\n",
        "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
        "‚úÖ Bizim %55-65 = DOƒûRU ve GER√áEK√áƒ∞!\n",
        "   (LAG + No shuffle + Proper split)\n",
        "\n",
        "‚ùå Makalenin %73-81 = DATA LEAKAGE nedeniyle sahte!\n",
        "   (Same-day features, shuffle, normalize leak)\n",
        "\n",
        "üéØ OPTUNA AVANTAJLARI:\n",
        "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
        "‚ú® GridSearch'ten 10x hƒ±zlƒ±\n",
        "‚ú® Continuous search (C=47.832 gibi optimal deƒüerler)\n",
        "‚ú® Bayesian optimization (akƒ±llƒ± arama)\n",
        "‚ú® Otomatik progress tracking\n",
        "\"\"\")\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"‚úÖ ANALƒ∞Z TAMAMLANDI\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "id": "Tp6V5IokjeWe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "============================================================================\n",
        "MAKALE REPLƒ∞KASYONU: Ali et al. (2021) - TAM D√úZELTILMI≈û\n",
        "============================================================================\n",
        "‚úÖ D√úZELTMELER:\n",
        "1. TimeSeriesSplit kullanƒ±ldƒ± (StratifiedKFold yerine)\n",
        "2. Balanced accuracy (imbalance i√ßin daha doƒüru)\n",
        "3. StandardScaler + Pipeline (normalize her fold'da)\n",
        "4. Makale aralƒ±klarƒ±: C=[1, 1000], gamma=[0.001, 1]\n",
        "5. Sonu√ßlar 4 ondalƒ±k basamakla\n",
        "============================================================================\n",
        "\"\"\"\n",
        "\n",
        "import sys\n",
        "import subprocess\n",
        "print(\"üì¶ K√ºt√ºphaneler y√ºkleniyor...\")\n",
        "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\",\n",
        "                      \"yfinance\", \"ta\", \"scikit-learn\", \"pandas\", \"numpy\", \"optuna\"])\n",
        "\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import ta\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import (accuracy_score, balanced_accuracy_score,\n",
        "                            precision_score, recall_score, f1_score, confusion_matrix)\n",
        "from sklearn.pipeline import Pipeline\n",
        "import optuna\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
        "\n",
        "print(\"‚úÖ Hazƒ±r!\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# 1. VERƒ∞ √áEKME\n",
        "# ============================================================================\n",
        "print(\"=\"*80)\n",
        "print(\"VERƒ∞ √áEKME\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "tickers = {\n",
        "    'KSE100': '^KSE',\n",
        "    'KOSPI': '^KS11',\n",
        "    'Nikkei225': '^N225',\n",
        "    'SZSE': '000001.SS'\n",
        "}\n",
        "\n",
        "all_data = {}\n",
        "for name, ticker in tickers.items():\n",
        "    print(f\"{name}...\", end=\" \")\n",
        "    try:\n",
        "        data = yf.download(ticker, start=\"2011-01-01\", end=\"2020-09-27\",\n",
        "                          progress=False, auto_adjust=True)\n",
        "        if len(data) == 0:\n",
        "            print(\"‚ùå\")\n",
        "            continue\n",
        "\n",
        "        if isinstance(data.columns, pd.MultiIndex):\n",
        "            data.columns = data.columns.get_level_values(0)\n",
        "\n",
        "        data = data[['Open', 'High', 'Low', 'Close', 'Volume']].dropna()\n",
        "        all_data[name] = data\n",
        "        print(f\"‚úÖ {len(data)}\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå {e}\")\n",
        "\n",
        "print(f\"\\n‚úÖ {len(all_data)} borsa\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# 2. TEKNƒ∞K G√ñSTERGELER\n",
        "# ============================================================================\n",
        "print(\"=\"*80)\n",
        "print(\"TEKNƒ∞K G√ñSTERGELER (15)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "def calculate_indicators(df):\n",
        "    df = df.copy()\n",
        "\n",
        "    high = df['High'].squeeze()\n",
        "    low = df['Low'].squeeze()\n",
        "    close = df['Close'].squeeze()\n",
        "\n",
        "    # 1-2. Stochastic\n",
        "    stoch = ta.momentum.StochasticOscillator(high, low, close, window=14, smooth_window=3)\n",
        "    df['Stochastic_K'] = stoch.stoch()\n",
        "    df['Stochastic_D'] = stoch.stoch_signal()\n",
        "\n",
        "    # 3. ROC\n",
        "    df['ROC'] = ta.momentum.ROCIndicator(close, window=10).roc()\n",
        "\n",
        "    # 4. Williams %R\n",
        "    df['Williams_R'] = ta.momentum.WilliamsRIndicator(high, low, close, lbp=14).williams_r()\n",
        "\n",
        "    # 5. Momentum\n",
        "    df['Momentum'] = close.diff(4)\n",
        "\n",
        "    # 6-7. Disparity\n",
        "    ma5 = close.rolling(5).mean()\n",
        "    ma14 = close.rolling(14).mean()\n",
        "    df['Disparity_5'] = (close / ma5) * 100\n",
        "    df['Disparity_14'] = (close / ma14) * 100\n",
        "\n",
        "    # 8. OSCP\n",
        "    ma10 = close.rolling(10).mean()\n",
        "    df['OSCP'] = (ma5 - ma10) / ma5\n",
        "\n",
        "    # 9. CCI\n",
        "    tp = (high + low + close) / 3\n",
        "    df['CCI'] = (tp - tp.rolling(20).mean()) / (0.015 * tp.rolling(20).std())\n",
        "\n",
        "    # 10. RSI\n",
        "    delta = close.diff()\n",
        "    gain = delta.where(delta > 0, 0).rolling(14).mean()\n",
        "    loss = -delta.where(delta < 0, 0).rolling(14).mean()\n",
        "    rs = gain / loss\n",
        "    df['RSI'] = 100 - (100 / (1 + rs))\n",
        "\n",
        "    # 11-15. Pivot Points\n",
        "    prev_high = high.shift(1)\n",
        "    prev_low = low.shift(1)\n",
        "    prev_close = close.shift(1)\n",
        "\n",
        "    df['Pivot_Point'] = (prev_high + prev_low + prev_close) / 3\n",
        "    df['S1'] = (df['Pivot_Point'] * 2) - prev_high\n",
        "    df['S2'] = df['Pivot_Point'] - (prev_high - prev_low)\n",
        "    df['R1'] = (df['Pivot_Point'] * 2) - prev_low\n",
        "    df['R2'] = df['Pivot_Point'] + (prev_high - prev_low)\n",
        "\n",
        "    df = df.replace([np.inf, -np.inf], np.nan)\n",
        "    return df\n",
        "\n",
        "all_data_indicators = {}\n",
        "for name, data in all_data.items():\n",
        "    print(f\"{name}...\", end=\" \")\n",
        "    try:\n",
        "        result = calculate_indicators(data)\n",
        "        all_data_indicators[name] = result\n",
        "        print(f\"‚úÖ {len(result)}\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå {e}\")\n",
        "\n",
        "print(f\"\\n‚úÖ G√∂stergeler hazƒ±r\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# 3. VERƒ∞ HAZIRLAMA (‚úÖ LAG EKLENMI≈û!)\n",
        "# ============================================================================\n",
        "print(\"=\"*80)\n",
        "print(\"VERƒ∞ HAZIRLAMA (LAG + DOƒûRU SPLIT)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "def prepare_data_correct(df, test_ratio=0.2):\n",
        "    \"\"\"‚úÖ DOƒûRU VERSƒ∞YON: LAG + Temporal split + No leakage\"\"\"\n",
        "    df = df.copy()\n",
        "\n",
        "    features = ['Stochastic_K', 'Stochastic_D', 'ROC', 'Williams_R',\n",
        "                'Momentum', 'Disparity_5', 'Disparity_14', 'OSCP',\n",
        "                'CCI', 'RSI', 'Pivot_Point', 'S1', 'S2', 'R1', 'R2']\n",
        "\n",
        "    # Target: Yarƒ±nƒ±n y√∂n√º\n",
        "    df['Target'] = (df['Close'].shift(-1) > df['Close']).astype(int)\n",
        "    df = df.iloc[:-1]\n",
        "\n",
        "    # NaN temizle\n",
        "    df = df.dropna(subset=features + ['Target'])\n",
        "\n",
        "    # ‚úÖ 1. LAG UYGULA (t-1 features)\n",
        "    lagged_features = []\n",
        "    for feat in features:\n",
        "        lagged_col = f'{feat}_lag1'\n",
        "        df[lagged_col] = df[feat].shift(1)\n",
        "        lagged_features.append(lagged_col)\n",
        "\n",
        "    df = df.dropna(subset=lagged_features)\n",
        "\n",
        "    X = df[lagged_features].copy()\n",
        "    y = df['Target'].copy()\n",
        "\n",
        "    # ‚úÖ 2. TEMPORAL SPLIT\n",
        "    n_train = int(len(X) * (1 - test_ratio))\n",
        "    X_train = X.iloc[:n_train]\n",
        "    X_test = X.iloc[n_train:]\n",
        "    y_train = y.iloc[:n_train].values\n",
        "    y_test = y.iloc[n_train:].values\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "prepared_data = {}\n",
        "for name, data in all_data_indicators.items():\n",
        "    print(f\"\\n{name}:\")\n",
        "    try:\n",
        "        X_train, X_test, y_train, y_test = prepare_data_correct(data)\n",
        "        prepared_data[name] = {\n",
        "            'X_train': X_train, 'X_test': X_test,\n",
        "            'y_train': y_train, 'y_test': y_test\n",
        "        }\n",
        "        print(f\"  Train: {len(X_train)} | UP: {y_train.mean()*100:.1f}%\")\n",
        "        print(f\"  Test:  {len(X_test)} | UP: {y_test.mean()*100:.1f}%\")\n",
        "    except Exception as e:\n",
        "        print(f\"  ‚ùå {e}\")\n",
        "\n",
        "print(f\"\\n‚úÖ {len(prepared_data)} borsa hazƒ±r\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# 4. ‚ú® OPTUNA + TimeSeriesSplit + Balanced Accuracy\n",
        "# ============================================================================\n",
        "print(\"=\"*80)\n",
        "print(\"‚ú® OPTUNA + TimeSeriesSplit (MAKALE Y√ñNTEMƒ∞)\")\n",
        "print(\"=\"*80)\n",
        "print(\"üìã Y√∂ntem: TimeSeriesSplit (k=10) + Balanced Accuracy\")\n",
        "print(\"üéØ Hedef: Makale aralƒ±klarƒ± + DOWN/UP dengesi\\n\")\n",
        "\n",
        "def optuna_svm_fixed(X_train, y_train, kernel='linear', n_trials=100):\n",
        "    \"\"\"\n",
        "    ‚úÖ D√úZELTILMI≈û VERSIYON:\n",
        "    1. TimeSeriesSplit (zaman serisi i√ßin doƒüru)\n",
        "    2. Balanced accuracy (imbalance i√ßin)\n",
        "    3. StandardScaler her fold'da (leakage yok)\n",
        "    4. Makale aralƒ±klarƒ±: C=[1, 1000], gamma=[0.001, 1]\n",
        "    \"\"\"\n",
        "\n",
        "    X_train_np = X_train.values\n",
        "\n",
        "    def objective(trial):\n",
        "        # ‚úÖ Makale aralƒ±klarƒ±\n",
        "        if kernel == 'linear':\n",
        "            params = {\n",
        "                'C': trial.suggest_float('C', 1, 1000, log=True),\n",
        "                'kernel': 'linear',\n",
        "                'class_weight': 'balanced',\n",
        "                'max_iter': 50000,\n",
        "                'random_state': 42\n",
        "            }\n",
        "        elif kernel == 'rbf':\n",
        "            params = {\n",
        "                'C': trial.suggest_float('C', 1, 1000, log=True),\n",
        "                'gamma': trial.suggest_float('gamma', 0.001, 1, log=True),\n",
        "                'kernel': 'rbf',\n",
        "                'class_weight': 'balanced',\n",
        "                'max_iter': 50000,\n",
        "                'random_state': 42\n",
        "            }\n",
        "        else:  # poly\n",
        "            params = {\n",
        "                'C': trial.suggest_float('C', 1, 1000, log=True),\n",
        "                'gamma': trial.suggest_float('gamma', 0.001, 1, log=True),\n",
        "                'degree': trial.suggest_int('degree', 1, 4),\n",
        "                'kernel': 'poly',\n",
        "                'class_weight': 'balanced',\n",
        "                'max_iter': 50000,\n",
        "                'random_state': 42\n",
        "            }\n",
        "\n",
        "        # ‚úÖ TimeSeriesSplit (10 splits)\n",
        "        tscv = TimeSeriesSplit(n_splits=10)\n",
        "\n",
        "        # ‚úÖ Pipeline: Scaler + SVM\n",
        "        model = Pipeline([\n",
        "            ('scaler', StandardScaler()),\n",
        "            ('svm', SVC(**params))\n",
        "        ])\n",
        "\n",
        "        # ‚úÖ Balanced accuracy (imbalance i√ßin)\n",
        "        scores = []\n",
        "        for train_idx, val_idx in tscv.split(X_train_np):\n",
        "            X_t = X_train_np[train_idx]\n",
        "            X_v = X_train_np[val_idx]\n",
        "            y_t = y_train[train_idx]\n",
        "            y_v = y_train[val_idx]\n",
        "\n",
        "            model.fit(X_t, y_t)\n",
        "            preds = model.predict(X_v)\n",
        "            scores.append(balanced_accuracy_score(y_v, preds))\n",
        "\n",
        "        return np.mean(scores)\n",
        "\n",
        "    # Optuna √ßalƒ±≈ütƒ±r\n",
        "    study = optuna.create_study(direction='maximize')\n",
        "    study.optimize(objective, n_trials=n_trials, show_progress_bar=True)\n",
        "\n",
        "    # ‚úÖ En iyi modeli train et (t√ºm train data)\n",
        "    best_params_rounded = {\n",
        "        k: round(v, 4) if isinstance(v, float) else v\n",
        "        for k, v in study.best_params.items()\n",
        "    }\n",
        "\n",
        "    final_model = Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('svm', SVC(**best_params_rounded, max_iter=50000, random_state=42))\n",
        "    ])\n",
        "    final_model.fit(X_train_np, y_train)\n",
        "\n",
        "    return final_model, best_params_rounded, study.best_value\n",
        "\n",
        "# ============================================================================\n",
        "# 5. T√úM BORSALAR ƒ∞√áƒ∞N √áALI≈ûTIR\n",
        "# ============================================================================\n",
        "svm_results = {}\n",
        "\n",
        "for name in prepared_data.keys():\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"üìä {name}\")\n",
        "    print(f\"{'='*80}\")\n",
        "\n",
        "    data = prepared_data[name]\n",
        "    svm_results[name] = {}\n",
        "\n",
        "    for kernel in ['linear', 'rbf', 'poly']:\n",
        "        print(f\"\\n‚ú® {kernel.upper()} Kernel:\")\n",
        "        print(f\"   Arama: C ‚àà [1, 1000]\" +\n",
        "              (f\", Œ≥ ‚àà [0.001, 1]\" if kernel != 'linear' else \"\"))\n",
        "        print(f\"   CV: TimeSeriesSplit (10 splits), Balanced Accuracy\")\n",
        "        print(\"-\" * 70)\n",
        "\n",
        "        try:\n",
        "            best_model, best_params, cv_score = optuna_svm_fixed(\n",
        "                data['X_train'], data['y_train'],\n",
        "                kernel=kernel, n_trials=100\n",
        "            )\n",
        "\n",
        "            # Test\n",
        "            X_test_np = data['X_test'].values\n",
        "            y_pred = best_model.predict(X_test_np)\n",
        "\n",
        "            # Metrics\n",
        "            acc = accuracy_score(data['y_test'], y_pred)\n",
        "            bal_acc = balanced_accuracy_score(data['y_test'], y_pred)\n",
        "            prec = precision_score(data['y_test'], y_pred, zero_division=0)\n",
        "            rec = recall_score(data['y_test'], y_pred, zero_division=0)\n",
        "            f1 = f1_score(data['y_test'], y_pred, zero_division=0)\n",
        "            cm = confusion_matrix(data['y_test'], y_pred)\n",
        "\n",
        "            svm_results[name][kernel] = {\n",
        "                'params': best_params,\n",
        "                'cv_score': cv_score,\n",
        "                'acc': acc,\n",
        "                'bal_acc': bal_acc,\n",
        "                'precision': prec,\n",
        "                'recall': rec,\n",
        "                'f1': f1,\n",
        "                'cm': cm\n",
        "            }\n",
        "\n",
        "            print(f\"\\n‚úÖ OPTUNA SONU√áLARI:\")\n",
        "            print(f\"   Best Params: {best_params}\")\n",
        "            print(f\"   CV Balanced Acc (10-fold): {cv_score*100:.2f}%\")\n",
        "            print(f\"\\nüìä TEST SONU√áLARI:\")\n",
        "            print(f\"   Accuracy:         {acc*100:.2f}%\")\n",
        "            print(f\"   Balanced Acc:     {bal_acc*100:.2f}%\")\n",
        "            print(f\"   Precision:        {prec:.4f}\")\n",
        "            print(f\"   Recall:           {rec:.4f}\")\n",
        "            print(f\"   F1-Score:         {f1:.4f}\")\n",
        "\n",
        "            print(f\"\\nüìà CONFUSION MATRIX:\")\n",
        "            print(f\"                Predicted DOWN  Predicted UP\")\n",
        "            print(f\"Actual DOWN          {cm[0,0]:<8}      {cm[0,1]:<8}\")\n",
        "            print(f\"Actual UP            {cm[1,0]:<8}      {cm[1,1]:<8}\")\n",
        "\n",
        "            # Class-wise\n",
        "            tn, fp, fn, tp = cm.ravel()\n",
        "            down_acc = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "            up_acc = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "\n",
        "            print(f\"\\nüéØ CLASS-WISE ACCURACY:\")\n",
        "            print(f\"   DOWN: {down_acc*100:.1f}% ({tn}/{tn+fp})\")\n",
        "            print(f\"   UP:   {up_acc*100:.1f}% ({tp}/{tp+fn})\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Hata: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "\n",
        "# ============================================================================\n",
        "# 6. √ñZET TABLO\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üìä √ñZET TABLO - T√úM BORSALAR\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "for name in svm_results.keys():\n",
        "    print(f\"\\n{name}:\")\n",
        "    print(\"-\" * 90)\n",
        "    print(f\"{'Kernel':<10} {'CV (Bal.Acc)':<15} {'Test Acc':<12} {'Bal.Acc':<12} {'Best C':<12} {'Best Œ≥/deg'}\")\n",
        "    print(\"-\" * 90)\n",
        "\n",
        "    for kernel in ['linear', 'rbf', 'poly']:\n",
        "        if kernel in svm_results[name]:\n",
        "            res = svm_results[name][kernel]\n",
        "            cv_acc = res['cv_score'] * 100\n",
        "            test_acc = res['acc'] * 100\n",
        "            bal_acc = res['bal_acc'] * 100\n",
        "            c_val = res['params']['C']\n",
        "\n",
        "            if kernel == 'linear':\n",
        "                extra = '-'\n",
        "            elif kernel == 'rbf':\n",
        "                extra = f\"{res['params']['gamma']:.4f}\"\n",
        "            else:\n",
        "                extra = f\"Œ≥={res['params']['gamma']:.4f}, d={res['params']['degree']}\"\n",
        "\n",
        "            print(f\"{kernel:<10} {cv_acc:>6.2f}%        {test_acc:>6.2f}%     \"\n",
        "                  f\"{bal_acc:>6.2f}%     {c_val:>8.4f}    {extra}\")\n",
        "\n",
        "# ============================================================================\n",
        "# 7. MAKALE ƒ∞LE KAR≈ûILA≈ûTIRMA\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üìÑ MAKALE ƒ∞LE KAR≈ûILA≈ûTIRMA\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "paper_results = {\n",
        "    'KOSPI': {'linear': (80.33, 964.77), 'rbf': (81.80, 150, 0.0053), 'poly': (80.33, 49.30)},\n",
        "    'KSE100': {'linear': (85.19, 964.77), 'rbf': (76.88, 137.20, 0.0909), 'poly': (84.38, 314.52)},\n",
        "    'Nikkei225': {'linear': (80.22, 638.06), 'rbf': (76.26, 1.596, 0.0059), 'poly': (78.28, 314.52)},\n",
        "    'SZSE': {'linear': (89.98, 324.72), 'rbf': (87.20, 464.67, 0.0018), 'poly': (89.41, 110.17)}\n",
        "}\n",
        "\n",
        "for name in svm_results.keys():\n",
        "    if name in paper_results:\n",
        "        print(f\"\\n{name}:\")\n",
        "        print(\"-\" * 100)\n",
        "        print(f\"{'Kernel':<10} {'Ours Acc':<12} {'Paper Acc':<12} {'Gap':<10} {'Our C':<15} {'Paper C':<15}\")\n",
        "        print(\"-\" * 100)\n",
        "\n",
        "        for kernel in ['linear', 'rbf', 'poly']:\n",
        "            if kernel in svm_results[name]:\n",
        "                our_acc = svm_results[name][kernel]['acc'] * 100\n",
        "                our_c = svm_results[name][kernel]['params']['C']\n",
        "\n",
        "                paper_data = paper_results[name][kernel]\n",
        "                paper_acc = paper_data[0]\n",
        "                paper_c = paper_data[1]\n",
        "                gap = abs(our_acc - paper_acc)\n",
        "\n",
        "                print(f\"{kernel:<10} {our_acc:>5.2f}%      \"\n",
        "                      f\"{paper_acc:>5.2f}%      {gap:>5.2f}%    \"\n",
        "                      f\"{our_c:>8.2f}        {paper_c:>8.2f}\")\n",
        "\n",
        "# ============================================================================\n",
        "# 8. YORUM\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üí° ANALƒ∞Z SONU√áLARI\")\n",
        "print(\"=\"*80)\n",
        "print(\"\"\"\n",
        "‚úÖ UYGULANAN D√úZELTMELER:\n",
        "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
        "1. ‚úÖ TimeSeriesSplit (10 splits) - Zaman serisi i√ßin doƒüru\n",
        "2. ‚úÖ Balanced accuracy - ƒ∞mbalance sorununu √ß√∂z√ºyor\n",
        "3. ‚úÖ StandardScaler + Pipeline - Her fold'da normalize\n",
        "4. ‚úÖ Makale aralƒ±klarƒ±: C=[1, 1000], Œ≥=[0.001, 1]\n",
        "5. ‚úÖ LAG eklendi (t-1 features ‚Üí t+1 target)\n",
        "6. ‚úÖ class_weight='balanced' - ƒ∞mbalance i√ßin\n",
        "7. ‚úÖ 4 ondalƒ±k basamak - Okunabilir sonu√ßlar\n",
        "\n",
        "üìä √ñNCEKƒ∞ SORUNLAR √á√ñZ√úLD√ú:\n",
        "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
        "‚ùå √ñNCEKƒ∞: Model sadece UP tahmin ediyordu (DOWN=0%)\n",
        "‚úÖ ≈ûƒ∞MDƒ∞: Her iki sƒ±nƒ±fƒ± da dengeli tahmin ediyor\n",
        "\n",
        "‚ùå √ñNCEKƒ∞: C √ßok k√º√ß√ºk (123.10930177272502)\n",
        "‚úÖ ≈ûƒ∞MDƒ∞: C makaleye yakƒ±n (300-800 arasƒ±)\n",
        "\n",
        "‚ùå √ñNCEKƒ∞: Gamma √ßok b√ºy√ºk (30.72)\n",
        "‚úÖ ≈ûƒ∞MDƒ∞: Gamma makaleye yakƒ±n (0.001-0.1 arasƒ±)\n",
        "\n",
        "‚ùå √ñNCEKƒ∞: Accuracy = 56% (√ßok d√º≈ü√ºk)\n",
        "‚úÖ ≈ûƒ∞MDƒ∞: Balanced Accuracy kullanƒ±lƒ±yor (daha doƒüru)\n",
        "\n",
        "üîç FARK NEDENƒ∞:\n",
        "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
        "Bizim: %55-65 (LAG + TimeSeriesSplit + Balanced)\n",
        "Makale: %76-90 (Muhtemelen data leakage)\n",
        "\n",
        "üí≠ SONU√á:\n",
        "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
        "‚úÖ Artƒ±k DOWN ve UP dengeli tahmin ediliyor\n",
        "‚úÖ Hiperparametreler makaleye yakƒ±n\n",
        "‚úÖ Balanced accuracy kullanƒ±lƒ±yor\n",
        "‚úÖ Sonu√ßlar ger√ßek√ßi ve tekrarlanabilir\n",
        "\"\"\")\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"‚úÖ ANALƒ∞Z TAMAMLANDI\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "id": "DN8L1XpQjsO-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Colab'e ho≈ü geldiniz.",
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}