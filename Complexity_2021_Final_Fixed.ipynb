{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# üéØ COMPLEXITY (2021) - FINAL FIXED VERSION\n",
    "\n",
    "**Article:** Ali, M., et al. (2021). Predicting the Direction Movement of Financial Time Series Using Artificial Neural Network and Support Vector Machine. *Complexity*, 2021.\n",
    "\n",
    "**‚úÖ Fixes Applied:**\n",
    "- MultiIndex DataFrame issue resolved\n",
    "- Proper Series handling for all calculations\n",
    "- Comprehensive evaluation metrics\n",
    "- TimeSeriesSplit for cross-validation\n",
    "- Detailed visualizations\n",
    "\n",
    "**üöÄ Quick Start:** Runtime ‚Üí Run all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_libraries"
   },
   "outputs": [],
   "source": [
    "# Install and import libraries\n",
    "!pip install yfinance -q\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ Libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "download_data"
   },
   "outputs": [],
   "source": [
    "# Download data\n",
    "print(\"=\"*70)\n",
    "print(\"üì• DOWNLOADING DATA...\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Download KSE-100 data\n",
    "data = yf.download(\"^KSE\", start=\"2011-01-01\", end=\"2020-09-27\", progress=False)\n",
    "\n",
    "# CRITICAL: Fix MultiIndex columns\n",
    "if isinstance(data.columns, pd.MultiIndex):\n",
    "    data.columns = data.columns.droplevel(1)\n",
    "    print(\"‚úÖ MultiIndex fixed\")\n",
    "\n",
    "print(f\"‚úÖ Downloaded {len(data)} days of data\")\n",
    "print(f\"üìÖ Date range: {data.index[0]} ‚Üí {data.index[-1]}\")\n",
    "print(f\"\\nüìä First 5 rows:\")\n",
    "print(data.head())\n",
    "print(f\"\\nüìä Data shape: {data.shape}\")\n",
    "print(f\"‚ùì Missing values: {data.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "technical_indicators"
   },
   "outputs": [],
   "source": [
    "# Technical Indicators - FIXED VERSION\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üîß CALCULATING TECHNICAL INDICATORS...\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "df = data.copy()\n",
    "\n",
    "# Convert to Series (handle MultiIndex issues)\n",
    "close = df['Close'].values if isinstance(df['Close'], pd.Series) else df['Close'].iloc[:, 0].values\n",
    "high = df['High'].values if isinstance(df['High'], pd.Series) else df['High'].iloc[:, 0].values\n",
    "low = df['Low'].values if isinstance(df['Low'], pd.Series) else df['Low'].iloc[:, 0].values\n",
    "\n",
    "# Create clean DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Close': close,\n",
    "    'High': high,\n",
    "    'Low': low\n",
    "}, index=data.index)\n",
    "\n",
    "# 1-2. Stochastic Oscillator\n",
    "low_14 = df['Low'].rolling(14).min()\n",
    "high_14 = df['High'].rolling(14).max()\n",
    "df['Stochastic_K'] = 100 * ((df['Close'] - low_14) / (high_14 - low_14 + 1e-10))\n",
    "df['Stochastic_D'] = df['Stochastic_K'].rolling(3).mean()\n",
    "\n",
    "# 3. Rate of Change (ROC)\n",
    "df['ROC'] = ((df['Close'] / df['Close'].shift(10)) - 1) * 100\n",
    "\n",
    "# 4. Williams %R\n",
    "df['Williams_R'] = -100 * ((high_14 - df['Close']) / (high_14 - low_14 + 1e-10))\n",
    "\n",
    "# 5. Momentum\n",
    "df['Momentum'] = df['Close'] - df['Close'].shift(4)\n",
    "\n",
    "# 6-7. Disparity Index\n",
    "ma5 = df['Close'].rolling(5).mean()\n",
    "ma14 = df['Close'].rolling(14).mean()\n",
    "df['Disparity_5'] = ((df['Close'] - ma5) / (ma5 + 1e-10)) * 100\n",
    "df['Disparity_14'] = ((df['Close'] - ma14) / (ma14 + 1e-10)) * 100\n",
    "\n",
    "# 8. OSCP (Oscillator of a Short-term Cycle)\n",
    "ma10 = df['Close'].rolling(10).mean()\n",
    "df['OSCP'] = ((ma5 - ma10) / (ma5 + 1e-10)) * 100\n",
    "\n",
    "# 9. Commodity Channel Index (CCI)\n",
    "tp = (df['High'] + df['Low'] + df['Close']) / 3\n",
    "ma_tp = tp.rolling(20).mean()\n",
    "md = tp.rolling(20).apply(lambda x: np.abs(x - x.mean()).mean())\n",
    "df['CCI'] = (tp - ma_tp) / (0.015 * md + 1e-10)\n",
    "\n",
    "# 10. Relative Strength Index (RSI)\n",
    "delta = df['Close'].diff()\n",
    "gain = (delta.where(delta > 0, 0)).rolling(14).mean()\n",
    "loss = (-delta.where(delta < 0, 0)).rolling(14).mean()\n",
    "rs = gain / (loss + 1e-10)\n",
    "df['RSI'] = 100 - (100 / (1 + rs))\n",
    "\n",
    "# 11-15. Pivot Points (using previous day's data)\n",
    "prev_high = df['High'].shift(1)\n",
    "prev_low = df['Low'].shift(1)\n",
    "prev_close = df['Close'].shift(1)\n",
    "\n",
    "df['Pivot_Point'] = (prev_high + prev_low + prev_close) / 3\n",
    "df['S1'] = (df['Pivot_Point'] * 2) - prev_high\n",
    "df['S2'] = df['Pivot_Point'] - (prev_high - prev_low)\n",
    "df['R1'] = (df['Pivot_Point'] * 2) - prev_low\n",
    "df['R2'] = df['Pivot_Point'] + (prev_high - prev_low)\n",
    "\n",
    "# Target: Next day's direction (1=Up, 0=Down)\n",
    "df['Target'] = (df['Close'].shift(-1) > df['Close']).astype(int)\n",
    "\n",
    "# Remove NaN and infinite values\n",
    "df = df.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "\n",
    "print(f\"‚úÖ {len(df)} rows prepared\")\n",
    "print(f\"\\nüìä Target distribution:\")\n",
    "print(df['Target'].value_counts(normalize=True))\n",
    "print(f\"\\nüî¢ Sample indicators:\")\n",
    "print(df[['RSI', 'CCI', 'Momentum', 'Pivot_Point', 'Target']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "data_preparation"
   },
   "outputs": [],
   "source": [
    "# Data Preparation\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìä DATA PREPARATION...\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "feature_cols = ['Stochastic_K', 'Stochastic_D', 'ROC', 'Williams_R',\n",
    "                'Momentum', 'Disparity_5', 'Disparity_14', 'OSCP',\n",
    "                'CCI', 'RSI', 'Pivot_Point', 'S1', 'S2', 'R1', 'R2']\n",
    "\n",
    "X = df[feature_cols].values\n",
    "y = df['Target'].values\n",
    "dates = df.index\n",
    "\n",
    "# Chronological split (80/20)\n",
    "train_size = int(len(X) * 0.8)\n",
    "X_train = X[:train_size]\n",
    "X_test = X[train_size:]\n",
    "y_train = y[:train_size]\n",
    "y_test = y[train_size:]\n",
    "\n",
    "# Normalization (fit on train only)\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Train: {len(X_train)} samples | Up: {sum(y_train)}/{len(y_train)} ({sum(y_train)/len(y_train)*100:.1f}%)\")\n",
    "print(f\"Test:  {len(X_test)} samples | Up: {sum(y_test)}/{len(y_test)} ({sum(y_test)/len(y_test)*100:.1f}%)\")\n",
    "print(f\"Train period: {dates[:train_size][0]} ‚Üí {dates[:train_size][-1]}\")\n",
    "print(f\"Test period:  {dates[train_size:][0]} ‚Üí {dates[train_size:][-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "evaluation_function"
   },
   "outputs": [],
   "source": [
    "# Evaluation Function\n",
    "def evaluate_model(model, X_test, y_test, model_name):\n",
    "    \"\"\"Comprehensive model evaluation\"\"\"\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"{model_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Accuracy:  {acc:.4f} ({acc*100:.2f}%)\")\n",
    "    print(f\"Precision: {prec:.4f}\")\n",
    "    print(f\"Recall:    {rec:.4f}\")\n",
    "    print(f\"F1-Score:  {f1:.4f}\")\n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(f\"\\nConfusion Matrix:\")\n",
    "    print(cm)\n",
    "    print(f\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=['Down', 'Up']))\n",
    "    \n",
    "    return {\n",
    "        'accuracy': acc, 'precision': prec, 'recall': rec, 'f1': f1,\n",
    "        'predictions': y_pred, 'confusion_matrix': cm\n",
    "    }\n",
    "\n",
    "print(\"‚úÖ Evaluation function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "article_parameters"
   },
   "outputs": [],
   "source": [
    "# SVM Models - Article Parameters\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ü§ñ SVM MODELS (ARTICLE PARAMETERS)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "results = {}\n",
    "\n",
    "# 1. Linear SVM\n",
    "print(\"\\n[1/3] Linear SVM (C=964.7736)...\")\n",
    "svm_linear = SVC(kernel='linear', C=964.7736, random_state=42)\n",
    "svm_linear.fit(X_train, y_train)\n",
    "results['Linear'] = evaluate_model(svm_linear, X_test, y_test, \"LINEAR SVM\")\n",
    "print(f\"üìù Article reports: 85.19%\")\n",
    "\n",
    "# 2. RBF SVM\n",
    "print(\"\\n[2/3] RBF SVM (C=137.20, gamma=60.51)...\")\n",
    "svm_rbf = SVC(kernel='rbf', C=137.20, gamma=60.51, random_state=42)\n",
    "svm_rbf.fit(X_train, y_train)\n",
    "results['RBF'] = evaluate_model(svm_rbf, X_test, y_test, \"RBF SVM\")\n",
    "print(f\"üìù Article reports: 76.88%\")\n",
    "\n",
    "# 3. Polynomial SVM\n",
    "print(\"\\n[3/3] Polynomial SVM (C=314.52, degree=2, coef0=0.5554)...\")\n",
    "svm_poly = SVC(kernel='poly', C=314.52, degree=2, coef0=0.5554, random_state=42)\n",
    "svm_poly.fit(X_train, y_train)\n",
    "results['Polynomial'] = evaluate_model(svm_poly, X_test, y_test, \"POLYNOMIAL SVM\")\n",
    "print(f\"üìù Article reports: 84.38%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "grid_search"
   },
   "outputs": [],
   "source": [
    "# Grid Search with TimeSeriesSplit\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üîç GRID SEARCH (TimeSeriesSplit)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=4)\n",
    "results_grid = {}\n",
    "\n",
    "# 1. Linear SVM\n",
    "print(\"\\n[1/3] Linear Grid Search...\")\n",
    "grid_linear = GridSearchCV(\n",
    "    SVC(kernel='linear', random_state=42),\n",
    "    {'C': [0.1, 1, 10, 100, 500, 964.7736, 1000]},\n",
    "    cv=tscv, scoring='accuracy', n_jobs=-1, verbose=0\n",
    ")\n",
    "grid_linear.fit(X_train, y_train)\n",
    "print(f\"Best params: {grid_linear.best_params_} | CV score: {grid_linear.best_score_:.4f}\")\n",
    "results_grid['Linear'] = evaluate_model(grid_linear, X_test, y_test, \"LINEAR SVM (Grid)\")\n",
    "\n",
    "# 2. RBF SVM\n",
    "print(\"\\n[2/3] RBF Grid Search...\")\n",
    "grid_rbf = GridSearchCV(\n",
    "    SVC(kernel='rbf', random_state=42),\n",
    "    {'C': [1, 10, 100, 137.20], 'gamma': [0.01, 0.1, 1, 10, 60.51, 'scale']},\n",
    "    cv=tscv, scoring='accuracy', n_jobs=-1, verbose=0\n",
    ")\n",
    "grid_rbf.fit(X_train, y_train)\n",
    "print(f\"Best params: {grid_rbf.best_params_} | CV score: {grid_rbf.best_score_:.4f}\")\n",
    "results_grid['RBF'] = evaluate_model(grid_rbf, X_test, y_test, \"RBF SVM (Grid)\")\n",
    "\n",
    "# 3. Polynomial SVM\n",
    "print(\"\\n[3/3] Polynomial Grid Search...\")\n",
    "grid_poly = GridSearchCV(\n",
    "    SVC(kernel='poly', random_state=42),\n",
    "    {'C': [10, 100, 314.52, 500], 'degree': [2, 3], 'coef0': [0, 0.5554, 1.0]},\n",
    "    cv=tscv, scoring='accuracy', n_jobs=-1, verbose=0\n",
    ")\n",
    "grid_poly.fit(X_train, y_train)\n",
    "print(f\"Best params: {grid_poly.best_params_} | CV score: {grid_poly.best_score_:.4f}\")\n",
    "results_grid['Polynomial'] = evaluate_model(grid_poly, X_test, y_test, \"POLYNOMIAL SVM (Grid)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "final_comparison"
   },
   "outputs": [],
   "source": [
    "# Final Comparison\n",
    "article = {'Linear': 0.8519, 'RBF': 0.7688, 'Polynomial': 0.8438}\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìä FINAL RESULTS COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\n{'Model':<15} {'Article':<12} {'Exact':<12} {'Grid':<12} {'Diff':<10}\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "for m in ['Linear', 'RBF', 'Polynomial']:\n",
    "    art = article[m] * 100\n",
    "    exact = results[m]['accuracy'] * 100\n",
    "    grid = results_grid[m]['accuracy'] * 100\n",
    "    diff = exact - art\n",
    "    \n",
    "    print(f\"{m:<15} {art:>8.2f}%    {exact:>8.2f}%    {grid:>8.2f}%    {diff:>+7.2f}%\")\n",
    "\n",
    "avg_art = np.mean(list(article.values())) * 100\n",
    "avg_exact = np.mean([results[m]['accuracy'] for m in ['Linear', 'RBF', 'Polynomial']]) * 100\n",
    "avg_grid = np.mean([results_grid[m]['accuracy'] for m in ['Linear', 'RBF', 'Polynomial']]) * 100\n",
    "\n",
    "print(\"-\"*80)\n",
    "print(f\"{'AVERAGE':<15} {avg_art:>8.2f}%    {avg_exact:>8.2f}%    {avg_grid:>8.2f}%    {avg_exact-avg_art:>+7.2f}%\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "# Interpretation\n",
    "gap = abs(avg_exact - avg_art)\n",
    "if gap <= 5:\n",
    "    print(\"‚úÖ EXCELLENT: Results closely match the article!\")\n",
    "elif gap <= 10:\n",
    "    print(\"‚úÖ GOOD: Results are reasonably close to the article.\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è MODERATE: Significant difference likely due to:\")\n",
    "    print(\"   1. Different data source (Yahoo Finance vs. article's source)\")\n",
    "    print(\"   2. KSE-100 data quality/availability issues\")\n",
    "    print(\"   3. Different market periods\")\n",
    "    print(\"   4. Preprocessing differences\")\n",
    "    print(f\"\\nüí° Suggestion: Test with SPY for better data quality:\")\n",
    "    print(\"   data = yf.download('SPY', start='2011-01-01', end='2020-09-27')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "visualizations"
   },
   "outputs": [],
   "source": [
    "# Visualizations\n",
    "print(\"\\nüìä Creating visualizations...\")\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# 1. Accuracy Comparison\n",
    "models = ['Linear', 'RBF', 'Polynomial']\n",
    "x = np.arange(len(models))\n",
    "width = 0.25\n",
    "\n",
    "art_vals = [article[m] for m in models]\n",
    "exact_vals = [results[m]['accuracy'] for m in models]\n",
    "grid_vals = [results_grid[m]['accuracy'] for m in models]\n",
    "\n",
    "axes[0, 0].bar(x - width, art_vals, width, label='Article', alpha=0.8, color='#2ecc71')\n",
    "axes[0, 0].bar(x, exact_vals, width, label='Exact Params', alpha=0.8, color='#3498db')\n",
    "axes[0, 0].bar(x + width, grid_vals, width, label='Grid Search', alpha=0.8, color='#e74c3c')\n",
    "axes[0, 0].set_ylabel('Accuracy', fontsize=12)\n",
    "axes[0, 0].set_title('Model Performance Comparison', fontweight='bold', fontsize=14)\n",
    "axes[0, 0].set_xticks(x)\n",
    "axes[0, 0].set_xticklabels(models)\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(axis='y', alpha=0.3)\n",
    "axes[0, 0].set_ylim([0.4, 1.0])\n",
    "\n",
    "# 2. F1-Score Comparison\n",
    "f1_exact = [results[m]['f1'] for m in models]\n",
    "f1_grid = [results_grid[m]['f1'] for m in models]\n",
    "\n",
    "axes[0, 1].bar(x - width/2, f1_exact, width, label='Exact Params', alpha=0.8, color='#3498db')\n",
    "axes[0, 1].bar(x + width/2, f1_grid, width, label='Grid Search', alpha=0.8, color='#e74c3c')\n",
    "axes[0, 1].set_ylabel('F1-Score', fontsize=12)\n",
    "axes[0, 1].set_title('F1-Score Comparison', fontweight='bold', fontsize=14)\n",
    "axes[0, 1].set_xticks(x)\n",
    "axes[0, 1].set_xticklabels(models)\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 3. Best Model Confusion Matrix\n",
    "best_model = max(results_grid, key=lambda k: results_grid[k]['accuracy'])\n",
    "cm = results_grid[best_model]['confusion_matrix']\n",
    "\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[1, 0],\n",
    "            xticklabels=['Down', 'Up'], yticklabels=['Down', 'Up'])\n",
    "axes[1, 0].set_title(f'Confusion Matrix - Best Model ({best_model})', fontweight='bold', fontsize=14)\n",
    "axes[1, 0].set_ylabel('True Label')\n",
    "axes[1, 0].set_xlabel('Predicted Label')\n",
    "\n",
    "# 4. Accuracy Gap Analysis\n",
    "gaps = [abs(results[m]['accuracy'] - article[m]) * 100 for m in models]\n",
    "colors = ['red' if g > 10 else 'orange' if g > 5 else 'green' for g in gaps]\n",
    "\n",
    "axes[1, 1].bar(models, gaps, alpha=0.8, color=colors)\n",
    "axes[1, 1].set_ylabel('Accuracy Gap (%)', fontsize=12)\n",
    "axes[1, 1].set_title('Difference from Article', fontweight='bold', fontsize=14)\n",
    "axes[1, 1].grid(axis='y', alpha=0.3)\n",
    "axes[1, 1].axhline(y=5, color='orange', linestyle='--', linewidth=2, label='¬±5% threshold')\n",
    "axes[1, 1].axhline(y=10, color='red', linestyle='--', linewidth=2, label='¬±10% threshold')\n",
    "axes[1, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Visualizations complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "summary"
   },
   "outputs": [],
   "source": [
    "# Summary Report\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìù SUMMARY REPORT\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nüéØ Best Model: {best_model} SVM\")\n",
    "print(f\"   Accuracy:  {results_grid[best_model]['accuracy']:.4f} ({results_grid[best_model]['accuracy']*100:.2f}%)\")\n",
    "print(f\"   F1-Score:  {results_grid[best_model]['f1']:.4f}\")\n",
    "print(f\"   Precision: {results_grid[best_model]['precision']:.4f}\")\n",
    "print(f\"   Recall:    {results_grid[best_model]['recall']:.4f}\")\n",
    "\n",
    "print(f\"\\nüìä Data Information:\")\n",
    "print(f\"   Total samples: {len(df)}\")\n",
    "print(f\"   Train samples: {len(X_train)}\")\n",
    "print(f\"   Test samples:  {len(X_test)}\")\n",
    "print(f\"   Class balance (test): {sum(y_test)/len(y_test)*100:.1f}% Up\")\n",
    "\n",
    "print(f\"\\nüí° Key Findings:\")\n",
    "if avg_exact > avg_art:\n",
    "    print(f\"   ‚úÖ Our implementation performs {avg_exact-avg_art:.2f}% better than reported\")\n",
    "elif avg_exact > avg_art * 0.95:\n",
    "    print(f\"   ‚úÖ Results closely match the article (within 5%)\")\n",
    "else:\n",
    "    print(f\"   ‚ö†Ô∏è Performance gap: {avg_art-avg_exact:.2f}% lower than article\")\n",
    "    print(f\"   This is normal due to data source differences\")\n",
    "\n",
    "print(f\"\\nüî¨ Technical Notes:\")\n",
    "print(f\"   - TimeSeriesSplit used for proper temporal validation\")\n",
    "print(f\"   - MinMaxScaler normalization applied\")\n",
    "print(f\"   - 80/20 chronological train/test split\")\n",
    "print(f\"   - All indicators computed with proper handling of edge cases\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ ANALYSIS COMPLETE!\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "name": "Complexity_2021_Final_Fixed.ipynb"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
